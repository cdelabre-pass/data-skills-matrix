# Modélisation de Données - Data Modeling skills
category:
  id: data_modeling
  name: "Modélisation de Données"

skills:
  - id: data_preparation
    name: "Préparation de Données"
    description: "Nettoyer, transformer et préparer les données (pandas, numpy, pyarrow)"
    core_roles: [data_analyst, data_engineer, analytics_eng]
    levels:
      data_analyst: [1, 2, 3, 4]
      data_engineer: [1, 2, 3, 4]
      data_scientist: [1, 2, 3, 4]
      analytics_eng: [1, 2, 3, 4]
      ml_engineer: [1, 2, 3, 4]
      backend: [1, 1, 2, 3]
    level_descriptions:
      0: "Aucune capacité de préparation de données"
      1: "Je sais nettoyer une table basique (nulls, doublons, filtres)"
      2: "Je gère les transformations complexes (jointures, conversions de types, agrégations)"
      3: "Je conçois des pipelines de préparation reproductibles et je gère les gros volumes"
      4: "Je définis les standards de préparation de données et j'automatise la validation qualité"
      5: "Je forme les équipes aux techniques avancées et j'établis les conventions de préparation à l'échelle de l'organisation"
      6: "Contributeur open-source data processing"
    behavioral_indicators:
      1:
        - "Je sais identifier et supprimer les doublons"
        - "Je gère les valeurs nulles (suppression ou imputation simple)"
        - "Je peux filtrer et trier un dataset"
      2:
        - "Je fais des jointures entre plusieurs tables"
        - "Je convertis les types de données correctement (dates, numériques)"
        - "J'utilise les opérations groupby et agrégations"
        - "Je détecte les outliers et valeurs aberrantes"
      3:
        - "Je conçois des pipelines de transformation reproductibles"
        - "Je gère les gros volumes avec pyarrow ou polars"
        - "J'automatise les contrôles de qualité des données"
        - "Je documente les transformations appliquées"
      4:
        - "J'ai défini les standards de préparation de données"
        - "Je crée des outils de validation réutilisables"
        - "Je produis un guide de bonnes pratiques de préparation de données pour l'équipe"
        - "J'optimise les performances des pipelines de préparation"
      5:
        - "Je définis la stratégie de préparation de données de l'organisation"
        - "J'arbitre les choix techniques sur les problématiques complexes de qualité des données"
        - "Je forme et mentore les équipes sur les techniques avancées de data preparation"
        - "J'établis les conventions et patterns réutilisables à l'échelle de l'entreprise"
      6:
        - "Je contribue activement à des projets open-source (pandas, polars, pyarrow)"
        - "Je suis reconnu dans la communauté data pour mon expertise en préparation de données"
        - "Je publie des articles ou donne des conférences sur le sujet"
        - "Je participe à la définition des standards et best practices de l'industrie"
    resources:
      - url: "https://pandas.pydata.org/docs/user_guide/index.html"
        title: "Pandas User Guide"
        type: "documentation"
      - url: "https://www.kaggle.com/learn/data-cleaning"
        title: "Data Cleaning Course (Kaggle)"
        type: "course"
      - url: "https://arrow.apache.org/docs/python/"
        title: "PyArrow Documentation"
        type: "documentation"
      - url: "https://realpython.com/python-data-cleaning-numpy-pandas/"
        title: "Data Cleaning with Pandas"
        type: "tutorial"
    improvement_tips:
      "1→2": "Maîtrisez les opérations pandas avancées (apply, transform, merge). Gérez les types de données correctement."
      "2→3": "Construisez des pipelines de préparation reproductibles. Utilisez pyarrow pour les gros volumes."
      "3→4": "Automatisez la validation de la qualité des données. Définissez les standards de l'équipe."

  - id: data_modeling
    name: "Modélisation & Architecture de Données"
    description: "Concevoir des modèles logiques et physiques (star/snowflake schemas), implémenter l'architecture Medallion (Bronze/Silver/Gold), documenter les modèles et alimenter le data catalog"
    core_roles: [data_engineer, analytics_eng]
    levels:
      data_analyst: [1, 1, 2, 3]
      data_engineer: [1, 2, 3, 4]
      data_scientist: [1, 1, 2, 3]
      analytics_eng: [2, 3, 4, 4]
      ml_engineer: [1, 1, 2, 3]
      backend: [1, 2, 3, 4]
    level_descriptions:
      0: "Aucune connaissance en modélisation et architecture de données"
      1: "Je comprends les concepts de base (tables, relations, clés) et le rôle des couches Bronze/Silver/Gold"
      2: "Je conçois des modèles dimensionnels basiques, je structure les données dans les bonnes couches et je documente mes modèles"
      3: "Je conçois des modèles complexes avec pipelines Bronze-to-Gold, SLAs de qualité par couche et documentation dans le data catalog"
      4: "Je définis l'architecture data warehouse et les standards Medallion de l'organisation"
      5: "Je définis la stratégie de modélisation, d'architecture de données et de documentation à l'échelle de l'organisation"
      6: "Expert data modeling et architecture reconnu, publications, contributions aux méthodologies"
    behavioral_indicators:
      1:
        - "Je comprends les clés primaires et étrangères"
        - "Je sais ce qu'est une relation 1-N et N-N"
        - "Je comprends le rôle de chaque couche (Bronze/Silver/Gold) et le flux de données entre elles"
      2:
        - "J'ai conçu un star schema avec facts et dimensions"
        - "Je comprends comment gérer l'historique des données (écraser vs conserver les anciennes valeurs)"
        - "Je structure les données dans les bonnes couches et j'applique les transformations appropriées"
        - "Je documente mes modèles avec des diagrammes et des descriptions dans le catalog"
      3:
        - "Je maîtrise les stratégies SCD Type 1 et Type 2 pour gérer l'historique des dimensions"
        - "J'ai conçu un pipeline complet Bronze to Gold avec SLAs de qualité par couche"
        - "Je choisis entre star et snowflake schema selon le cas"
        - "Je maintiens la documentation de mes modèles dans le data catalog (descriptions, owners, SLAs)"
      4:
        - "J'ai défini l'architecture data warehouse et les standards Medallion de l'équipe"
        - "Je produis les guidelines de modélisation et de documentation pour l'équipe"
        - "Je fais des revues de modèles pour les autres équipes"
        - "J'optimise les coûts de stockage et performances par couche"
      5:
        - "Je définis la stratégie de modélisation, d'architecture lakehouse et de data catalog de l'organisation"
        - "J'arbitre les décisions d'architecture data warehouse à l'échelle de l'organisation"
        - "Je forme et mentore les équipes sur les patterns de modélisation et Medallion avancés"
        - "J'établis et fais évoluer les standards de modélisation et documentation"
      6:
        - "Je suis reconnu comme expert en modélisation et architecture de données dans l'industrie"
        - "Je publie des articles ou livres sur le data modeling et l'architecture lakehouse"
        - "Je donne des conférences sur les architectures de données"
        - "Je contribue aux évolutions des méthodologies (Kimball, Data Vault, Medallion)"
    resources:
      - url: "https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/"
        title: "Kimball Dimensional Modeling"
        type: "documentation"
      - url: "https://www.databricks.com/glossary/medallion-architecture"
        title: "Medallion Architecture (Databricks)"
        type: "documentation"
      - url: "https://www.getdbt.com/blog/modular-data-modeling-techniques"
        title: "dbt Modular Data Modeling"
        type: "tutorial"
      - url: "https://www.amazon.com/Data-Warehouse-Toolkit-Definitive-Dimensional/dp/1118530802"
        title: "The Data Warehouse Toolkit (Kimball)"
        type: "book"
    improvement_tips:
      "1→2": "Étudiez les modèles dimensionnels (star schema) et l'architecture Medallion. Concevez votre premier data mart et documentez-le."
      "2→3": "Appliquez les techniques Kimball et Medallion à un projet complet. Définissez les SLAs de qualité par couche."
      "3→4": "Concevez l'architecture data warehouse et Medallion de l'organisation. Définissez les conventions de documentation."

  - id: dbt
    name: "dbt (Data Build Tool)"
    description: "Utiliser dbt pour la transformation: modèles, tests, documentation, macros Jinja, packages, modèles incrémentaux, matérialisations custom"
    core_roles: [analytics_eng, data_engineer]
    levels:
      data_analyst: [NC, NC, 1, 2]
      data_engineer: [1, 2, 3, 4]
      data_scientist: [NC, NC, 1, 2]
      analytics_eng: [2, 3, 4, 4]
      ml_engineer: [1, 1, 2, 3]
      backend: [NC, NC, 1, 2]
    level_descriptions:
      0: "Aucune connaissance dbt"
      1: "Je sais exécuter des modèles existants, utiliser les tests built-in et les packages comme dbt-utils"
      2: "J'écris des modèles avec tests, documentation, macros Jinja et modèles incrémentaux"
      3: "Je conçois la structure du projet, j'implémente les data contracts, les packages internes et j'optimise les builds"
      4: "Je mets en place le CI/CD dbt, les matérialisations custom, les snapshots et je définis les conventions de l'équipe"
      5: "Je forme les équipes aux patterns dbt avancés et j'établis la stratégie qualité données de l'organisation"
      6: "dbt Champion, speaker Coalesce, contributeur packages open-source ou dbt-core"
    behavioral_indicators:
      1:
        - "Je sais exécuter dbt run et dbt test"
        - "Je comprends la structure d'un projet dbt (models, tests, seeds)"
        - "J'utilise les tests unique et not_null sur mes modèles"
        - "J'utilise dbt-utils et je comprends les modèles incrémentaux basiques"
      2:
        - "J'écris des modèles dbt avec ref() et source()"
        - "J'écris des macros Jinja réutilisables et des tests singular"
        - "Je configure la freshness des sources et les merge strategies pour incremental"
        - "Je documente mes modèles dans les fichiers .yml"
      3:
        - "Je structure le projet en staging/intermediate/mart avec data contracts"
        - "J'ai créé un package interne avec des macros réutilisables"
        - "J'optimise les temps de build avec defer et state"
        - "J'ai mis en place une stratégie de test complète avec exposures"
      4:
        - "J'ai mis en place le CI/CD dbt avec tests automatisés et alertes"
        - "J'ai créé des matérialisations custom et je maîtrise les snapshots"
        - "Je définis les conventions dbt et la documentation de référence pour l'équipe"
        - "Je contribue à des packages dbt open-source"
      5:
        - "Je définis la stratégie dbt et qualité des données de l'organisation"
        - "Je conduis les audits de performance et d'architecture dbt à l'échelle de l'organisation"
        - "Je forme et mentore les équipes sur les patterns dbt avancés"
        - "J'établis les standards de performance et de réutilisabilité à l'échelle de l'entreprise"
      6:
        - "Je contribue activement aux packages dbt open-source ou à dbt-core"
        - "Je suis speaker à Coalesce ou autres conférences dbt"
        - "Je suis reconnu dans la communauté dbt pour mon expertise"
        - "Je publie des articles ou donne des talks sur les patterns dbt avancés"
    resources:
      - url: "https://docs.getdbt.com/"
        title: "dbt Documentation"
        type: "documentation"
      - url: "https://courses.getdbt.com/"
        title: "dbt Learn"
        type: "course"
      - url: "https://www.getdbt.com/blog/how-we-structure-our-dbt-projects"
        title: "How to Structure dbt Projects"
        type: "tutorial"
      - url: "https://docs.getdbt.com/docs/build/jinja-macros"
        title: "dbt Jinja and Macros"
        type: "documentation"
    improvement_tips:
      "1→2": "Écrivez vos premiers modèles dbt avec macros et tests. Implémentez un modèle incrémental."
      "2→3": "Structurez votre projet en staging/intermediate/mart. Créez un package interne avec des macros réutilisables."
      "3→4": "Mettez en place le CI/CD dbt. Créez une matérialisation custom. Contribuez à un package open-source."

  - id: data_mesh
    name: "Data Mesh"
    description: "Comprendre et implémenter les principes du Data Mesh (domain ownership, data as product, self-serve platform, federated governance)"
    core_roles: [data_engineer, analytics_eng]
    levels:
      data_analyst: [NC, NC, 1, 2]
      data_engineer: [1, 2, 3, 4]
      data_scientist: [NC, 1, 2, 3]
      analytics_eng: [1, 2, 3, 4]
      ml_engineer: [NC, 1, 2, 3]
      backend: [NC, 1, 2, 3]
    level_descriptions:
      0: "Aucune connaissance du Data Mesh"
      1: "Je connais les 4 principes fondamentaux du Data Mesh et je comprends la différence avec une architecture centralisée"
      2: "J'identifie les domaines de données et je conçois des data products avec leurs interfaces"
      3: "J'implémente une architecture Data Mesh et je définis les contrats de données inter-domaines"
      4: "Je guide la transformation Data Mesh de l'organisation et je conçois la plateforme self-serve"
      5: "Je définis la vision Data Mesh de l'organisation et je forme les domain owners à leurs responsabilités"
      6: "Expert reconnu, speaker/auteur sur le Data Mesh"
    behavioral_indicators:
      1:
        - "Je connais les 4 principes du Data Mesh"
        - "Je comprends la différence avec une architecture centralisée"
        - "Je sais ce qu'est un data product"
      2:
        - "J'ai identifié les domaines de données de l'organisation"
        - "J'ai conçu un data product avec ses interfaces"
        - "Je comprends les responsabilités d'un domain owner"
        - "Je sais définir les SLAs d'un data product"
      3:
        - "J'ai mis en place des data contracts entre domaines"
        - "Je configure une plateforme self-serve pour les domaines"
        - "Je définis la gouvernance fédérée"
        - "J'ai accompagné un domaine dans sa transformation"
      4:
        - "Je guide la transformation Data Mesh du projet"
        - "J'ai conçu la plateforme self-serve complète"
        - "Je produis le framework d'onboarding des domain owners"
        - "Je mesure la maturité Data Mesh des domaines"
      5:
        - "Je définis la vision et la roadmap Data Mesh de l'organisation"
        - "J'arbitre les décisions d'architecture Data Mesh à l'échelle de l'organisation"
        - "Je forme et mentore les équipes et domain owners sur les principes Data Mesh"
        - "J'établis les standards de gouvernance fédérée à l'échelle de l'entreprise"
      6:
        - "Je suis reconnu comme expert Data Mesh dans l'industrie"
        - "Je donne des conférences sur le Data Mesh (QCon, Data Council)"
        - "Je publie des articles ou livres sur le sujet"
        - "Je conseille d'autres organisations sur leur transformation Data Mesh"
    resources:
      - url: "https://www.datamesh-architecture.com/"
        title: "Data Mesh Architecture"
        type: "documentation"
      - url: "https://martinfowler.com/articles/data-mesh-principles.html"
        title: "Data Mesh Principles (Martin Fowler)"
        type: "documentation"
      - url: "https://www.oreilly.com/library/view/data-mesh/9781492092384/"
        title: "Data Mesh Book (O'Reilly)"
        type: "book"
      - url: "https://www.thoughtworks.com/what-we-do/data-and-ai/data-mesh"
        title: "ThoughtWorks Data Mesh"
        type: "documentation"
    improvement_tips:
      "1→2": "Identifiez les domaines de données de votre organisation. Concevez votre premier data product."
      "2→3": "Implémentez les data contracts entre domaines. Mettez en place la gouvernance fédérée."
      "3→4": "Guidez la transformation Data Mesh de l'organisation. Créez un framework d'onboarding pour les domain owners et mesurez la maturité Data Mesh des domaines."
