{
  "_source_hash": "0c2a4786763ea874",
  "roles": [
    {
      "id": "data_analyst",
      "name": "Data Analyst",
      "abbreviation": "DA"
    },
    {
      "id": "data_engineer",
      "name": "Data Engineer",
      "abbreviation": "DE"
    },
    {
      "id": "data_scientist",
      "name": "Data Scientist",
      "abbreviation": "DS"
    },
    {
      "id": "analytics_eng",
      "name": "Analytics Eng",
      "abbreviation": "AE"
    },
    {
      "id": "ml_engineer",
      "name": "ML Engineer",
      "abbreviation": "MLE"
    },
    {
      "id": "backend",
      "name": "Backend",
      "abbreviation": "BE"
    }
  ],
  "levels": [
    {
      "id": "junior",
      "name": "Junior",
      "abbreviation": "Jr",
      "experience": "0-3 ans",
      "description": "Apprentissage, besoin d'accompagnement",
      "core_expected": [
        1,
        2
      ],
      "secondary_expected": [
        0,
        1
      ]
    },
    {
      "id": "confirmed",
      "name": "Confirmé",
      "abbreviation": "Cf",
      "experience": "3-5 ans",
      "description": "Autonome sur les tâches standards",
      "core_expected": [
        2,
        3
      ],
      "secondary_expected": [
        1,
        2
      ]
    },
    {
      "id": "senior",
      "name": "Senior",
      "abbreviation": "Sr",
      "experience": "5-10 ans",
      "description": "Expert technique, mentor",
      "core_expected": [
        3,
        4
      ],
      "secondary_expected": [
        2,
        3
      ]
    },
    {
      "id": "expert",
      "name": "Expert",
      "abbreviation": "Ex",
      "experience": "10+ ans",
      "description": "Vision stratégique, leadership technique",
      "core_expected": [
        4,
        5
      ],
      "secondary_expected": [
        3,
        4
      ]
    }
  ],
  "skill_levels": {
    "standard": [
      {
        "level": 0,
        "name": "Aucune connaissance",
        "description": "N'a jamais utilisé l'outil/technique"
      },
      {
        "level": 1,
        "name": "Débutant",
        "description": "Peut exécuter des tâches basiques avec assistance"
      },
      {
        "level": 2,
        "name": "Intermédiaire",
        "description": "Travaille de manière autonome sur des tâches standards"
      },
      {
        "level": 3,
        "name": "Avancé",
        "description": "Gère des scénarios complexes, peut guider les autres"
      },
      {
        "level": 4,
        "name": "Expert",
        "description": "Maîtrise complète, conçoit des solutions à grande échelle"
      }
    ],
    "bonus": [
      {
        "level": 5,
        "name": "Mentor/Évangéliste",
        "description": "Forme les équipes, établit les bonnes pratiques, champion interne"
      },
      {
        "level": 6,
        "name": "Expert Externe",
        "description": "Contributions open-source, conférences, reconnu comme expert"
      }
    ]
  },
  "categories": [
    {
      "id": "analytics",
      "name": "Analytics",
      "skill_count": 13
    },
    {
      "id": "business",
      "name": "Business",
      "skill_count": 4
    },
    {
      "id": "compliance",
      "name": "Compliance",
      "skill_count": 2
    },
    {
      "id": "engineering",
      "name": "Engineering",
      "skill_count": 17
    },
    {
      "id": "ml",
      "name": "Machine Learning",
      "skill_count": 7
    },
    {
      "id": "ops",
      "name": "Data Ops",
      "skill_count": 11
    },
    {
      "id": "soft_skills",
      "name": "Soft Skills",
      "skill_count": 9
    }
  ],
  "skills": [
    {
      "id": "sql_bigquery",
      "name": "SQL & BigQuery",
      "description": "Écrire des requêtes SQL optimisées sur BigQuery, comprendre le partitionnement et le clustering",
      "core_roles": [
        "data_analyst",
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          3
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance SQL",
        "1": "Peut écrire des SELECT simples avec JOINs et WHERE basiques",
        "2": "Maîtrise les CTEs, fenêtres (window functions) et sous-requêtes complexes",
        "3": "Optimise les performances, comprend les plans d'exécution, gère les gros volumes",
        "4": "Conçoit des modèles de données efficaces, maîtrise le partitionnement/clustering BigQuery",
        "5": "Mentor SQL reconnu, forme les équipes, établit les standards",
        "6": "Contributeur BigQuery reconnu, speaker, expert externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux écrire SELECT, WHERE, GROUP BY sans aide",
          "Je sais faire un JOIN entre 2 tables",
          "Je dois parfois chercher la syntaxe pour les requêtes plus complexes"
        ],
        "2": [
          "J'écris des CTEs (WITH) couramment dans mes requêtes",
          "J'utilise les window functions (ROW_NUMBER, LEAD, LAG, SUM OVER)",
          "Je peux écrire des sous-requêtes corrélées",
          "Je comprends la différence entre LEFT/RIGHT/INNER JOIN"
        ],
        "3": [
          "Je lis et analyse les plans d'exécution BigQuery",
          "J'ai optimisé une requête en réduisant son coût de 50%+",
          "Je sais quand utiliser le partitionnement vs clustering",
          "Je gère des requêtes sur des tables de plusieurs TB"
        ],
        "4": [
          "Je conçois des schémas de données optimisés pour BigQuery",
          "Je fais des revues de requêtes SQL pour l'équipe",
          "J'ai défini des conventions SQL pour le projet",
          "Je maîtrise les fonctions analytiques avancées (QUALIFY, PIVOT)"
        ],
        "5": [
          "Je suis le référent SQL/BigQuery de l'organisation",
          "J'ai défini les standards et bonnes pratiques SQL pour l'entreprise",
          "Je forme et mentor les équipes sur les requêtes optimisées",
          "J'ai créé des templates et outils SQL réutilisables"
        ],
        "6": [
          "Je contribue à des projets open-source liés à BigQuery ou SQL",
          "J'ai présenté sur SQL/BigQuery à des conférences externes",
          "Je suis reconnu comme expert SQL/BigQuery en dehors de l'entreprise",
          "J'ai publié des articles ou tutoriels sur l'optimisation SQL"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-performance-overview",
          "title": "BigQuery Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://mode.com/sql-tutorial/",
          "title": "Mode SQL Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://www.coursera.org/learn/modern-big-data-analysis-with-sql",
          "title": "Modern Big Data Analysis with SQL (Coursera)",
          "type": "course"
        },
        {
          "url": "https://learnsql.com/blog/sql-window-functions-cheat-sheet/",
          "title": "Window Functions Cheat Sheet",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Pratiquez les CTEs et window functions sur des cas réels. Essayez de réécrire vos requêtes existantes avec des CTEs pour améliorer la lisibilité.",
        "2→3": "Apprenez à lire les plans d'exécution BigQuery. Concentrez-vous sur l'optimisation des coûts et des performances avec le partitionnement.",
        "3→4": "Menez un projet de refonte de modèle de données. Documentez vos choix de partitionnement et clustering pour l'équipe."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "statistical_analysis",
      "name": "Analyse Statistique",
      "description": "Appliquer des méthodes statistiques pour analyser les données et générer des insights",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          2,
          3,
          4,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          1
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en statistiques",
        "1": "Comprend les statistiques descriptives (moyenne, médiane, écart-type)",
        "2": "Peut réaliser des tests d'hypothèses, analyses de corrélation et régression",
        "3": "Conçoit des expériences A/B, applique des méthodes statistiques avancées",
        "4": "Expert en modélisation statistique, guide les analyses complexes",
        "5": "Référent statistiques de l'organisation, forme les équipes",
        "6": "Publication de recherche, contribution à la communauté statistique"
      },
      "behavioral_indicators": {
        "1": [
          "Je calcule et interprète moyenne, médiane, écart-type",
          "Je sais créer un histogramme ou box plot",
          "Je comprends la différence entre corrélation et causalité"
        ],
        "2": [
          "J'ai réalisé un test t ou chi-carré sur des données réelles",
          "Je peux calculer et interpréter une régression linéaire",
          "Je sais calculer un intervalle de confiance",
          "Je comprends la notion de p-value et significativité"
        ],
        "3": [
          "J'ai conçu et analysé un A/B test de bout en bout",
          "Je calcule la puissance statistique et taille d'échantillon nécessaire",
          "J'utilise des méthodes comme ANOVA ou régression multiple",
          "Je sais détecter et gérer les biais statistiques"
        ],
        "4": [
          "Je choisis la méthode statistique appropriée selon le contexte",
          "J'ai formé des collègues aux statistiques",
          "Je valide les analyses statistiques des autres",
          "Je maîtrise les approches bayésiennes"
        ],
        "5": [
          "Je suis le référent statistiques de l'organisation",
          "J'ai défini les méthodologies statistiques standard de l'entreprise",
          "Je forme et mentor les équipes sur l'analyse statistique",
          "J'ai créé des frameworks de tests statistiques réutilisables"
        ],
        "6": [
          "Je contribue à des packages statistiques open-source",
          "J'ai présenté mes travaux à des conférences sur les statistiques ou data science",
          "Je suis reconnu comme expert statistique en dehors de l'entreprise",
          "J'ai des publications ou articles sur les méthodes statistiques"
        ]
      },
      "resources": [
        {
          "url": "https://www.khanacademy.org/math/statistics-probability",
          "title": "Khan Academy Statistics",
          "type": "course"
        },
        {
          "url": "https://www.coursera.org/specializations/statistics",
          "title": "Statistics with Python (Coursera)",
          "type": "course"
        },
        {
          "url": "https://seeing-theory.brown.edu/",
          "title": "Seeing Theory - Visual Statistics",
          "type": "tutorial"
        },
        {
          "url": "https://statsthinking21.github.io/statsthinking21-core-site/",
          "title": "Statistical Thinking for the 21st Century",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez les tests d'hypothèses (t-test, chi-carré). Pratiquez sur des données réelles de l'entreprise.",
        "2→3": "Formez-vous au design d'expériences A/B. Calculez la puissance statistique et la taille d'échantillon nécessaire.",
        "3→4": "Explorez les méthodes avancées (analyse bayésienne, modèles mixtes). Menez une analyse complexe de bout en bout."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "insight_generation",
      "name": "Génération d'Insights",
      "description": "Transformer les données en recommandations business actionnables",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Ne peut pas générer d'insights",
        "1": "Peut décrire ce que montrent les données, observations basiques",
        "2": "Identifie les patterns, tendances et anomalies avec contexte métier",
        "3": "Génère des insights stratégiques et recommandations à partir d'analyses complexes",
        "4": "Pilote la prise de décision data-driven au niveau organisationnel",
        "5": "Influence la stratégie de l'entreprise par les données",
        "6": "Reconnu comme expert en data storytelling"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux décrire les chiffres clés d'un dashboard",
          "Je réponds aux questions 'combien' et 'quand'",
          "Je présente les données sans interprétation approfondie"
        ],
        "2": [
          "J'identifie les tendances et anomalies dans les données",
          "Je pose la question 'pourquoi' après chaque observation",
          "Je relie les données au contexte métier",
          "Je peux expliquer l'impact potentiel d'un changement observé"
        ],
        "3": [
          "Mes analyses mènent à des décisions concrètes",
          "Je propose des recommandations actionnables avec les données",
          "J'anticipe les questions des stakeholders",
          "J'ai influencé au moins une décision stratégique avec mes analyses"
        ],
        "4": [
          "Je pilote des initiatives data-driven à l'échelle de l'organisation",
          "Les dirigeants me consultent pour des décisions importantes",
          "Je forme les équipes au data storytelling",
          "J'ai un track record d'impacts mesurables"
        ],
        "5": [
          "Je suis le référent data storytelling de l'organisation",
          "J'ai défini les standards de communication des insights",
          "Je forme et mentor les équipes sur la génération d'insights",
          "J'ai créé des frameworks d'analyse réutilisables pour l'entreprise"
        ],
        "6": [
          "Je contribue à la communauté data storytelling (blogs, open-source)",
          "J'ai présenté sur la génération d'insights à des conférences externes",
          "Je suis reconnu comme expert data storytelling en dehors de l'entreprise",
          "J'ai des publications ou articles sur l'analyse de données business"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://www.coursera.org/learn/analytics-business",
          "title": "Business Analytics (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2013/03/know-the-difference-between-your-data-and-your-metrics",
          "title": "HBR - Data vs Metrics",
          "type": "documentation"
        },
        {
          "url": "https://amplitude.com/blog/data-storytelling",
          "title": "Data Storytelling Guide",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Ajoutez toujours le contexte métier à vos analyses. Posez la question 'So what?' après chaque observation.",
        "2→3": "Développez la capacité à anticiper les questions des stakeholders. Préparez des recommandations actionnables.",
        "3→4": "Menez des projets d'impact stratégique. Présentez régulièrement au COMEX ou équivalent."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "ml_fundamentals",
      "name": "Fondamentaux ML",
      "description": "Comprendre et appliquer les concepts de Machine Learning",
      "core_roles": [
        "data_scientist",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance ML",
        "1": "Comprend les concepts de base (supervisé vs non-supervisé, biais-variance)",
        "2": "Peut implémenter des modèles ML basiques avec scikit-learn",
        "3": "Sélectionne les algorithmes appropriés, optimise les hyperparamètres",
        "4": "Conçoit des solutions ML de bout en bout et optimise les performances",
        "5": "Architecte ML, définit les standards de l'organisation",
        "6": "Contributeur open-source ML, publications, conférences"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends la différence entre supervisé et non-supervisé",
          "Je sais expliquer ce qu'est l'overfitting",
          "Je connais les algorithmes classiques (régression, arbre de décision)",
          "J'ai suivi un cours d'introduction au ML"
        ],
        "2": [
          "J'ai entraîné un modèle scikit-learn sur des données réelles",
          "Je sais faire un train/test split correctement",
          "Je comprends les métriques de base (accuracy, precision, recall)",
          "J'ai participé à un projet ML même en support"
        ],
        "3": [
          "Je choisis l'algorithme adapté selon le problème",
          "Je fais de l'optimisation d'hyperparamètres (GridSearch, RandomSearch)",
          "J'utilise la validation croisée systématiquement",
          "J'ai déployé au moins un modèle en production"
        ],
        "4": [
          "Je conçois l'architecture ML complète d'un projet",
          "Je maîtrise les techniques avancées (ensemble, boosting)",
          "Je gère le monitoring et retraining des modèles",
          "Je forme les autres aux bonnes pratiques ML"
        ],
        "5": [
          "Je suis le référent ML de l'organisation",
          "J'ai défini les standards et bonnes pratiques ML pour l'entreprise",
          "Je forme et mentor les équipes sur le Machine Learning",
          "J'ai créé des pipelines et outils ML réutilisables"
        ],
        "6": [
          "Je contribue à des projets open-source ML (scikit-learn, TensorFlow, etc.)",
          "J'ai présenté sur le ML à des conférences externes",
          "Je suis reconnu comme expert ML en dehors de l'entreprise",
          "J'ai des publications ou articles de recherche sur le ML"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/machine-learning",
          "title": "Machine Learning by Andrew Ng",
          "type": "course"
        },
        {
          "url": "https://scikit-learn.org/stable/tutorial/index.html",
          "title": "Scikit-learn Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://www.statlearning.com/",
          "title": "Introduction to Statistical Learning",
          "type": "book"
        },
        {
          "url": "https://madewithml.com/",
          "title": "Made with ML",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez les algorithmes classiques (régression, arbres de décision, clustering) sur des datasets publics.",
        "2→3": "Apprenez la validation croisée et l'optimisation d'hyperparamètres. Participez à une compétition Kaggle.",
        "3→4": "Développez un projet ML complet en production. Maîtrisez le monitoring et le retraining des modèles."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "ab_testing",
      "name": "A/B Testing & Expérimentation",
      "description": "Conception, implémentation et analyse statistique de tests A/B (puissance, significativité, interprétation)",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des tests A/B",
        "1": "Comprend le concept de test A/B et son utilité",
        "2": "Peut analyser les résultats d'un test A/B, calcule la significativité statistique",
        "3": "Conçoit des expériences complexes (tests multi-variés, calcul de puissance, segmentation)",
        "4": "Expert en expérimentation, définit la stratégie de testing, gère les biais",
        "5": "Référent expérimentation, évangélise la culture du test",
        "6": "Speaker sur l'expérimentation, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends pourquoi on fait des tests A/B",
          "Je sais que 'statistiquement significatif' ne veut pas dire 'important'",
          "Je peux lire les résultats d'un test A/B dans un outil"
        ],
        "2": [
          "Je calcule la significativité statistique d'un test",
          "J'interprète correctement les intervalles de confiance",
          "J'ai analysé les résultats d'au moins 5 tests A/B",
          "Je sais détecter un test arrêté trop tôt"
        ],
        "3": [
          "Je calcule la taille d'échantillon nécessaire avant un test",
          "Je conçois des tests multi-variés",
          "Je segmente les résultats pour trouver des effets hétérogènes",
          "J'ai mis en place un test de bout en bout"
        ],
        "4": [
          "Je forme les PMs à l'expérimentation",
          "J'ai défini le framework d'expérimentation de l'équipe",
          "Je gère les cas complexes (effet de nouveauté, contamination)",
          "Je challenge les interprétations incorrectes"
        ],
        "5": [
          "Je suis le référent expérimentation de l'organisation",
          "J'ai défini les standards et méthodologies de tests A/B pour l'entreprise",
          "Je forme et mentor les équipes sur l'expérimentation",
          "J'ai créé des outils et calculateurs de tests réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source d'expérimentation",
          "J'ai présenté sur l'A/B testing à des conférences externes",
          "Je suis reconnu comme expert expérimentation en dehors de l'entreprise",
          "J'ai des publications ou articles sur les tests A/B"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/ab-testing-google",
          "title": "A/B Testing by Google (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.evanmiller.org/ab-testing/",
          "title": "Evan Miller's A/B Testing Tools",
          "type": "tutorial"
        },
        {
          "url": "https://www.optimizely.com/optimization-glossary/",
          "title": "Optimizely Experimentation Glossary",
          "type": "documentation"
        },
        {
          "url": "https://www.exp-platform.com/Documents/2017-08%20ABTestingAtScale.pdf",
          "title": "Online Experiments at Scale (Microsoft)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez à calculer la significativité statistique. Analysez les tests A/B passés de l'entreprise.",
        "2→3": "Maîtrisez le calcul de puissance et de taille d'échantillon. Concevez un test multi-varié.",
        "3→4": "Formez les équipes produit à l'expérimentation. Mettez en place un framework d'expérimentation."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "firebase_analytics",
      "name": "Firebase & Mobile Analytics",
      "description": "Configuration Firebase Analytics, event tracking, user properties, funnels, Remote Config",
      "core_roles": [
        "data_analyst",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Firebase Analytics",
        "1": "Comprend les concepts Firebase, peut consulter les rapports basiques",
        "2": "Configure des events custom, user properties, analyse les funnels de conversion",
        "3": "Conçoit le plan de taggage complet, utilise Remote Config, optimise le tracking",
        "4": "Expert Firebase, architecte la stratégie de tracking mobile",
        "5": "Référent tracking mobile de l'organisation",
        "6": "Contributeur Firebase community, expert reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans la console Firebase Analytics",
          "Je consulte les rapports d'audience et d'engagement",
          "Je comprends la différence entre events et user properties"
        ],
        "2": [
          "J'ai configuré des events custom dans l'app",
          "Je crée des funnels pour analyser les parcours utilisateur",
          "J'utilise les user properties pour segmenter l'audience",
          "Je sais exporter les données vers BigQuery"
        ],
        "3": [
          "J'ai conçu un plan de taggage complet pour une app",
          "J'utilise Remote Config pour les feature flags",
          "Je configure les audiences pour le remarketing",
          "J'optimise la collecte pour réduire les coûts"
        ],
        "4": [
          "Je définis la stratégie de tracking mobile de l'organisation",
          "Je forme les développeurs aux bonnes pratiques Firebase",
          "Je gère les problèmes de privacy et consent",
          "J'ai mis en place le debug view pour le QA"
        ],
        "5": [
          "Je suis le référent Firebase/tracking mobile de l'organisation",
          "J'ai défini les standards et bonnes pratiques Firebase pour l'entreprise",
          "Je forme et mentor les équipes sur Firebase Analytics",
          "J'ai créé des frameworks de tracking mobile réutilisables"
        ],
        "6": [
          "Je contribue à la communauté Firebase (forums, plugins, exemples)",
          "J'ai présenté sur Firebase à des conférences externes ou Google events",
          "Je suis reconnu comme expert Firebase en dehors de l'entreprise",
          "J'ai des publications ou articles sur le tracking mobile"
        ]
      },
      "resources": [
        {
          "url": "https://firebase.google.com/docs/analytics",
          "title": "Firebase Analytics Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/playlist?list=PLl-K7zZEsYLnfwBe4WgEw9ao0J0N1LYDR",
          "title": "Firebase YouTube Tutorials",
          "type": "video"
        },
        {
          "url": "https://firebase.google.com/codelabs/firebase-analytics-android",
          "title": "Firebase Analytics Codelab",
          "type": "tutorial"
        },
        {
          "url": "https://segment.com/academy/collecting-data/naming-conventions-for-clean-data/",
          "title": "Event Naming Conventions",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Configurez des events custom pour un feature spécifique. Créez votre premier funnel d'analyse.",
        "2→3": "Concevez un plan de taggage complet. Mettez en place des user properties pour la segmentation.",
        "3→4": "Devenez le référent Firebase. Formez les développeurs aux bonnes pratiques de tracking."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "product_metrics",
      "name": "Product Metrics & KPIs",
      "description": "Définition et suivi des métriques produit (DAU/MAU, rétention, churn, LTV, activation, engagement)",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des métriques produit",
        "1": "Comprend les métriques basiques (DAU, MAU, conversion)",
        "2": "Calcule et analyse les métriques clés, comprend les cohortes de rétention",
        "3": "Définit les KPIs stratégiques, analyse le LTV, segmente par comportement",
        "4": "Expert en métriques produit, guide la stratégie produit basée sur les données",
        "5": "Définit le framework de métriques de l'organisation",
        "6": "Expert product analytics reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais ce que signifient DAU, MAU, et taux de conversion",
          "Je peux lire un dashboard de métriques produit",
          "Je comprends pourquoi la rétention est importante"
        ],
        "2": [
          "Je calcule les cohortes de rétention (D1, D7, D30)",
          "J'analyse les taux de conversion par étape du funnel",
          "Je segmente les métriques par source d'acquisition",
          "J'ai construit un dashboard de KPIs produit"
        ],
        "3": [
          "J'ai défini la North Star Metric de mon équipe",
          "Je calcule et segmente le LTV par cohorte",
          "J'identifie les leading indicators vs lagging indicators",
          "Je propose des objectifs quantifiés basés sur les données"
        ],
        "4": [
          "J'ai défini le framework de métriques de l'organisation",
          "Je présente les KPIs au COMEX régulièrement",
          "Je challenge les objectifs irréalistes avec les données",
          "Je forme les PMs à définir leurs métriques de succès"
        ],
        "5": [
          "Je suis le référent product metrics de l'organisation",
          "J'ai défini les standards et frameworks de métriques pour l'entreprise",
          "Je forme et mentor les équipes sur les métriques produit",
          "J'ai créé des outils et templates de suivi de KPIs réutilisables"
        ],
        "6": [
          "Je contribue à la communauté product analytics (blogs, outils open-source)",
          "J'ai présenté sur les métriques produit à des conférences externes",
          "Je suis reconnu comme expert product analytics en dehors de l'entreprise",
          "J'ai des publications ou articles sur les métriques et analytics produit"
        ]
      },
      "resources": [
        {
          "url": "https://amplitude.com/blog/product-metrics",
          "title": "Guide to Product Metrics",
          "type": "documentation"
        },
        {
          "url": "https://www.reforge.com/blog/north-star-metric-growth",
          "title": "North Star Metric (Reforge)",
          "type": "documentation"
        },
        {
          "url": "https://mixpanel.com/blog/product-analytics-guide/",
          "title": "Product Analytics Guide (Mixpanel)",
          "type": "tutorial"
        },
        {
          "url": "https://www.lennysnewsletter.com/p/what-is-good-retention-issue-29",
          "title": "What is Good Retention (Lenny's Newsletter)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Calculez les métriques de rétention de votre produit. Construisez un dashboard de suivi des KPIs principaux.",
        "2→3": "Définissez la North Star Metric de votre équipe. Analysez le LTV par segment utilisateur.",
        "3→4": "Créez un framework de métriques pour toute l'organisation. Présentez les insights produit au COMEX."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "behavioral_analysis",
      "name": "Analyse Comportementale",
      "description": "Analyse de cohortes, funnel analysis, parcours utilisateur, segmentation comportementale",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'analyse comportementale",
        "1": "Comprend les concepts de funnel et cohorte",
        "2": "Réalise des analyses de cohortes, identifie les points de friction dans les funnels",
        "3": "Conçoit des segmentations comportementales avancées, analyse les parcours utilisateur",
        "4": "Expert en analyse comportementale, prédit les comportements et recommande des actions",
        "5": "Référent analyse comportementale, forme les équipes produit",
        "6": "Expert UX analytics reconnu externement"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un funnel de conversion",
          "Je sais ce qu'est une analyse de cohorte",
          "Je peux identifier les étapes principales d'un parcours utilisateur"
        ],
        "2": [
          "J'ai réalisé une analyse de cohorte sur les inscriptions",
          "J'identifie les points de friction dans un funnel",
          "Je compare les comportements entre segments d'utilisateurs",
          "Je sais utiliser un outil comme Amplitude ou Mixpanel"
        ],
        "3": [
          "Je crée des segments comportementaux (power users, at-risk, dormants)",
          "J'analyse les parcours utilisateur complets (customer journey)",
          "J'identifie les comportements prédictifs de la rétention",
          "J'ai influencé une décision produit grâce à mon analyse"
        ],
        "4": [
          "Je construis des modèles prédictifs de churn",
          "J'automatise les alertes sur les changements de comportement",
          "Je forme les équipes produit à l'analyse comportementale",
          "J'ai un track record d'optimisations basées sur mes analyses"
        ],
        "5": [
          "Je suis le référent analyse comportementale de l'organisation",
          "J'ai défini les standards et méthodologies d'analyse comportementale pour l'entreprise",
          "Je forme et mentor les équipes sur l'analyse de parcours utilisateur",
          "J'ai créé des frameworks de segmentation réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source d'analytics comportemental",
          "J'ai présenté sur l'analyse comportementale à des conférences externes",
          "Je suis reconnu comme expert UX analytics en dehors de l'entreprise",
          "J'ai des publications ou articles sur l'analyse comportementale"
        ]
      },
      "resources": [
        {
          "url": "https://amplitude.com/blog/cohort-analysis",
          "title": "Cohort Analysis Guide",
          "type": "tutorial"
        },
        {
          "url": "https://www.hotjar.com/conversion-rate-optimization/glossary/funnel-analysis/",
          "title": "Funnel Analysis (Hotjar)",
          "type": "documentation"
        },
        {
          "url": "https://www.nngroup.com/articles/journey-mapping-101/",
          "title": "Journey Mapping 101 (NN Group)",
          "type": "documentation"
        },
        {
          "url": "https://mixpanel.com/blog/behavioral-analytics/",
          "title": "Behavioral Analytics Guide",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Réalisez une analyse de cohorte sur les inscriptions des 12 derniers mois. Identifiez les patterns de rétention.",
        "2→3": "Créez des segments comportementaux (power users, at-risk, etc.). Analysez les parcours menant à la conversion.",
        "3→4": "Développez des modèles prédictifs de churn. Automatisez les alertes sur les changements de comportement."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "attribution_marketing",
      "name": "Attribution & Marketing Analytics",
      "description": "Modèles d'attribution, analyse des canaux d'acquisition, ROI campagnes, UTM tracking",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'attribution marketing",
        "1": "Comprend les UTM et le tracking des sources",
        "2": "Analyse les performances par canal, calcule le ROI des campagnes",
        "3": "Implémente des modèles d'attribution multi-touch, optimise les budgets",
        "4": "Expert en attribution, conçoit la stratégie de mesure marketing complète",
        "5": "Définit la stratégie d'attribution de l'organisation",
        "6": "Expert marketing analytics reconnu, conférences"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce que sont les paramètres UTM",
          "Je sais ce qu'est l'attribution last-click",
          "Je peux identifier la source d'acquisition d'un utilisateur"
        ],
        "2": [
          "Je calcule le CAC (coût d'acquisition) par canal",
          "J'analyse le ROI des campagnes marketing",
          "Je compare les performances des différents canaux",
          "J'ai configuré le tracking UTM pour des campagnes"
        ],
        "3": [
          "J'implémente des modèles d'attribution multi-touch",
          "Je compare les résultats first-click vs last-click vs linear",
          "Je propose des réallocations de budget basées sur les données",
          "Je gère les problèmes de tracking cross-device"
        ],
        "4": [
          "J'ai défini la stratégie de mesure marketing complète",
          "Je challenge les attributions des agences media",
          "Je forme les équipes marketing à l'analyse de performance",
          "Je gère les problèmes de privacy (iOS 14.5, GDPR)"
        ],
        "5": [
          "Je suis le référent attribution/marketing analytics de l'organisation",
          "J'ai défini les standards et modèles d'attribution pour l'entreprise",
          "Je forme et mentor les équipes sur le marketing analytics",
          "J'ai créé des frameworks d'attribution réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source de marketing analytics",
          "J'ai présenté sur l'attribution à des conférences marketing externes",
          "Je suis reconnu comme expert marketing analytics en dehors de l'entreprise",
          "J'ai des publications ou articles sur l'attribution et le marketing analytics"
        ]
      },
      "resources": [
        {
          "url": "https://support.google.com/analytics/answer/10596866",
          "title": "Google Analytics Attribution",
          "type": "documentation"
        },
        {
          "url": "https://www.thinkwithgoogle.com/intl/en-gb/marketing-strategies/data-and-measurement/marketing-attribution-models/",
          "title": "Attribution Models (Think with Google)",
          "type": "documentation"
        },
        {
          "url": "https://segment.com/academy/collecting-data/naming-conventions-for-clean-data/",
          "title": "UTM Best Practices",
          "type": "tutorial"
        },
        {
          "url": "https://www.coursera.org/learn/marketing-analytics",
          "title": "Marketing Analytics (Coursera)",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les performances de vos canaux d'acquisition. Calculez le CAC par canal.",
        "2→3": "Implémentez un modèle d'attribution multi-touch. Comparez les résultats avec le last-click.",
        "3→4": "Définissez la stratégie de mesure marketing complète. Optimisez l'allocation budgétaire data-driven."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "tracking_design",
      "name": "Design de Tracking",
      "description": "Conception de taxonomies d'events, data contracts, plan de taggage, documentation",
      "core_roles": [
        "analytics_eng",
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du design de tracking",
        "1": "Comprend l'importance d'un plan de taggage structuré",
        "2": "Peut documenter les events existants, propose des améliorations",
        "3": "Conçoit des taxonomies d'events cohérentes, définit les data contracts",
        "4": "Expert en architecture de tracking, établit les standards pour toute l'organisation",
        "5": "Référent tracking, forme et audite les équipes",
        "6": "Expert data governance reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends pourquoi un plan de taggage est important",
          "Je sais ce qu'est un event et ses propriétés",
          "Je peux lire la documentation de tracking existante"
        ],
        "2": [
          "J'ai documenté les events d'une feature",
          "J'identifie les incohérences dans le nommage des events",
          "Je propose des améliorations au tracking existant",
          "Je valide que le tracking est bien implémenté"
        ],
        "3": [
          "J'ai conçu une taxonomie d'events pour un domaine",
          "Je définis des data contracts avec les équipes produit",
          "J'utilise un outil de gestion de tracking (Avo, Amplitude)",
          "Je mets en place un processus de validation du tracking"
        ],
        "4": [
          "J'ai défini les standards de tracking de l'organisation",
          "J'audite la qualité du tracking des différentes équipes",
          "Je forme les développeurs aux bonnes pratiques",
          "J'automatise la validation et les alertes de qualité"
        ],
        "5": [
          "Je suis le référent tracking/data governance de l'organisation",
          "J'ai défini les standards et taxonomies de tracking pour l'entreprise",
          "Je forme et mentor les équipes sur le design de tracking",
          "J'ai créé des outils et templates de plan de taggage réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source de data governance",
          "J'ai présenté sur le design de tracking à des conférences externes",
          "Je suis reconnu comme expert data governance en dehors de l'entreprise",
          "J'ai des publications ou articles sur le tracking et data contracts"
        ]
      },
      "resources": [
        {
          "url": "https://segment.com/academy/collecting-data/how-to-create-a-tracking-plan/",
          "title": "How to Create a Tracking Plan",
          "type": "tutorial"
        },
        {
          "url": "https://www.avo.app/blog/tracking-plan-best-practices",
          "title": "Tracking Plan Best Practices (Avo)",
          "type": "documentation"
        },
        {
          "url": "https://snowplowanalytics.com/blog/2020/01/24/re-thinking-the-structure-of-event-data/",
          "title": "Event Data Structure (Snowplow)",
          "type": "documentation"
        },
        {
          "url": "https://dataform.co/blog/data-contracts",
          "title": "Data Contracts",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Documentez les events existants dans votre produit. Identifiez les incohérences de nommage.",
        "2→3": "Créez une taxonomie d'events standardisée. Mettez en place un processus de validation.",
        "3→4": "Implémentez des data contracts avec les équipes produit. Automatisez la validation du tracking."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "metabase",
      "name": "Metabase",
      "description": "Utiliser Metabase pour le BI et les dashboards",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          1
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Metabase",
        "1": "Peut naviguer et utiliser les dashboards existants",
        "2": "Peut créer des questions, dashboards, visualisations basiques",
        "3": "Conçoit des dashboards complexes, utilise variables et filtres",
        "4": "Expert Metabase, peut optimiser les performances",
        "5": "Admin Metabase, définit les standards de l'organisation",
        "6": "Contributeur Metabase community"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans Metabase et utilise les dashboards existants",
          "Je sais appliquer des filtres sur un dashboard",
          "Je peux exporter des données depuis Metabase"
        ],
        "2": [
          "Je crée des questions (simple et custom)",
          "J'assemble des dashboards avec plusieurs visualisations",
          "Je choisis le bon type de graphique selon les données",
          "J'utilise les filtres de dashboard pour l'interactivité"
        ],
        "3": [
          "J'utilise les variables et SQL natif pour les cas complexes",
          "Je crée des dashboards avec drill-down",
          "Je configure les alertes et subscriptions",
          "Je gère les collections et permissions"
        ],
        "4": [
          "J'optimise les requêtes lentes dans Metabase",
          "Je configure le caching pour les performances",
          "Je forme les utilisateurs à créer leurs propres dashboards",
          "J'administre l'instance Metabase"
        ],
        "5": [
          "Je suis le référent Metabase de l'organisation",
          "J'ai défini les standards et bonnes pratiques Metabase pour l'entreprise",
          "Je forme et mentor les équipes sur Metabase",
          "J'ai créé des templates de dashboards réutilisables"
        ],
        "6": [
          "Je contribue au projet open-source Metabase",
          "J'ai présenté sur Metabase à des conférences externes ou meetups",
          "Je suis reconnu comme expert Metabase en dehors de l'entreprise",
          "J'ai publié des articles ou tutoriels sur Metabase"
        ]
      },
      "resources": [
        {
          "url": "https://www.metabase.com/learn/",
          "title": "Metabase Learn",
          "type": "tutorial"
        },
        {
          "url": "https://www.metabase.com/docs/latest/",
          "title": "Metabase Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.metabase.com/blog/dashboard-design-principles",
          "title": "Dashboard Design Principles",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/c/Metabase/videos",
          "title": "Metabase YouTube Channel",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez votre premier dashboard avec 3-5 questions liées. Utilisez les filtres pour rendre le dashboard interactif.",
        "2→3": "Maîtrisez les SQL questions et les variables. Créez des dashboards avec drill-down.",
        "3→4": "Optimisez les performances des questions lentes. Mettez en place les bonnes pratiques de cache."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "looker",
      "name": "Looker",
      "description": "Utiliser Looker pour l'exploration de données et les dashboards BI",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          "NC",
          "NC"
        ],
        "data_scientist": [
          "NC",
          "NC",
          "NC",
          "NC"
        ],
        "analytics_eng": [
          "NC",
          "NC",
          "NC",
          "NC"
        ],
        "ml_engineer": [
          "NC",
          "NC",
          "NC",
          "NC"
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          "NC"
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Looker",
        "1": "Peut utiliser les Explores et dashboards existants",
        "2": "Peut créer des Looks et dashboards personnalisés",
        "3": "Conçoit des dashboards complexes, maîtrise les Explores avancés",
        "4": "Expert Looker, optimise les performances et forme les utilisateurs",
        "5": "Référent Looker de l'organisation",
        "6": "Expert Looker reconnu, speaker Looker events"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans les Explores existants",
          "J'applique des filtres et pivots sur les dashboards",
          "Je peux sauvegarder un Look pour mon usage"
        ],
        "2": [
          "Je crée des Looks avec dimensions et mesures",
          "J'assemble des dashboards avec des tiles",
          "Je comprends la notion de dimension vs measure"
        ],
        "3": [
          "Je crée des explores personnalisés avec filtres avancés",
          "Je conçois des dashboards interactifs avec drill-down",
          "J'utilise les derived tables pour les cas complexes"
        ],
        "4": [
          "J'optimise les performances des explores",
          "Je forme les analystes à utiliser Looker efficacement",
          "J'administre et configure l'instance Looker"
        ],
        "5": [
          "Je suis le référent Looker de l'organisation",
          "J'ai défini les standards et bonnes pratiques Looker pour l'entreprise",
          "Je forme et mentor les équipes sur Looker"
        ],
        "6": [
          "Je contribue à la communauté Looker (forums, plugins)",
          "J'ai présenté sur Looker à des conférences externes ou Google events",
          "Je suis reconnu comme expert Looker en dehors de l'entreprise"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/looker/docs",
          "title": "Looker Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.cloudskillsboost.google/paths/28",
          "title": "Looker Learning Path (Google Cloud)",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/playlist?list=PL6nfYkMvvs4l7r_6JYdH0fwvw8bsKPzDl",
          "title": "Looker YouTube Tutorials",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez des Looks et dashboards pour votre équipe. Explorez les différentes visualisations disponibles.",
        "2→3": "Maîtrisez les filtres avancés et le drill-down. Créez des dashboards interactifs.",
        "3→4": "Optimisez les performances des explores. Formez les utilisateurs et définissez les bonnes pratiques."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "dashboard_design",
      "name": "Design de Dashboards",
      "description": "Concevoir des visualisations de données efficaces et storytelling data",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en visualisation",
        "1": "Comprend les types de graphiques basiques et leur usage",
        "2": "Conçoit des dashboards clairs suivant les bonnes pratiques",
        "3": "Crée des data stories compelling, dashboards interactifs complexes",
        "4": "Expert en visualisation de données et storytelling",
        "5": "Référent dataviz de l'organisation",
        "6": "Expert dataviz reconnu, publications, formations externes"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais quand utiliser un bar chart vs line chart",
          "Je comprends l'importance des titres et labels",
          "Je peux créer un graphique simple et lisible"
        ],
        "2": [
          "Je respecte les bonnes pratiques (pas de 3D, couleurs cohérentes)",
          "Mes dashboards ont une hiérarchie visuelle claire",
          "Je place les KPIs importants en haut du dashboard",
          "Je choisis les échelles appropriées (pas de axes tronqués trompeurs)"
        ],
        "3": [
          "Je crée des data stories avec un fil conducteur",
          "Mes dashboards guident l'utilisateur vers les insights",
          "J'utilise l'interactivité (filtres, drill-down) à bon escient",
          "J'ai reçu des retours positifs sur mes visualisations"
        ],
        "4": [
          "J'ai défini un style guide dataviz pour l'équipe",
          "Je forme les autres au data storytelling",
          "Mes dashboards sont cités en exemple",
          "Je maîtrise les techniques avancées (small multiples, annotations)"
        ],
        "5": [
          "Je suis le référent dataviz de l'organisation",
          "J'ai défini les standards et bonnes pratiques de visualisation pour l'entreprise",
          "Je forme et mentor les équipes sur le design de dashboards",
          "J'ai créé un design system dataviz réutilisable"
        ],
        "6": [
          "Je contribue à des projets open-source de visualisation (D3.js, etc.)",
          "J'ai présenté sur la dataviz à des conférences externes",
          "Je suis reconnu comme expert dataviz en dehors de l'entreprise",
          "J'ai des publications ou articles sur la visualisation de données"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://www.data-to-viz.com/",
          "title": "From Data to Viz - Chart Selection",
          "type": "tutorial"
        },
        {
          "url": "https://www.tableau.com/learn/articles/data-visualization-tips",
          "title": "Data Visualization Tips (Tableau)",
          "type": "documentation"
        },
        {
          "url": "https://nightingaledvs.com/",
          "title": "Nightingale - Data Visualization Society",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez quand utiliser chaque type de graphique. Refaites un de vos dashboards en appliquant les bonnes pratiques.",
        "2→3": "Créez une data story complète avec un fil conducteur. Utilisez les principes de storytelling.",
        "3→4": "Développez un style guide de dataviz pour votre organisation. Formez les équipes aux bonnes pratiques."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "pass_culture_knowledge",
      "name": "Connaissance Pass Culture",
      "description": "Comprendre le dispositif Pass Culture (crédit jeunes 15-20 ans, parcours utilisateur, catalogue d'offres, objectifs de diversification culturelle) et les domaines culturels (Livres, Cinéma, Musique, Spectacle vivant, Musées/Patrimoine, Festivals, Pratiques artistiques)",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du Pass Culture",
        "1": "Comprend le dispositif (crédit jeunes 15-20 ans, objectifs de démocratisation) et les grandes catégories d'offres culturelles (livres, cinéma, musique, spectacle vivant, musées)",
        "2": "Maîtrise les entités métier (offres, réservations, lieux, utilisateurs) et les spécificités de chaque domaine culturel (poids dans les réservations, offres physiques vs numériques)",
        "3": "Expert des parcours utilisateurs, mécaniques de crédit, et des tendances de consommation par domaine culturel et par cohorte",
        "4": "Référent métier, analyse les cohortes, mesure l'impact du dispositif et identifie les leviers de diversification par domaine",
        "5": "Expert domaine, influence la stratégie produit, les politiques publiques et la stratégie d'enrichissement du catalogue",
        "6": "Reconnu comme expert Pass Culture en externe, publications institutionnelles et études sectorielles"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les objectifs du Pass Culture et la démocratisation culturelle",
          "Je connais les tranches d'âge, les montants de crédit et les grandes catégories d'offres",
          "Je sais ce qu'est une offre, une réservation, et la différence entre offres physiques et numériques"
        ],
        "2": [
          "Je maîtrise le modèle de données Pass Culture et les KPIs principaux",
          "Je comprends les différents types d'offres, de lieux et les spécificités de chaque domaine culturel",
          "Je connais le parcours utilisateur de A à Z et la répartition des réservations par domaine",
          "Je sais quels domaines sont surreprésentés ou sous-représentés dans les réservations"
        ],
        "3": [
          "J'analyse les cohortes de bénéficiaires et l'évolution de la consommation par domaine",
          "Je comprends les mécaniques de crédit par âge et les facteurs de diversification",
          "J'identifie les tendances émergentes par domaine culturel et les leviers de diversification",
          "Je connais l'écosystème des acteurs culturels et leurs enjeux sectoriels"
        ],
        "4": [
          "Je suis référent métier pour les équipes data sur le dispositif et les domaines culturels",
          "Je mesure l'impact du dispositif et contribue aux rapports institutionnels",
          "Je contribue aux stratégies d'enrichissement du catalogue par domaine",
          "Je forme les nouveaux arrivants au métier et aux spécificités des domaines culturels"
        ],
        "5": [
          "Je définis les orientations stratégiques du produit data et de l'offre culturelle",
          "Je suis consulté par la direction sur les sujets métier et les partenariats sectoriels",
          "Je contribue aux réflexions de politique publique et à la stratégie d'enrichissement",
          "Je forme les équipes produit et direction aux enjeux métier et sectoriels"
        ],
        "6": [
          "Je publie des études institutionnelles sur le Pass Culture et les pratiques culturelles",
          "Je suis sollicité par le ministère ou des institutions externes",
          "Je donne des conférences sur le dispositif Pass Culture et les politiques culturelles",
          "Je suis reconnu comme expert de référence en externe sur le dispositif et les domaines culturels"
        ]
      },
      "resources": [
        {
          "url": "https://pass.culture.fr/",
          "title": "Site officiel Pass Culture",
          "type": "documentation"
        },
        {
          "url": "https://passculture.zendesk.com/hc/fr",
          "title": "Centre d'aide Pass Culture",
          "type": "documentation"
        },
        {
          "url": "https://www.culture.gouv.fr/Thematiques/Pass-Culture",
          "title": "Ministère de la Culture - Pass Culture",
          "type": "documentation"
        },
        {
          "url": "https://www.data.gouv.fr/fr/organizations/pass-culture/",
          "title": "Open Data Pass Culture",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Explorez les données métier (offres, réservations par domaine). Comprenez le modèle de données et la répartition par catégorie.",
        "2→3": "Analysez les parcours utilisateurs et les tendances de consommation par cohorte et par domaine. Étudiez les facteurs de diversification.",
        "3→4": "Contribuez aux études d'impact et aux stratégies de diversification par domaine. Présentez les résultats aux parties prenantes institutionnelles."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "cultural_recommendation",
      "name": "Recommandation Culturelle",
      "description": "Comprendre les enjeux de la recommandation d'offres culturelles: diversification, découverte, sérendipité, équilibre popularité/niche",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la recommandation culturelle",
        "1": "Comprend les enjeux de diversité et découverte culturelle propres au Pass Culture",
        "2": "Maîtrise les métriques spécifiques (diversité, sérendipité, taux de découverte)",
        "3": "Conçoit des stratégies de recommandation adaptées aux objectifs de politique publique",
        "4": "Expert en recommandation culturelle, équilibre popularité et découverte de niches",
        "5": "Définit la stratégie de recommandation et mesure son impact sur les pratiques",
        "6": "Expert reco culturelle reconnu, publications académiques sur la diversification"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les objectifs de diversification culturelle",
          "Je connais les risques des bulles de filtre",
          "Je sais ce qu'est la sérendipité dans un contexte culturel"
        ],
        "2": [
          "Je calcule les métriques de diversité (coverage, novelty)",
          "Je mesure le taux de découverte de nouveaux domaines",
          "J'analyse l'impact des recommandations sur la diversification",
          "Je comprends l'équilibre explore/exploit"
        ],
        "3": [
          "Je conçois des stratégies de recommandation pour la diversification",
          "J'intègre les objectifs de politique publique dans les algorithmes",
          "Je mesure l'impact à long terme sur les pratiques culturelles",
          "J'ai contribué à améliorer les recommandations du Pass Culture"
        ],
        "4": [
          "Je définis la stratégie de recommandation de l'organisation",
          "J'équilibre popularité et découverte de niches",
          "Je publie sur la recommandation culturelle",
          "Je forme les équipes aux enjeux spécifiques"
        ],
        "5": [
          "Je définis la roadmap stratégique de recommandation",
          "Je mesure l'impact des algorithmes sur les pratiques culturelles",
          "Je suis référent pour les choix éthiques de recommandation",
          "Je forme les équipes produit et direction aux enjeux de la reco"
        ],
        "6": [
          "Je publie des articles académiques sur la recommandation culturelle",
          "Je suis speaker dans des conférences RecSys ou similaires",
          "Je suis consulté par d'autres organisations sur leurs stratégies",
          "Je suis reconnu comme expert de la recommandation culturelle"
        ]
      },
      "resources": [
        {
          "url": "https://research.netflix.com/publications",
          "title": "Netflix Research - Recommendations",
          "type": "documentation"
        },
        {
          "url": "https://recsys.acm.org/",
          "title": "ACM RecSys Conference",
          "type": "documentation"
        },
        {
          "url": "https://arxiv.org/list/cs.IR/recent",
          "title": "arXiv - Information Retrieval",
          "type": "documentation"
        },
        {
          "url": "https://eugeneyan.com/writing/system-design-for-discovery/",
          "title": "System Design for Discovery",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Comprenez les métriques de diversité (coverage, novelty, serendipity). Analysez l'impact des recos actuelles.",
        "2→3": "Concevez des expériences pour mesurer la diversification. Équilibrez explore/exploit.",
        "3→4": "Publiez vos recherches. Contribuez aux discussions académiques sur la recommandation culturelle."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "cultural_ecosystem",
      "name": "Écosystème Culturel Français",
      "description": "Connaître les acteurs culturels (librairies, cinémas, salles de spectacle, musées, festivals) et leurs enjeux économiques et territoriaux",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'écosystème culturel",
        "1": "Comprend les grandes catégories d'acteurs culturels partenaires",
        "2": "Maîtrise les spécificités par secteur (librairies indépendantes, cinémas art et essai, scènes nationales...)",
        "3": "Expert des enjeux économiques et territoriaux de chaque secteur culturel",
        "4": "Référent écosystème, contextualise les analyses selon les dynamiques sectorielles",
        "5": "Expert reconnu de l'écosystème culturel français et de ses évolutions",
        "6": "Influence les politiques culturelles, expert auprès du ministère de la Culture"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les types d'acteurs culturels partenaires",
          "Je comprends le rôle des librairies, cinémas, musées",
          "Je sais ce qu'est un acteur culturel vs un offreur"
        ],
        "2": [
          "Je connais les spécificités des librairies indépendantes",
          "Je comprends les enjeux des cinémas art et essai",
          "Je sais ce qu'est une scène nationale ou conventionnée",
          "J'analyse les données des partenaires culturels"
        ],
        "3": [
          "Je comprends les enjeux économiques par secteur",
          "J'analyse les dynamiques territoriales (zones rurales, QPV)",
          "Je connais les fédérations et syndicats professionnels",
          "Je contextualise mes analyses selon les réalités sectorielles"
        ],
        "4": [
          "Je suis référent écosystème pour les équipes",
          "Je participe aux échanges avec les partenaires institutionnels",
          "Je contribue aux rapports sur l'écosystème",
          "Je forme les équipes aux spécificités des acteurs culturels"
        ],
        "5": [
          "Je définis les orientations stratégiques sur l'écosystème",
          "Je suis l'interlocuteur privilégié des fédérations professionnelles",
          "Je contribue aux réflexions de politique publique sur les secteurs",
          "Je forme la direction aux enjeux de l'écosystème"
        ],
        "6": [
          "Je suis sollicité par le ministère comme expert de l'écosystème",
          "Je publie des études sur l'écosystème culturel français",
          "Je donne des conférences sur les enjeux des acteurs culturels",
          "Je suis reconnu comme expert de référence de l'écosystème"
        ]
      },
      "resources": [
        {
          "url": "https://www.culture.gouv.fr/Thematiques/Industries-culturelles",
          "title": "Industries culturelles",
          "type": "documentation"
        },
        {
          "url": "https://www.syndicat-librairie.fr/",
          "title": "Syndicat de la librairie française",
          "type": "documentation"
        },
        {
          "url": "https://www.fncf.org/",
          "title": "FNCF - Cinémas",
          "type": "documentation"
        },
        {
          "url": "https://www.lesindependants.net/",
          "title": "Les Indépendants",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Étudiez les différents types d'acteurs culturels. Comprenez leurs enjeux économiques.",
        "2→3": "Analysez les dynamiques territoriales. Identifiez les zones en tension.",
        "3→4": "Contribuez aux discussions avec les partenaires institutionnels. Publiez des analyses sectorielles."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "cultural_impact_measurement",
      "name": "Mesure d'Impact Culturel",
      "description": "Évaluer l'impact du Pass Culture: études cohortes, diversification des pratiques, découverte culturelle, réitération post-crédit",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          1
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la mesure d'impact",
        "1": "Comprend les indicateurs clés (taux d'utilisation, diversification, découverte)",
        "2": "Analyse les cohortes sortantes et mesure l'évolution des pratiques culturelles",
        "3": "Conçoit des méthodologies d'évaluation d'impact (enquêtes, analyse comportementale)",
        "4": "Expert en évaluation de politiques publiques culturelles",
        "5": "Définit la stratégie d'évaluation et produit les rapports institutionnels",
        "6": "Expert reconnu en évaluation d'impact, publications académiques"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les indicateurs d'impact du Pass Culture",
          "Je connais le taux d'utilisation et de diversification",
          "Je sais ce qu'est une étude de cohorte"
        ],
        "2": [
          "J'analyse les cohortes sortantes (18-19 ans)",
          "Je mesure l'évolution des pratiques culturelles",
          "Je calcule les indicateurs de découverte et réitération",
          "Je contribue aux tableaux de bord d'impact"
        ],
        "3": [
          "Je conçois des méthodologies d'évaluation d'impact",
          "Je croise les données comportementales et déclaratives",
          "J'analyse la réitération post-crédit",
          "Je produis des études d'impact structurées"
        ],
        "4": [
          "Je suis expert en évaluation de politiques publiques",
          "Je produis les rapports pour les instances institutionnelles",
          "Je définis la stratégie d'évaluation",
          "Je forme les équipes à la mesure d'impact"
        ],
        "5": [
          "Je définis la stratégie globale d'évaluation d'impact",
          "Je suis l'interlocuteur des instances de tutelle (ministère, etc.)",
          "Je coordonne les études d'impact avec des partenaires externes",
          "Je forme la direction et les équipes à l'évaluation d'impact"
        ],
        "6": [
          "Je publie des articles académiques sur l'évaluation d'impact culturel",
          "Je suis sollicité comme expert par d'autres institutions publiques",
          "Je donne des conférences sur l'évaluation des politiques culturelles",
          "Je suis reconnu comme expert de référence en évaluation d'impact"
        ]
      },
      "resources": [
        {
          "url": "https://www.sciencespo.fr/liepp/fr/content/evaluation-des-politiques-publiques",
          "title": "Sciences Po - Évaluation politiques publiques",
          "type": "documentation"
        },
        {
          "url": "https://www.francestrategic.fr/thematiques/evaluation-des-politiques-publiques",
          "title": "France Stratégie - Évaluation",
          "type": "documentation"
        },
        {
          "url": "https://www.jpal.org/research",
          "title": "J-PAL - Impact Evaluation",
          "type": "documentation"
        },
        {
          "url": "https://www.povertyactionlab.org/sites/default/files/research-resources/practical-guide-evaluating-impact.pdf",
          "title": "Guide pratique évaluation d'impact",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les indicateurs d'impact existants. Comprenez la méthodologie des études cohortes.",
        "2→3": "Contribuez à une étude d'impact. Concevez des indicateurs complémentaires.",
        "3→4": "Menez une étude d'impact de bout en bout. Présentez aux instances institutionnelles."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "rgpd",
      "name": "RGPD & Protection des Données",
      "description": "Comprendre et appliquer le RGPD et les régulations de protection des données",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance RGPD",
        "1": "Comprend les principes de base du RGPD",
        "2": "Peut implémenter les exigences RGPD dans le travail data",
        "3": "Conçoit des systèmes conformes au RGPD",
        "4": "Expert en régulations de protection des données",
        "5": "Référent RGPD de l'organisation, DPO adjoint",
        "6": "Expert RGPD reconnu, formateur externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les 6 principes du RGPD",
          "Je sais ce qu'est une donnée personnelle",
          "Je comprends les droits des personnes (accès, effacement)"
        ],
        "2": [
          "J'identifie les données personnelles dans mes pipelines",
          "J'applique l'anonymisation et la pseudonymisation",
          "Je respecte la minimisation des données",
          "Je documente les traitements de données"
        ],
        "3": [
          "Je conçois des systèmes avec Privacy by Design",
          "J'implémente le droit à l'oubli dans les pipelines",
          "Je gère les durées de rétention",
          "J'ai réalisé une analyse d'impact (AIPD)"
        ],
        "4": [
          "Je suis référent RGPD pour les équipes data",
          "Je forme les équipes aux exigences RGPD",
          "Je valide la conformité des nouveaux traitements",
          "Je participe aux audits de conformité"
        ],
        "5": [
          "Je définis la politique de protection des données de l'organisation",
          "Je suis DPO adjoint ou référent privacy",
          "Je forme les managers et équipes à la conformité RGPD",
          "Je coordonne les audits de conformité internes"
        ],
        "6": [
          "Je suis formateur externe certifié RGPD",
          "Je suis sollicité comme consultant par d'autres organisations",
          "Je donne des conférences sur la protection des données",
          "Je suis reconnu comme expert RGPD dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on",
          "title": "CNIL - RGPD Guide",
          "type": "documentation"
        },
        {
          "url": "https://gdpr.eu/",
          "title": "GDPR.eu Complete Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/data-privacy-fundamentals",
          "title": "Data Privacy Fundamentals (Coursera)",
          "type": "course"
        },
        {
          "url": "https://ico.org.uk/for-organisations/guide-to-data-protection/",
          "title": "ICO Data Protection Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Identifiez les données personnelles dans vos pipelines. Implémentez l'anonymisation basique.",
        "2→3": "Concevez des systèmes avec Privacy by Design. Implémentez le droit à l'oubli.",
        "3→4": "Devenez référent RGPD de l'équipe. Formez les autres aux bonnes pratiques."
      },
      "category": "compliance",
      "category_name": "Compliance"
    },
    {
      "id": "data_security",
      "name": "Sécurité des Données",
      "description": "Implémenter les bonnes pratiques de sécurité (IAM, encryption, secrets)",
      "core_roles": [
        "data_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance sécurité",
        "1": "Comprend les concepts de sécurité de base",
        "2": "Peut implémenter les contrôles d'accès, encryption basique",
        "3": "Conçoit des architectures de données sécurisées",
        "4": "Expert en patterns de sécurité des données",
        "5": "Architecte sécurité data de l'organisation",
        "6": "Expert sécurité reconnu, certifications CISSP/CISM"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le principe du moindre privilège",
          "Je ne stocke jamais de secrets dans le code",
          "Je connais les bases de IAM GCP"
        ],
        "2": [
          "Je configure les permissions IAM correctement",
          "J'utilise Secret Manager pour les credentials",
          "Je chiffre les données sensibles",
          "J'évite les configurations ouvertes (buckets publics)"
        ],
        "3": [
          "Je conçois des architectures sécurisées",
          "J'implémente l'audit des accès aux données",
          "Je configure le column-level security",
          "Je gère les service accounts avec principe du moindre privilège"
        ],
        "4": [
          "J'ai défini les standards de sécurité data",
          "Je réalise des audits de sécurité",
          "Je forme les équipes aux bonnes pratiques",
          "Je participe aux certifications de sécurité"
        ],
        "5": [
          "Je définis l'architecture de sécurité data de l'organisation",
          "Je suis référent sécurité pour les équipes data",
          "Je coordonne les audits de sécurité internes et externes",
          "Je forme les managers et équipes à la sécurité des données"
        ],
        "6": [
          "Je suis certifié CISSP, CISM ou équivalent",
          "Je suis consultant externe en sécurité des données",
          "Je donne des conférences sur la sécurité data",
          "Je suis reconnu comme expert sécurité dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/security/best-practices",
          "title": "GCP Security Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://owasp.org/www-project-data-security/",
          "title": "OWASP Data Security",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/professional-certificates/google-cybersecurity",
          "title": "Google Cybersecurity Certificate",
          "type": "course"
        },
        {
          "url": "https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations",
          "title": "GCP Enterprise Security",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez les bases de IAM GCP. Gérez les secrets avec Secret Manager.",
        "2→3": "Implémentez le chiffrement des données sensibles. Auditez les accès.",
        "3→4": "Concevez l'architecture de sécurité data. Passez une certification sécurité."
      },
      "category": "compliance",
      "category_name": "Compliance"
    },
    {
      "id": "data_preparation",
      "name": "Préparation de Données",
      "description": "Nettoyer, transformer et préparer les données (pandas, numpy, pyarrow)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune capacité de préparation de données",
        "1": "Peut réaliser un nettoyage basique (nulls, doublons)",
        "2": "Gère les transformations complexes, conversions de types et fusions",
        "3": "Conçoit des pipelines de préparation, gère les cas limites à grande échelle",
        "4": "Expert en qualité des données et automatisation de la préparation",
        "5": "Définit les standards de préparation de données de l'organisation",
        "6": "Contributeur open-source data processing"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais identifier et supprimer les doublons",
          "Je gère les valeurs nulles (suppression ou imputation simple)",
          "Je peux filtrer et trier un dataset"
        ],
        "2": [
          "Je fais des jointures entre plusieurs tables",
          "Je convertis les types de données correctement (dates, numériques)",
          "J'utilise les opérations groupby et agrégations",
          "Je détecte les outliers et valeurs aberrantes"
        ],
        "3": [
          "Je conçois des pipelines de transformation reproductibles",
          "Je gère les gros volumes avec pyarrow ou polars",
          "J'automatise les contrôles de qualité des données",
          "Je documente les transformations appliquées"
        ],
        "4": [
          "J'ai défini les standards de préparation de données",
          "Je crée des outils de validation réutilisables",
          "Je forme les autres aux bonnes pratiques",
          "J'optimise les performances des pipelines de préparation"
        ],
        "5": [
          "Je définis la stratégie de préparation de données de l'organisation",
          "Je suis la référence interne pour les problématiques de qualité des données",
          "Je forme et mentor les équipes sur les techniques avancées de data preparation",
          "J'établis les conventions et patterns réutilisables à l'échelle de l'entreprise"
        ],
        "6": [
          "Je contribue activement à des projets open-source (pandas, polars, pyarrow)",
          "Je suis reconnu dans la communauté data pour mon expertise en préparation de données",
          "Je publie des articles ou donne des conférences sur le sujet",
          "Je participe à la définition des standards et best practices de l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://pandas.pydata.org/docs/user_guide/index.html",
          "title": "Pandas User Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.kaggle.com/learn/data-cleaning",
          "title": "Data Cleaning Course (Kaggle)",
          "type": "course"
        },
        {
          "url": "https://arrow.apache.org/docs/python/",
          "title": "PyArrow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://realpython.com/python-data-cleaning-numpy-pandas/",
          "title": "Data Cleaning with Pandas",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Maîtrisez les opérations pandas avancées (apply, transform, merge). Gérez les types de données correctement.",
        "2→3": "Construisez des pipelines de préparation reproductibles. Utilisez pyarrow pour les gros volumes.",
        "3→4": "Automatisez la validation de la qualité des données. Définissez les standards de l'équipe."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "data_modeling",
      "name": "Modélisation de Données",
      "description": "Concevoir des modèles logiques et physiques (star/snowflake schemas)",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en modélisation",
        "1": "Comprend les concepts de base (tables, relations, clés)",
        "2": "Peut concevoir des modèles dimensionnels basiques",
        "3": "Conçoit des modèles complexes considérant performance et scalabilité",
        "4": "Expert en patterns de modélisation, architectures enterprise",
        "5": "Architecte données de l'organisation",
        "6": "Expert data modeling reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les clés primaires et étrangères",
          "Je sais ce qu'est une relation 1-N et N-N",
          "Je peux lire un schéma de base de données"
        ],
        "2": [
          "J'ai conçu un star schema avec facts et dimensions",
          "Je comprends la différence entre SCD Type 1 et Type 2",
          "Je normalise et dénormalise selon les besoins",
          "Je documente mes modèles avec des diagrammes"
        ],
        "3": [
          "Je conçois des modèles optimisés pour les performances",
          "Je choisis entre star et snowflake schema selon le cas",
          "J'ai conçu un data mart complet pour un domaine métier",
          "Je gère les slowly changing dimensions complexes"
        ],
        "4": [
          "J'ai défini l'architecture data warehouse de l'organisation",
          "Je forme les équipes aux bonnes pratiques de modélisation",
          "Je fais des revues de modèles pour les autres",
          "J'ai documenté les conventions de modélisation"
        ],
        "5": [
          "Je définis la stratégie de modélisation de données de l'organisation",
          "Je suis le référent pour les décisions d'architecture data warehouse",
          "Je mentor les équipes sur les patterns de modélisation avancés",
          "J'établis et fais évoluer les standards de modélisation"
        ],
        "6": [
          "Je suis reconnu comme expert en modélisation de données dans l'industrie",
          "Je publie des articles ou livres sur le data modeling",
          "Je donne des conférences sur les architectures de données",
          "Je contribue aux évolutions des méthodologies (Kimball, Data Vault)"
        ]
      },
      "resources": [
        {
          "url": "https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/",
          "title": "Kimball Dimensional Modeling",
          "type": "documentation"
        },
        {
          "url": "https://www.getdbt.com/analytics-engineering/modular-data-modeling-technique/",
          "title": "dbt Modular Data Modeling",
          "type": "tutorial"
        },
        {
          "url": "https://www.datacamp.com/courses/data-modeling-in-sql-server",
          "title": "Data Modeling Course (DataCamp)",
          "type": "course"
        },
        {
          "url": "https://www.amazon.com/Data-Warehouse-Toolkit-Definitive-Dimensional/dp/1118530802",
          "title": "The Data Warehouse Toolkit (Kimball)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Étudiez les modèles dimensionnels (star schema). Concevez votre premier data mart.",
        "2→3": "Appliquez les techniques Kimball à un projet complet. Documentez les conventions de nommage.",
        "3→4": "Concevez l'architecture data warehouse de l'organisation. Formez les équipes aux bonnes pratiques."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "dbt",
      "name": "dbt (Data Build Tool)",
      "description": "Utiliser dbt pour la transformation: modèles, tests (generic, singular, freshness), documentation et seeds",
      "core_roles": [
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance dbt",
        "1": "Peut exécuter des modèles existants, utilise les tests built-in (unique, not_null)",
        "2": "Écrit des modèles et tests singular, configure source freshness et documentation",
        "3": "Conçoit la structure du projet, implémente une stratégie de test complète avec data contracts",
        "4": "Expert en architecture dbt, CI/CD avec tests, alerting et couverture optimale",
        "5": "Référent dbt, définit la stratégie qualité données de l'organisation",
        "6": "dbt Champion, speaker Coalesce, contributeur packages open-source"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais exécuter dbt run et dbt test",
          "Je comprends la structure d'un projet dbt (models, tests, seeds)",
          "J'utilise les tests unique et not_null sur mes modèles",
          "Je sais lire la documentation générée par dbt"
        ],
        "2": [
          "J'écris des modèles dbt avec ref() et source()",
          "J'ai créé des tests singular pour valider des règles métier",
          "Je configure la freshness des sources",
          "Je documente mes modèles dans les fichiers .yml",
          "J'utilise les seeds pour les données de référence"
        ],
        "3": [
          "Je structure le projet en staging/intermediate/mart",
          "J'implémente des data contracts avec dbt",
          "J'utilise les tags et selectors pour organiser les runs",
          "J'ai mis en place une stratégie de test complète",
          "Je configure les exposures pour la traçabilité"
        ],
        "4": [
          "J'ai mis en place le CI/CD dbt avec tests automatisés",
          "Je configure les alertes sur les échecs de tests",
          "Je définis les conventions dbt pour l'équipe",
          "J'optimise les temps de build avec defer et state"
        ],
        "5": [
          "Je définis la stratégie dbt et qualité des données de l'organisation",
          "Je suis le référent interne pour les problématiques dbt complexes",
          "Je forme et mentor les équipes sur les patterns dbt avancés",
          "J'établis les conventions et best practices dbt à l'échelle de l'entreprise"
        ],
        "6": [
          "Je contribue activement aux packages dbt open-source (dbt-utils, dbt-expectations)",
          "Je suis speaker à Coalesce ou autres conférences dbt",
          "Je suis reconnu dans la communauté dbt pour mon expertise",
          "Je participe aux discussions sur l'évolution de dbt"
        ]
      },
      "resources": [
        {
          "url": "https://docs.getdbt.com/",
          "title": "dbt Documentation",
          "type": "documentation"
        },
        {
          "url": "https://courses.getdbt.com/",
          "title": "dbt Learn",
          "type": "course"
        },
        {
          "url": "https://www.getdbt.com/blog/how-we-structure-our-dbt-projects",
          "title": "How to Structure dbt Projects",
          "type": "tutorial"
        },
        {
          "url": "https://hub.getdbt.com/",
          "title": "dbt Hub - Packages",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Écrivez vos premiers modèles dbt. Ajoutez des tests et de la documentation.",
        "2→3": "Structurez votre projet en staging/intermediate/mart. Implémentez les data contracts.",
        "3→4": "Mettez en place le CI/CD dbt. Contribuez à un package open-source. Présentez à Coalesce."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "dbt_advanced",
      "name": "dbt Avancé (Macros, Packages, Incremental)",
      "description": "Maîtriser les fonctionnalités avancées: macros Jinja, packages, modèles incrémentaux, hooks, materialisations custom",
      "core_roles": [
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des fonctionnalités avancées dbt",
        "1": "Utilise des packages existants, comprend les modèles incrémentaux basiques",
        "2": "Écrit des macros réutilisables, configure incremental avec merge strategies",
        "3": "Développe des packages internes, optimise les runs avec defer et state",
        "4": "Expert en materialisations custom, hooks, performance tuning avancé",
        "5": "Architecte dbt, définit les patterns de l'organisation",
        "6": "Maintainer de packages dbt open-source, contributeur dbt-core"
      },
      "behavioral_indicators": {
        "1": [
          "J'utilise dbt-utils dans mes projets",
          "Je comprends le fonctionnement des modèles incrémentaux",
          "Je sais quand utiliser incremental vs table"
        ],
        "2": [
          "J'écris des macros Jinja réutilisables",
          "Je configure les merge strategies pour incremental",
          "J'utilise les hooks pour des opérations pre/post",
          "J'ai installé et configuré des packages externes"
        ],
        "3": [
          "J'ai créé un package interne avec des macros",
          "J'utilise defer et state pour optimiser les builds",
          "Je configure des matérialisations ephemeral stratégiquement",
          "J'ai réduit significativement les temps de build"
        ],
        "4": [
          "J'ai créé une matérialisation custom",
          "Je maîtrise les snapshots pour l'historisation",
          "Je contribue à des packages open-source",
          "Je forme l'équipe aux fonctionnalités avancées"
        ],
        "5": [
          "Je définis l'architecture dbt et les patterns avancés de l'organisation",
          "Je suis le référent pour les optimisations dbt complexes",
          "Je mentor les équipes sur les macros, packages et matérialisations custom",
          "J'établis les standards de performance et de réutilisabilité"
        ],
        "6": [
          "Je maintiens des packages dbt open-source populaires",
          "Je contribue au code de dbt-core ou aux adapters",
          "Je suis reconnu dans la communauté pour mes contributions techniques",
          "Je publie des articles ou donne des talks sur les patterns dbt avancés"
        ]
      },
      "resources": [
        {
          "url": "https://docs.getdbt.com/docs/build/jinja-macros",
          "title": "dbt Jinja and Macros",
          "type": "documentation"
        },
        {
          "url": "https://docs.getdbt.com/docs/build/incremental-models",
          "title": "Incremental Models Guide",
          "type": "documentation"
        },
        {
          "url": "https://github.com/dbt-labs/dbt-utils",
          "title": "dbt-utils Package",
          "type": "documentation"
        },
        {
          "url": "https://www.getdbt.com/blog/how-we-built-dbt",
          "title": "How dbt Works",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Écrivez vos premières macros. Implémentez un modèle incrémental avec merge strategy.",
        "2→3": "Créez un package interne avec des macros réutilisables. Utilisez defer et state pour optimiser.",
        "3→4": "Créez une materialisation custom. Contribuez à dbt-utils ou créez votre propre package public."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "data_mesh",
      "name": "Data Mesh",
      "description": "Comprendre et implémenter les principes du Data Mesh (domain ownership, data as product, self-serve platform, federated governance)",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du Data Mesh",
        "1": "Comprend les 4 principes fondamentaux du Data Mesh",
        "2": "Peut identifier les domaines de données et concevoir des data products",
        "3": "Implémente une architecture Data Mesh, définit les contrats de données inter-domaines",
        "4": "Expert en gouvernance fédérée, conçoit des plateformes self-serve pour les domaines",
        "5": "Référent Data Mesh, guide la transformation organisationnelle",
        "6": "Expert reconnu, speaker/auteur sur le Data Mesh"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les 4 principes du Data Mesh",
          "Je comprends la différence avec une architecture centralisée",
          "Je sais ce qu'est un data product"
        ],
        "2": [
          "J'ai identifié les domaines de données de l'organisation",
          "J'ai conçu un data product avec ses interfaces",
          "Je comprends les responsabilités d'un domain owner",
          "Je sais définir les SLAs d'un data product"
        ],
        "3": [
          "J'ai mis en place des data contracts entre domaines",
          "Je configure une plateforme self-serve pour les domaines",
          "Je définis la gouvernance fédérée",
          "J'ai accompagné un domaine dans sa transformation"
        ],
        "4": [
          "Je guide la transformation Data Mesh de l'organisation",
          "J'ai conçu la plateforme self-serve complète",
          "Je forme les domain owners à leurs responsabilités",
          "Je mesure la maturité Data Mesh des domaines"
        ],
        "5": [
          "Je définis la vision et la roadmap Data Mesh de l'organisation",
          "Je suis le référent pour les questions d'architecture Data Mesh",
          "Je mentor les équipes et domain owners sur les principes Data Mesh",
          "J'établis les standards de gouvernance fédérée à l'échelle de l'entreprise"
        ],
        "6": [
          "Je suis reconnu comme expert Data Mesh dans l'industrie",
          "Je donne des conférences sur le Data Mesh (QCon, Data Council)",
          "Je publie des articles ou livres sur le sujet",
          "Je conseille d'autres organisations sur leur transformation Data Mesh"
        ]
      },
      "resources": [
        {
          "url": "https://www.datamesh-architecture.com/",
          "title": "Data Mesh Architecture",
          "type": "documentation"
        },
        {
          "url": "https://martinfowler.com/articles/data-mesh-principles.html",
          "title": "Data Mesh Principles (Martin Fowler)",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-mesh/9781492092384/",
          "title": "Data Mesh Book (O'Reilly)",
          "type": "book"
        },
        {
          "url": "https://www.thoughtworks.com/what-we-do/data-and-ai/data-mesh",
          "title": "ThoughtWorks Data Mesh",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Identifiez les domaines de données de votre organisation. Concevez votre premier data product.",
        "2→3": "Implémentez les data contracts entre domaines. Mettez en place la gouvernance fédérée.",
        "3→4": "Guidez la transformation Data Mesh de l'organisation. Partagez votre expérience en conférence."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "medallion_architecture",
      "name": "Architecture Medallion (Bronze/Silver/Gold)",
      "description": "Concevoir et implémenter l'architecture Medallion avec les couches Bronze (raw), Silver (cleaned/conformed), Gold (business-ready)",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          1,
          2,
          3
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'architecture Medallion",
        "1": "Comprend les couches Bronze/Silver/Gold et leurs objectifs",
        "2": "Peut structurer les données dans les bonnes couches avec les transformations appropriées",
        "3": "Conçoit des pipelines complets respectant les SLAs de qualité par couche",
        "4": "Expert en optimisation des couches, gestion du lineage et des métadonnées",
        "5": "Définit les standards Medallion de l'organisation",
        "6": "Expert reconnu, contributeur aux best practices Databricks/Delta Lake"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le rôle de chaque couche (Bronze/Silver/Gold)",
          "Je sais pourquoi on sépare raw et cleaned data",
          "Je peux expliquer le flux de données entre couches"
        ],
        "2": [
          "J'ai structuré des données dans les bonnes couches",
          "J'applique les transformations appropriées par couche",
          "Je définis les schémas de validation par couche",
          "Je documente les transformations entre couches"
        ],
        "3": [
          "J'ai conçu un pipeline complet Bronze to Gold",
          "Je définis les SLAs de qualité par couche",
          "Je gère le lineage entre les couches",
          "J'optimise les performances par couche"
        ],
        "4": [
          "J'ai défini les standards Medallion de l'organisation",
          "Je forme les équipes à l'architecture Medallion",
          "Je gère les métadonnées et le data catalog",
          "J'optimise les coûts de stockage par couche"
        ],
        "5": [
          "Je définis la stratégie d'architecture Medallion de l'organisation",
          "Je suis le référent pour les questions d'architecture lakehouse",
          "Je mentor les équipes sur les patterns Medallion avancés",
          "J'établis les standards de qualité et de gouvernance par couche"
        ],
        "6": [
          "Je contribue aux best practices Databricks/Delta Lake",
          "Je suis speaker aux conférences Data+AI Summit",
          "Je publie des articles sur l'architecture lakehouse",
          "Je suis reconnu comme expert Medallion/Delta Lake dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.databricks.com/glossary/medallion-architecture",
          "title": "Medallion Architecture (Databricks)",
          "type": "documentation"
        },
        {
          "url": "https://docs.databricks.com/en/lakehouse/medallion.html",
          "title": "Databricks Medallion Guide",
          "type": "documentation"
        },
        {
          "url": "https://delta.io/",
          "title": "Delta Lake Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/watch?v=kAMEZNfLG5U",
          "title": "Medallion Architecture Explained",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Structurez vos premières données en Bronze/Silver/Gold. Documentez les transformations par couche.",
        "2→3": "Définissez les SLAs de qualité par couche. Implémentez le lineage automatique.",
        "3→4": "Optimisez les performances et coûts par couche. Partagez vos patterns en interne."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "gcp_fundamentals",
      "name": "GCP Fondamentaux",
      "description": "Comprendre les services GCP (GCS, GCE, IAM, networking)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance GCP",
        "1": "Peut naviguer dans la console, comprend les services de base",
        "2": "Utilise GCS, Compute Engine et IAM basique",
        "3": "Conçoit des architectures multi-services, comprend networking et sécurité",
        "4": "Expert en architecture GCP, optimise coûts et performances",
        "5": "Architecte cloud de l'organisation, certifié Professional",
        "6": "Google Cloud Champion, speaker Google Next"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans la console GCP",
          "Je comprends les services de base (GCS, BigQuery, Compute)",
          "Je sais ce qu'est un projet GCP"
        ],
        "2": [
          "J'uploade et télécharge des fichiers dans GCS",
          "Je configure les permissions IAM basiques",
          "J'utilise Cloud Shell pour des opérations simples",
          "Je comprends la facturation GCP"
        ],
        "3": [
          "Je conçois des architectures utilisant plusieurs services",
          "Je configure les VPC et règles firewall",
          "Je mets en place les service accounts et rôles",
          "J'utilise Terraform ou Deployment Manager"
        ],
        "4": [
          "J'optimise les coûts GCP de l'organisation",
          "Je conçois des architectures haute disponibilité",
          "J'ai une certification GCP Professional",
          "Je forme les équipes aux bonnes pratiques GCP"
        ],
        "5": [
          "Je définis la stratégie cloud GCP de l'organisation",
          "Je suis le référent pour les décisions d'architecture cloud",
          "Je mentor les équipes sur les patterns GCP avancés",
          "J'établis les standards de sécurité et de gouvernance cloud"
        ],
        "6": [
          "Je suis speaker à Google Cloud Next ou autres conférences Google",
          "Je suis reconnu comme Google Cloud Champion",
          "Je contribue aux discussions communautaires GCP",
          "Je publie des articles ou études de cas sur les architectures GCP"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/docs",
          "title": "Google Cloud Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.cloudskillsboost.google/",
          "title": "Google Cloud Skills Boost",
          "type": "course"
        },
        {
          "url": "https://cloud.google.com/certification",
          "title": "Google Cloud Certifications",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/googlecloudtech",
          "title": "Google Cloud Tech YouTube",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un projet GCP et utilisez GCS pour stocker des données. Configurez les IAM basiques.",
        "2→3": "Concevez une architecture multi-services. Apprenez le VPC et la sécurité réseau.",
        "3→4": "Passez une certification GCP Professional. Optimisez les coûts d'un projet existant."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "bigquery_advanced",
      "name": "BigQuery Avancé",
      "description": "Maîtriser BigQuery (partitionnement, clustering, BI Engine, coûts)",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          2,
          3,
          4,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance BigQuery",
        "1": "Peut exécuter des requêtes, naviguer dans les datasets",
        "2": "Conçoit tables/vues, optimise requêtes, comprend partitionnement/clustering",
        "3": "Conçoit l'architecture data warehouse, gère coûts et performances",
        "4": "Expert BigQuery, streaming, ML features, BigQuery Omni",
        "5": "Référent BigQuery, audite et optimise l'organisation",
        "6": "Expert BigQuery reconnu, contributions communautaires"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans les datasets et exécute des requêtes",
          "Je comprends l'interface BigQuery Console",
          "Je sais exporter les résultats de requêtes"
        ],
        "2": [
          "Je crée des tables avec partitionnement et clustering",
          "J'analyse les coûts de mes requêtes",
          "J'optimise les requêtes pour réduire les coûts",
          "J'utilise les vues matérialisées"
        ],
        "3": [
          "J'ai conçu l'architecture data warehouse d'un domaine",
          "Je configure les slot reservations",
          "J'utilise BI Engine pour les dashboards temps réel",
          "Je mets en place des alertes de coûts"
        ],
        "4": [
          "J'utilise BigQuery ML pour des modèles simples",
          "Je configure le streaming insert",
          "J'optimise les coûts à l'échelle de l'organisation",
          "Je forme les équipes aux bonnes pratiques BigQuery"
        ],
        "5": [
          "Je définis la stratégie BigQuery de l'organisation",
          "Je suis le référent pour les optimisations et audits BigQuery",
          "Je mentor les équipes sur les patterns BigQuery avancés",
          "J'établis les standards de coûts et de performance"
        ],
        "6": [
          "Je suis reconnu comme expert BigQuery dans la communauté",
          "Je contribue aux discussions et forums Google Cloud",
          "Je publie des articles ou donne des talks sur BigQuery",
          "Je participe aux beta tests et feedbacks des nouvelles fonctionnalités"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-performance-overview",
          "title": "BigQuery Performance Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/bigquery/docs/partitioned-tables",
          "title": "Partitioned Tables Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.cloudskillsboost.google/course_templates/53",
          "title": "BigQuery Fundamentals (Qwiklabs)",
          "type": "course"
        },
        {
          "url": "https://medium.com/google-cloud/bigquery-explained-series-4f0c2c4e1e0c",
          "title": "BigQuery Explained Series",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Appliquez le partitionnement et clustering sur vos tables les plus utilisées. Analysez les coûts de vos requêtes.",
        "2→3": "Concevez un data warehouse avec des couches distinctes (raw, staging, mart). Implémentez des strategies de slot reservation.",
        "3→4": "Explorez BigQuery ML et le streaming. Optimisez les coûts à l'échelle de l'organisation."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "kubernetes",
      "name": "Kubernetes (K8s)",
      "description": "Orchestration de conteneurs pour déployer les applications",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance K8s",
        "1": "Comprend les conteneurs et concepts K8s de base",
        "2": "Peut déployer des applications, écrire des manifests basiques",
        "3": "Conçoit des architectures K8s, résout les problèmes",
        "4": "Expert en patterns K8s, scaling et optimisation",
        "5": "Architecte K8s, certifié CKA/CKAD",
        "6": "Contributeur Kubernetes, speaker KubeCon"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un conteneur Docker",
          "Je connais les concepts Pod, Service, Deployment",
          "Je peux utiliser kubectl pour des opérations basiques"
        ],
        "2": [
          "J'écris des manifests YAML pour déployer des apps",
          "Je configure les ConfigMaps et Secrets",
          "Je comprends les services et l'exposition des apps",
          "J'ai déployé une application sur un cluster"
        ],
        "3": [
          "Je configure le scaling automatique (HPA)",
          "Je debug les problèmes de pods et deployments",
          "J'utilise les PersistentVolumes pour le stockage",
          "Je configure les health checks et readiness probes"
        ],
        "4": [
          "Je conçois des architectures K8s production-ready",
          "J'ai une certification CKA ou CKAD",
          "J'optimise les ressources et les coûts",
          "Je forme les équipes au déploiement K8s"
        ],
        "5": [
          "Je définis la stratégie Kubernetes de l'organisation",
          "Je suis le référent pour les architectures K8s complexes",
          "Je mentor les équipes sur les patterns K8s avancés",
          "J'établis les standards de sécurité et de déploiement"
        ],
        "6": [
          "Je contribue au projet Kubernetes ou aux projets CNCF",
          "Je suis speaker à KubeCon ou autres conférences cloud-native",
          "Je suis reconnu comme expert Kubernetes dans la communauté",
          "Je publie des articles ou maintiens des projets K8s open-source"
        ]
      },
      "resources": [
        {
          "url": "https://kubernetes.io/docs/tutorials/",
          "title": "Kubernetes Official Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://www.katacoda.com/courses/kubernetes",
          "title": "Kubernetes Interactive Learning",
          "type": "tutorial"
        },
        {
          "url": "https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/",
          "title": "CKA Certification",
          "type": "course"
        },
        {
          "url": "https://learnk8s.io/",
          "title": "Learn Kubernetes",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Déployez une application simple sur un cluster K8s. Écrivez vos premiers manifests YAML.",
        "2→3": "Gérez les ConfigMaps, Secrets et les services. Implémentez le scaling automatique.",
        "3→4": "Passez la certification CKA ou CKAD. Concevez une architecture K8s production-ready."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "vertex_ai",
      "name": "Vertex AI",
      "description": "Utiliser GCP Vertex AI pour les workflows ML (training, serving, endpoints)",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Vertex AI",
        "1": "Comprend les composants et cas d'usage",
        "2": "Utilise AutoML et pipelines de training basiques",
        "3": "Conçoit des pipelines de training custom, gère le model registry",
        "4": "Expert en architecture Vertex AI et patterns MLOps",
        "5": "Architecte MLOps GCP, certifié ML Engineer",
        "6": "Expert Vertex AI reconnu, speaker Google"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les composants de Vertex AI",
          "Je comprends la différence entre AutoML et custom training",
          "Je sais ce qu'est un endpoint de prédiction"
        ],
        "2": [
          "J'ai entraîné un modèle avec AutoML",
          "J'ai déployé un modèle sur un endpoint",
          "J'utilise Vertex AI Workbench pour le dev",
          "Je comprends le feature store"
        ],
        "3": [
          "Je crée des pipelines de training custom",
          "J'utilise le Model Registry pour versionner",
          "Je configure le monitoring des modèles",
          "J'ai mis en place un workflow MLOps complet"
        ],
        "4": [
          "Je conçois l'architecture MLOps de l'organisation",
          "J'ai une certification GCP ML Engineer",
          "J'optimise les coûts de training et serving",
          "Je forme les data scientists à Vertex AI"
        ],
        "5": [
          "Je définis la stratégie MLOps et Vertex AI de l'organisation",
          "Je suis le référent pour les architectures ML complexes sur GCP",
          "Je mentor les équipes sur les patterns Vertex AI avancés",
          "J'établis les standards de déploiement et de monitoring ML"
        ],
        "6": [
          "Je suis speaker aux événements Google Cloud sur le ML",
          "Je contribue aux discussions communautaires Vertex AI",
          "Je publie des articles ou études de cas sur MLOps avec Vertex AI",
          "Je suis reconnu comme expert Vertex AI dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/vertex-ai/docs",
          "title": "Vertex AI Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.cloudskillsboost.google/paths/17",
          "title": "ML Engineer Learning Path",
          "type": "course"
        },
        {
          "url": "https://github.com/GoogleCloudPlatform/vertex-ai-samples",
          "title": "Vertex AI Samples",
          "type": "tutorial"
        },
        {
          "url": "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning",
          "title": "MLOps Architecture Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un modèle avec AutoML. Déployez-le sur un endpoint.",
        "2→3": "Construisez un pipeline de training custom. Utilisez le Model Registry pour versioner.",
        "3→4": "Implémentez un workflow MLOps complet. Passez la certification ML Engineer."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "clickhouse",
      "name": "ClickHouse",
      "description": "Utiliser ClickHouse pour les workloads analytiques (exports, optimisation)",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance ClickHouse",
        "1": "Comprend les cas d'usage et requêtes basiques",
        "2": "Conçoit des tables, optimise les requêtes pour ClickHouse",
        "3": "Architecte des clusters ClickHouse, gère les performances",
        "4": "Expert en internals ClickHouse et optimisation",
        "5": "Référent ClickHouse de l'organisation",
        "6": "Contributeur ClickHouse, speaker ClickHouse meetups"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends pourquoi utiliser ClickHouse vs PostgreSQL",
          "Je peux exécuter des requêtes basiques",
          "Je connais les cas d'usage analytiques"
        ],
        "2": [
          "Je crée des tables avec les bons engines (MergeTree)",
          "J'optimise mes requêtes pour ClickHouse",
          "Je comprends l'importance de l'ordre des colonnes",
          "J'utilise les materialized views"
        ],
        "3": [
          "Je configure un cluster ClickHouse",
          "J'optimise les performances pour les gros volumes",
          "Je gère la réplication et le sharding",
          "Je monitore les performances du cluster"
        ],
        "4": [
          "Je comprends les internals de ClickHouse",
          "J'optimise les settings pour des cas spécifiques",
          "Je forme les équipes à ClickHouse",
          "Je contribue à la communauté ClickHouse"
        ],
        "5": [
          "Je définis la stratégie ClickHouse de l'organisation",
          "Je suis le référent pour les architectures analytiques ClickHouse",
          "Je mentor les équipes sur les patterns ClickHouse avancés",
          "J'établis les standards de performance et d'optimisation"
        ],
        "6": [
          "Je contribue au code source de ClickHouse",
          "Je suis speaker aux ClickHouse meetups ou conférences",
          "Je suis reconnu comme expert ClickHouse dans la communauté",
          "Je publie des articles ou études de cas sur ClickHouse"
        ]
      },
      "resources": [
        {
          "url": "https://clickhouse.com/docs/en/",
          "title": "ClickHouse Documentation",
          "type": "documentation"
        },
        {
          "url": "https://clickhouse.com/learn",
          "title": "ClickHouse Academy",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/c/ClickHouseDB",
          "title": "ClickHouse YouTube",
          "type": "video"
        },
        {
          "url": "https://clickhouse.com/blog",
          "title": "ClickHouse Blog",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez des tables avec les bons engines (MergeTree). Optimisez vos premières requêtes.",
        "2→3": "Concevez un schéma optimisé pour vos workloads analytiques. Implémentez les materialized views.",
        "3→4": "Gérez un cluster ClickHouse en production. Contribuez aux meetups."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "airflow",
      "name": "Apache Airflow",
      "description": "Orchestration de workflows avec Airflow (DAGs, operators, hooks, sensors)",
      "core_roles": [
        "data_engineer",
        "analytics_eng",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Airflow",
        "1": "Comprend les DAGs, peut lire les workflows existants",
        "2": "Peut écrire des DAGs, gérer les dépendances et scheduling",
        "3": "Conçoit des workflows complexes, implémente des operators custom",
        "4": "Expert en architecture Airflow, scaling et bonnes pratiques",
        "5": "Référent Airflow, définit les standards de l'organisation",
        "6": "Contributeur Apache Airflow, speaker Airflow Summit"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans l'UI Airflow et comprends les états des tasks",
          "Je sais lire un DAG existant et comprendre ses dépendances",
          "Je peux relancer manuellement un DAG ou une task",
          "Je comprends la notion de schedule et de catchup"
        ],
        "2": [
          "J'écris des DAGs avec plusieurs tasks et dépendances",
          "J'utilise les operators standards (PythonOperator, BashOperator)",
          "Je configure le scheduling avec des cron expressions",
          "J'utilise les templates Jinja pour les paramètres dynamiques",
          "Je gère les XComs pour passer des données entre tasks"
        ],
        "3": [
          "Je crée des DAGs dynamiques avec des factories",
          "J'implémente les patterns de retry et alerting",
          "J'utilise les sensors pour les dépendances externes",
          "Je configure les pools et priorités",
          "J'ai créé des operators custom pour des besoins spécifiques"
        ],
        "4": [
          "J'optimise les performances d'Airflow à l'échelle",
          "Je configure les executors (Celery, Kubernetes)",
          "Je définis les conventions Airflow de l'équipe",
          "Je forme les équipes aux bonnes pratiques"
        ],
        "5": [
          "Je définis la stratégie Airflow de l'organisation",
          "Je suis le référent pour les architectures de workflows complexes",
          "Je mentor les équipes sur les patterns Airflow avancés",
          "J'établis les standards de qualité et de monitoring des DAGs"
        ],
        "6": [
          "Je contribue au code source d'Apache Airflow",
          "Je suis speaker à Airflow Summit ou conférences data engineering",
          "Je suis reconnu comme expert Airflow dans la communauté",
          "Je publie des articles ou maintiens des providers Airflow"
        ]
      },
      "resources": [
        {
          "url": "https://airflow.apache.org/docs/",
          "title": "Apache Airflow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.astronomer.io/guides/",
          "title": "Astronomer Guides",
          "type": "tutorial"
        },
        {
          "url": "https://academy.astronomer.io/",
          "title": "Astronomer Academy",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/playlist?list=PLYizQ5FvN6pvIOcOd6dFZu3lQqc6zBGp2",
          "title": "Airflow YouTube Tutorials",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Écrivez votre premier DAG avec plusieurs tasks et dépendances. Utilisez les templates Jinja.",
        "2→3": "Créez un operator custom pour un use case spécifique. Implémentez les patterns de retry et alerting.",
        "3→4": "Optimisez les performances d'Airflow à l'échelle. Contribuez aux discussions de la communauté."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "airflow_custom_operators",
      "name": "Airflow Custom Operators",
      "description": "Développer des operators, hooks et sensors custom pour Airflow",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des extensions Airflow",
        "1": "Comprend le fonctionnement des operators, hooks, sensors",
        "2": "Peut modifier des operators existants pour des besoins spécifiques",
        "3": "Développe des operators custom robustes et réutilisables",
        "4": "Expert en patterns d'extension Airflow, plugins",
        "5": "Architecte plugins Airflow",
        "6": "Contributeur Airflow providers"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends la différence entre operator, hook et sensor",
          "Je connais les operators standards",
          "Je peux lire le code d'un operator existant"
        ],
        "2": [
          "J'ai modifié un operator pour un besoin spécifique",
          "Je comprends l'héritage de BaseOperator",
          "J'utilise les hooks pour les connexions externes",
          "Je crée des sensors pour les dépendances"
        ],
        "3": [
          "J'ai développé des operators custom documentés et testés",
          "Je crée des plugins Airflow réutilisables",
          "Je gère les connexions et credentials proprement",
          "J'ai publié des operators dans un registry interne"
        ],
        "4": [
          "J'ai contribué à un provider Airflow",
          "Je définis les patterns d'extension pour l'équipe",
          "Je forme les développeurs aux custom operators",
          "J'ai conçu l'architecture des plugins"
        ],
        "5": [
          "Je définis la stratégie de plugins Airflow de l'organisation",
          "Je suis le référent pour les architectures d'extension Airflow",
          "Je mentor les équipes sur le développement d'operators avancés",
          "J'établis les standards de qualité et de réutilisabilité des plugins"
        ],
        "6": [
          "Je contribue aux providers Apache Airflow officiels",
          "Je suis reconnu comme expert en extensibilité Airflow",
          "Je publie des providers open-source populaires",
          "Je donne des conférences sur le développement de plugins Airflow"
        ]
      },
      "resources": [
        {
          "url": "https://airflow.apache.org/docs/apache-airflow/stable/howto/custom-operator.html",
          "title": "Custom Operators Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.astronomer.io/guides/airflow-components/",
          "title": "Airflow Components Guide",
          "type": "tutorial"
        },
        {
          "url": "https://github.com/apache/airflow/tree/main/airflow/providers",
          "title": "Airflow Providers Source Code",
          "type": "documentation"
        },
        {
          "url": "https://registry.astronomer.io/",
          "title": "Astronomer Registry",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Étudiez le code source des operators existants. Modifiez-en un pour ajouter une fonctionnalité.",
        "2→3": "Créez un operator custom documenté et testé. Publiez-le dans votre registry interne.",
        "3→4": "Contribuez un provider à la communauté Apache Airflow. Partagez vos patterns en conférence."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "python_data",
      "name": "Python (Data)",
      "description": "Programmation Python pour le data (pandas, numpy, pyarrow)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          2,
          3,
          4,
          4
        ],
        "data_scientist": [
          2,
          3,
          4,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Python",
        "1": "Peut écrire des scripts basiques, utilise pandas simplement",
        "2": "Écrit du code propre, utilise pandas/numpy efficacement",
        "3": "Construit des pipelines de données, gère les transformations complexes",
        "4": "Expert Python, écrit du code maintenable et scalable",
        "5": "Référent Python, définit les standards de code",
        "6": "Contributeur open-source Python data ecosystem"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux lire un CSV avec pandas et faire des filtres basiques",
          "J'utilise des boucles for et des conditions if/else",
          "Je sais créer des fonctions simples",
          "Je cherche souvent la syntaxe sur Stack Overflow"
        ],
        "2": [
          "J'utilise groupby, merge, pivot_table couramment",
          "Je structure mon code en fonctions réutilisables",
          "Je gère les types de données (datetime, categorical, etc.)",
          "J'écris des list/dict comprehensions",
          "Je sais utiliser numpy pour les opérations vectorisées"
        ],
        "3": [
          "Je construis des pipelines de transformation modulaires",
          "J'utilise pyarrow/polars pour les gros volumes",
          "Je crée des packages Python avec setup.py/pyproject.toml",
          "J'écris des tests unitaires pour mon code",
          "J'utilise les type hints et la validation Pydantic"
        ],
        "4": [
          "Je fais des code reviews Python pour l'équipe",
          "J'ai défini les standards Python du projet",
          "Je maîtrise les patterns avancés (decorators, context managers)",
          "J'optimise les performances (profiling, memory)"
        ],
        "5": [
          "Je définis les standards Python de l'organisation",
          "Je suis le référent pour les décisions d'architecture Python",
          "Je mentor les équipes sur les patterns Python avancés",
          "J'établis les conventions de code et les bonnes pratiques"
        ],
        "6": [
          "Je contribue activement à des projets open-source (pandas, numpy, polars)",
          "Je suis speaker à PyCon ou autres conférences Python",
          "Je suis reconnu dans la communauté Python data",
          "Je publie des articles ou packages Python populaires"
        ]
      },
      "resources": [
        {
          "url": "https://docs.python.org/3/tutorial/",
          "title": "Python Official Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://pandas.pydata.org/docs/getting_started/intro_tutorials/",
          "title": "Pandas Getting Started",
          "type": "tutorial"
        },
        {
          "url": "https://www.coursera.org/specializations/python",
          "title": "Python for Everybody (Coursera)",
          "type": "course"
        },
        {
          "url": "https://realpython.com/",
          "title": "Real Python Tutorials",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez les opérations pandas avancées (groupby, merge, pivot). Écrivez du code avec des fonctions réutilisables.",
        "2→3": "Maîtrisez les patterns de data pipelines. Apprenez pyarrow pour les gros volumes.",
        "3→4": "Contribuez aux standards de code de l'équipe. Écrivez des packages Python internes documentés."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "python_backend",
      "name": "Python (Backend/API)",
      "description": "Programmation Python pour backend/APIs (FastAPI, Flask)",
      "core_roles": [
        "backend",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance backend Python",
        "1": "Comprend les APIs REST, peut faire des appels API",
        "2": "Peut construire des APIs simples avec FastAPI/Flask",
        "3": "Conçoit des APIs scalables, implémente auth, caching",
        "4": "Expert en architecture backend Python",
        "5": "Architecte API de l'organisation",
        "6": "Contributeur FastAPI/frameworks, speaker PyCon"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts REST (GET, POST, PUT, DELETE)",
          "Je peux faire des appels API avec requests",
          "Je comprends les codes HTTP et le format JSON"
        ],
        "2": [
          "J'ai créé une API CRUD avec FastAPI",
          "J'utilise Pydantic pour la validation",
          "Je gère les erreurs avec des exceptions HTTP",
          "Je documente mes APIs avec OpenAPI/Swagger"
        ],
        "3": [
          "J'implémente l'authentification (JWT, OAuth)",
          "J'utilise le caching (Redis) pour les performances",
          "Je structure mes projets avec une architecture clean",
          "Je gère les transactions et la concurrence"
        ],
        "4": [
          "Je conçois l'architecture API de l'organisation",
          "J'implémente le rate limiting et la sécurité",
          "Je mets en place le monitoring des APIs",
          "Je forme les équipes aux bonnes pratiques"
        ],
        "5": [
          "Je définis la stratégie API de l'organisation",
          "Je suis le référent pour les décisions d'architecture backend",
          "Je mentor les équipes sur les patterns API avancés",
          "J'établis les standards de sécurité et de performance"
        ],
        "6": [
          "Je contribue activement à FastAPI ou autres frameworks Python",
          "Je suis speaker à PyCon ou conférences API",
          "Je suis reconnu dans la communauté Python backend",
          "Je publie des articles ou maintiens des projets open-source"
        ]
      },
      "resources": [
        {
          "url": "https://fastapi.tiangolo.com/tutorial/",
          "title": "FastAPI Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://testdriven.io/courses/tdd-fastapi/",
          "title": "Test-Driven Development with FastAPI",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/watch?v=0sOvCWFmrtA",
          "title": "FastAPI Full Course",
          "type": "video"
        },
        {
          "url": "https://12factor.net/",
          "title": "The Twelve-Factor App",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez une API CRUD simple avec FastAPI. Apprenez la validation Pydantic.",
        "2→3": "Implémentez l'authentification et la gestion des erreurs. Ajoutez du caching avec Redis.",
        "3→4": "Concevez une architecture API complète. Implémentez le monitoring et les métriques de performance."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "rest_api_integration",
      "name": "Intégration API REST",
      "description": "Consommer et construire des APIs REST (pagination, auth, gestion erreurs)",
      "core_roles": [
        "data_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance API",
        "1": "Peut faire des appels API basiques, comprend JSON",
        "2": "Gère l'authentification, pagination et gestion d'erreurs",
        "3": "Conçoit des intégrations API efficaces, gère les scénarios complexes",
        "4": "Expert en design et patterns d'intégration API",
        "5": "Définit les standards API de l'organisation",
        "6": "Expert API design reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je fais des appels GET avec requests ou curl",
          "Je comprends le format JSON",
          "Je peux lire la documentation d'une API"
        ],
        "2": [
          "Je gère l'authentification (API keys, tokens)",
          "J'implémente la pagination pour récupérer toutes les données",
          "Je gère les erreurs HTTP correctement",
          "J'utilise les headers appropriés"
        ],
        "3": [
          "Je crée des clients API robustes avec retry",
          "Je gère le rate limiting et les backoffs",
          "Je documente mes intégrations avec OpenAPI",
          "J'ai intégré plusieurs APIs externes"
        ],
        "4": [
          "Je définis les standards d'intégration API",
          "Je conçois des patterns réutilisables",
          "Je gère les scénarios complexes (webhooks, streaming)",
          "Je forme les équipes aux bonnes pratiques"
        ],
        "5": [
          "Je définis la stratégie d'intégration API de l'organisation",
          "Je suis le référent pour les architectures d'intégration",
          "Je mentor les équipes sur les patterns d'intégration avancés",
          "J'établis les standards de robustesse et de résilience"
        ],
        "6": [
          "Je suis reconnu comme expert en API design dans l'industrie",
          "Je publie des articles ou livres sur l'intégration API",
          "Je donne des conférences sur les patterns d'intégration",
          "Je contribue aux standards et spécifications API (OpenAPI, AsyncAPI)"
        ]
      },
      "resources": [
        {
          "url": "https://restfulapi.net/",
          "title": "REST API Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://swagger.io/specification/",
          "title": "OpenAPI Specification",
          "type": "documentation"
        },
        {
          "url": "https://httpstatuses.com/",
          "title": "HTTP Status Codes Reference",
          "type": "documentation"
        },
        {
          "url": "https://www.postman.com/api-platform/api-design/",
          "title": "API Design Guide (Postman)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Intégrez une API externe avec authentification. Implémentez la gestion de pagination.",
        "2→3": "Créez un client API robuste avec retry et error handling. Documentez avec OpenAPI.",
        "3→4": "Définissez les standards d'API de votre équipe. Implémentez une gateway API."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "etl_connectors",
      "name": "Connecteurs ETL",
      "description": "Développer des connecteurs vers des sources externes (APIs SaaS, fichiers)",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance ETL",
        "1": "Comprend les patterns d'extraction de données",
        "2": "Peut développer des connecteurs basiques vers des APIs",
        "3": "Conçoit des connecteurs robustes avec retry, error handling",
        "4": "Expert en patterns de connecteurs, gestion des états",
        "5": "Architecte intégration de l'organisation",
        "6": "Contributeur Singer/Airbyte, expert ETL reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le pattern Extract-Transform-Load",
          "Je sais ce qu'est un connecteur de données",
          "Je peux extraire des données d'un fichier CSV/JSON"
        ],
        "2": [
          "J'ai développé un connecteur vers une API SaaS",
          "Je gère la pagination et les erreurs",
          "Je configure Airbyte ou Fivetran pour une source",
          "J'extrais des données incrémentales"
        ],
        "3": [
          "Je crée des connecteurs avec retry et backoff",
          "Je gère l'état pour les extractions incrémentales",
          "J'ai développé des connecteurs custom robustes",
          "Je documente et teste mes connecteurs"
        ],
        "4": [
          "J'ai créé un framework de connecteurs réutilisable",
          "Je contribue à Airbyte ou Singer",
          "Je définis les patterns de connecteurs de l'organisation",
          "Je forme les équipes au développement de connecteurs"
        ],
        "5": [
          "Je définis la stratégie d'intégration de données de l'organisation",
          "Je suis le référent pour les architectures de connecteurs",
          "Je mentor les équipes sur les patterns ETL avancés",
          "J'établis les standards de qualité et de robustesse des connecteurs"
        ],
        "6": [
          "Je contribue activement à Airbyte, Singer ou Fivetran",
          "Je suis reconnu comme expert ETL dans la communauté",
          "Je publie des connecteurs open-source populaires",
          "Je donne des conférences sur l'intégration de données"
        ]
      },
      "resources": [
        {
          "url": "https://airbyte.com/blog/data-extraction-complete-guide",
          "title": "Data Extraction Complete Guide",
          "type": "tutorial"
        },
        {
          "url": "https://www.singer.io/",
          "title": "Singer - Open Source ETL",
          "type": "documentation"
        },
        {
          "url": "https://docs.airbyte.com/connector-development/",
          "title": "Airbyte Connector Development",
          "type": "documentation"
        },
        {
          "url": "https://www.getdbt.com/analytics-engineering/modular-data-modeling-technique/",
          "title": "Modular Data Modeling",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Développez un connecteur simple vers une API SaaS. Gérez la pagination et les erreurs.",
        "2→3": "Ajoutez la gestion d'état et les reprises après échec. Implémentez l'extraction incrémentale.",
        "3→4": "Contribuez à Airbyte ou Singer. Créez un framework de connecteurs réutilisable."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "recommendation_systems",
      "name": "Systèmes de Recommandation",
      "description": "Concevoir et implémenter des systèmes de recommandation (collaborative, content-based, two-tower)",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des systèmes de recommandation",
        "1": "Comprend les types de systèmes de recommandation",
        "2": "Peut implémenter des recos basiques (collaborative filtering)",
        "3": "Conçoit des systèmes two-tower et recos hybrides",
        "4": "Expert en architectures de recommandation avancées",
        "5": "Architecte recommandation de l'organisation",
        "6": "Expert RecSys reconnu, publications, speaker RecSys"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais la différence entre collaborative et content-based filtering",
          "Je comprends le problème du cold start",
          "Je sais ce qu'est une matrice user-item"
        ],
        "2": [
          "J'ai implémenté un collaborative filtering basique",
          "Je calcule les métriques de recommandation (precision, recall, MRR)",
          "Je comprends les factorisations matricielles",
          "J'utilise des bibliothèques comme Surprise ou implicit"
        ],
        "3": [
          "J'ai conçu un système two-tower avec embeddings",
          "Je combine plusieurs signaux (collaborative + content)",
          "Je gère le ranking et la diversité des recommandations",
          "J'ai déployé un système de recommandation en production"
        ],
        "4": [
          "J'ai conçu l'architecture de recommandation de l'organisation",
          "Je gère le serving temps réel des recommandations",
          "Je mesure l'impact business des recommandations",
          "Je forme les équipes aux systèmes de recommandation"
        ],
        "5": [
          "Je définis les standards et patterns de recommandation pour l'organisation",
          "Je suis la référence interne pour les architectures RecSys",
          "Je mentore les équipes sur les systèmes de recommandation avancés",
          "J'ai mis en place la roadmap technique RecSys de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences RecSys ou similaires",
          "J'ai publié des articles ou papers sur les systèmes de recommandation",
          "Je contribue à des projets open-source dans le domaine RecSys",
          "Je suis reconnu comme expert externe et sollicité par d'autres entreprises"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/specializations/recommender-systems",
          "title": "Recommender Systems Specialization (Coursera)",
          "type": "course"
        },
        {
          "url": "https://developers.google.com/machine-learning/recommendation",
          "title": "Google ML Recommendations",
          "type": "tutorial"
        },
        {
          "url": "https://arxiv.org/abs/1905.01395",
          "title": "Two-Tower Models Paper",
          "type": "documentation"
        },
        {
          "url": "https://eugeneyan.com/writing/system-design-for-discovery/",
          "title": "System Design for Discovery",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez un système de collaborative filtering simple. Comprenez les métriques (MRR, NDCG).",
        "2→3": "Construisez un système two-tower avec des embeddings. Combinez plusieurs signaux.",
        "3→4": "Concevez un système de recommandation à l'échelle. Publiez vos learnings."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "embeddings",
      "name": "Embeddings & Retrieval Vectoriel",
      "description": "Générer des embeddings et implémenter la recherche sémantique",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des embeddings",
        "1": "Comprend les concepts de vecteurs et similarité",
        "2": "Peut générer des embeddings avec des modèles pré-entraînés",
        "3": "Conçoit des pipelines d'embeddings et retrieval vectoriel",
        "4": "Expert en architectures d'embeddings et vector stores",
        "5": "Architecte search/embeddings de l'organisation",
        "6": "Expert vector search reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un vecteur et la similarité cosine",
          "Je sais ce qu'est un embedding et son utilité",
          "Je connais des applications (recherche sémantique, recommandation)"
        ],
        "2": [
          "J'utilise des modèles pré-entraînés (Sentence-BERT, OpenAI)",
          "J'ai implémenté une recherche par similarité",
          "Je comprends les métriques de distance",
          "J'utilise une base vectorielle (Pinecone, Qdrant)"
        ],
        "3": [
          "Je conçois des pipelines d'embeddings à l'échelle",
          "Je fine-tune des modèles d'embeddings",
          "J'optimise les performances de retrieval",
          "J'ai déployé une recherche sémantique en production"
        ],
        "4": [
          "J'ai conçu l'architecture de recherche vectorielle",
          "Je gère des milliards d'embeddings",
          "J'optimise les coûts et latences",
          "Je forme les équipes aux embeddings"
        ],
        "5": [
          "Je définis la stratégie embeddings et vector search de l'organisation",
          "Je suis la référence interne pour les architectures de retrieval",
          "Je mentore les équipes sur les systèmes de recherche sémantique",
          "J'ai établi les bonnes pratiques d'indexation vectorielle à l'échelle"
        ],
        "6": [
          "Je suis speaker à des conférences sur le vector search ou les embeddings",
          "J'ai publié des articles ou papers sur le retrieval vectoriel",
          "Je contribue à des projets open-source (Qdrant, Milvus, FAISS)",
          "Je suis reconnu comme expert externe en recherche sémantique"
        ]
      },
      "resources": [
        {
          "url": "https://www.pinecone.io/learn/",
          "title": "Pinecone Learning Center",
          "type": "tutorial"
        },
        {
          "url": "https://huggingface.co/learn/nlp-course/chapter5/5",
          "title": "HuggingFace Embeddings",
          "type": "tutorial"
        },
        {
          "url": "https://www.sbert.net/",
          "title": "Sentence Transformers",
          "type": "documentation"
        },
        {
          "url": "https://qdrant.tech/articles/",
          "title": "Qdrant Vector Search Articles",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Utilisez des modèles pré-entraînés pour générer des embeddings. Implémentez une recherche par similarité.",
        "2→3": "Construisez un pipeline d'embeddings avec un vector store. Fine-tunez un modèle pour votre domaine.",
        "3→4": "Optimisez les performances à grande échelle. Contribuez à la communauté vector search."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "deep_learning",
      "name": "TensorFlow/PyTorch",
      "description": "Utiliser les frameworks de deep learning",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance DL",
        "1": "Comprend les concepts de base, peut exécuter des modèles existants",
        "2": "Peut construire et entraîner des réseaux de neurones basiques",
        "3": "Conçoit des architectures custom, optimise le training",
        "4": "Expert en frameworks DL, peut construire des systèmes complexes",
        "5": "Architecte DL de l'organisation",
        "6": "Contributeur TensorFlow/PyTorch, publications NeurIPS/ICML"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts de neurones, layers, activation",
          "Je peux exécuter un modèle pré-entraîné",
          "Je connais la différence entre PyTorch et TensorFlow"
        ],
        "2": [
          "J'ai entraîné un CNN ou RNN de base",
          "Je comprends la backpropagation et les optimizers",
          "J'utilise les dataloaders et augmentation",
          "Je peux fine-tuner un modèle pré-entraîné"
        ],
        "3": [
          "Je conçois des architectures custom pour un problème",
          "J'optimise le training (learning rate scheduling, regularization)",
          "J'utilise le training distribué (multi-GPU)",
          "J'ai déployé un modèle DL en production"
        ],
        "4": [
          "Je maîtrise les architectures avancées (Transformers, etc.)",
          "J'optimise les performances de training à l'échelle",
          "Je contribue à la recherche DL",
          "Je forme les équipes au deep learning"
        ],
        "5": [
          "Je définis les standards et patterns deep learning de l'organisation",
          "Je suis la référence interne pour les architectures DL complexes",
          "Je mentore les équipes sur les techniques de training avancées",
          "J'ai mis en place l'infrastructure de training à l'échelle"
        ],
        "6": [
          "Je suis speaker à des conférences NeurIPS, ICML ou similaires",
          "J'ai publié des papers de recherche en deep learning",
          "Je contribue aux frameworks TensorFlow ou PyTorch",
          "Je suis reconnu comme expert externe en deep learning"
        ]
      },
      "resources": [
        {
          "url": "https://www.deeplearning.ai/",
          "title": "DeepLearning.AI Courses",
          "type": "course"
        },
        {
          "url": "https://pytorch.org/tutorials/",
          "title": "PyTorch Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://www.tensorflow.org/tutorials",
          "title": "TensorFlow Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://d2l.ai/",
          "title": "Dive into Deep Learning",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Suivez le cours DeepLearning.AI. Implémentez un CNN et un RNN de base.",
        "2→3": "Construisez une architecture custom. Maîtrisez les techniques d'optimisation.",
        "3→4": "Contribuez à un framework. Publiez vos recherches."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "mlflow",
      "name": "MLFlow & Experiment Tracking",
      "description": "Tracking des expériences ML et gestion des modèles",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance MLFlow",
        "1": "Comprend les concepts MLFlow, peut voir les expériences",
        "2": "Peut logger des expériences, tracker les métriques, enregistrer des modèles",
        "3": "Conçoit des workflows MLFlow, intègre avec les pipelines",
        "4": "Expert en architecture MLFlow et MLOps",
        "5": "Architecte MLOps de l'organisation",
        "6": "Expert MLOps reconnu, contributeur open-source"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans l'UI MLFlow",
          "Je comprends les concepts d'experiment et run",
          "Je peux comparer des runs dans l'interface"
        ],
        "2": [
          "Je logue les paramètres, métriques et artefacts",
          "J'enregistre des modèles dans le Model Registry",
          "J'utilise mlflow.autolog() pour le tracking automatique",
          "Je compare les performances de plusieurs runs"
        ],
        "3": [
          "J'intègre MLFlow dans les pipelines de training",
          "Je configure le Model Registry avec stages (dev/staging/prod)",
          "J'utilise MLFlow Projects pour la reproductibilité",
          "J'automatise la promotion des modèles"
        ],
        "4": [
          "J'ai conçu l'architecture MLOps de l'organisation",
          "J'intègre MLFlow avec le CI/CD",
          "Je configure le serving de modèles",
          "Je forme les équipes aux bonnes pratiques"
        ],
        "5": [
          "Je définis les standards MLOps et experiment tracking de l'organisation",
          "Je suis la référence interne pour l'architecture MLFlow",
          "Je mentore les équipes sur les workflows ML en production",
          "J'ai mis en place la gouvernance des modèles ML"
        ],
        "6": [
          "Je suis speaker à des conférences MLOps ou ML Platform",
          "Je contribue au projet MLFlow ou outils similaires",
          "J'ai publié des articles sur les bonnes pratiques MLOps",
          "Je suis reconnu comme expert externe en ML lifecycle management"
        ]
      },
      "resources": [
        {
          "url": "https://mlflow.org/docs/latest/index.html",
          "title": "MLFlow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.databricks.com/blog/2020/04/15/databricks-mlflow-2-0.html",
          "title": "MLFlow Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://madewithml.com/courses/mlops/",
          "title": "Made with ML - MLOps",
          "type": "course"
        },
        {
          "url": "https://neptune.ai/blog/mlflow-vs-other-tools",
          "title": "MLFlow vs Other Tools",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Loggez vos premières expériences avec MLFlow. Utilisez le Model Registry.",
        "2→3": "Intégrez MLFlow dans vos pipelines de training. Automatisez le versioning.",
        "3→4": "Concevez l'architecture MLOps de l'organisation. Partagez vos learnings."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "ml_deployment",
      "name": "Déploiement de Modèles ML",
      "description": "Déployer des modèles ML en production (APIs, conteneurs, endpoints)",
      "core_roles": [
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance déploiement ML",
        "1": "Comprend les concepts et défis du déploiement",
        "2": "Peut déployer des modèles avec des méthodes basiques (API, conteneurs)",
        "3": "Conçoit des systèmes ML production, gère scaling, monitoring",
        "4": "Expert en patterns de déploiement ML et infrastructure",
        "5": "Architecte ML production de l'organisation",
        "6": "Expert ML serving reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les défis du déploiement ML (latence, throughput)",
          "Je connais les options de déploiement (batch vs temps réel)",
          "Je sais ce qu'est un endpoint de prédiction"
        ],
        "2": [
          "J'ai déployé un modèle via une API FastAPI",
          "Je conteneurise mes modèles avec Docker",
          "Je gère la sérialisation des modèles (pickle, ONNX)",
          "Je configure des endpoints de prédiction basiques"
        ],
        "3": [
          "Je configure le scaling automatique des endpoints",
          "Je mets en place le monitoring des prédictions",
          "J'implémente le A/B testing de modèles",
          "Je gère le versioning et rollback des modèles"
        ],
        "4": [
          "J'ai conçu l'architecture de serving de l'organisation",
          "J'optimise les latences et throughput",
          "Je gère le serving de modèles à grande échelle",
          "Je forme les équipes au déploiement ML"
        ],
        "5": [
          "Je définis les standards de déploiement ML de l'organisation",
          "Je suis la référence interne pour les architectures ML serving",
          "Je mentore les équipes sur le ML en production",
          "J'ai mis en place la plateforme ML serving de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences ML Platform ou MLOps",
          "J'ai publié des articles sur le ML serving à grande échelle",
          "Je contribue à des projets open-source (Seldon, KServe, BentoML)",
          "Je suis reconnu comme expert externe en ML production"
        ]
      },
      "resources": [
        {
          "url": "https://www.oreilly.com/library/view/building-machine-learning/9781492045106/",
          "title": "Building ML Powered Applications",
          "type": "book"
        },
        {
          "url": "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning",
          "title": "Google MLOps Guide",
          "type": "documentation"
        },
        {
          "url": "https://ml-ops.org/",
          "title": "ML-Ops.org",
          "type": "documentation"
        },
        {
          "url": "https://www.seldon.io/what-is-ml-serving",
          "title": "ML Serving Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Déployez un modèle simple via une API FastAPI. Conteneurisez-le avec Docker.",
        "2→3": "Implémentez le monitoring et l'alerting. Gérez le scaling automatique.",
        "3→4": "Concevez une plateforme ML serving. Partagez vos patterns."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "feature_engineering",
      "name": "Feature Engineering",
      "description": "Créer des features efficaces pour les modèles ML (transformations, feature stores)",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance feature engineering",
        "1": "Comprend les types de features basiques et transformations",
        "2": "Peut créer des features, gérer les données catégoriques et numériques",
        "3": "Conçoit des pipelines de features, implémente des transformations avancées",
        "4": "Expert en feature engineering et feature stores",
        "5": "Architecte feature store de l'organisation",
        "6": "Expert feature engineering reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends la différence entre features numériques et catégoriques",
          "Je sais ce qu'est la normalisation et le scaling",
          "Je connais les encodages basiques (one-hot, label encoding)"
        ],
        "2": [
          "Je crée des features à partir de données temporelles",
          "Je gère les valeurs manquantes et outliers",
          "J'utilise les transformations (log, polynomial)",
          "J'applique la sélection de features"
        ],
        "3": [
          "Je crée des pipelines de features reproductibles",
          "J'utilise un feature store (Feast, Vertex Feature Store)",
          "Je gère le feature drift en production",
          "J'automatise le feature engineering"
        ],
        "4": [
          "J'ai conçu l'architecture du feature store",
          "Je gère des milliers de features à l'échelle",
          "J'optimise les performances de serving",
          "Je forme les équipes au feature engineering"
        ],
        "5": [
          "Je définis les standards de feature engineering de l'organisation",
          "Je suis la référence interne pour l'architecture feature store",
          "Je mentore les équipes sur la création de features avancées",
          "J'ai mis en place la gouvernance des features ML"
        ],
        "6": [
          "Je suis speaker à des conférences ML ou Feature Store Summit",
          "J'ai publié des articles sur le feature engineering à l'échelle",
          "Je contribue à des projets open-source (Feast, Feathr)",
          "Je suis reconnu comme expert externe en feature platforms"
        ]
      },
      "resources": [
        {
          "url": "https://www.featurestore.org/",
          "title": "Feature Store.org",
          "type": "documentation"
        },
        {
          "url": "https://www.kaggle.com/learn/feature-engineering",
          "title": "Feature Engineering (Kaggle)",
          "type": "course"
        },
        {
          "url": "https://feast.dev/",
          "title": "Feast Feature Store",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/",
          "title": "Feature Engineering for ML (O'Reilly)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez des features pour un projet Kaggle. Maîtrisez les encodages catégoriels.",
        "2→3": "Construisez un pipeline de features reproductible. Explorez les feature stores.",
        "3→4": "Implémentez un feature store pour l'organisation. Automatisez la feature discovery."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "entity_resolution",
      "name": "Entity Resolution & Linkage",
      "description": "Résoudre les entités et relier les données (déduplication, matching)",
      "core_roles": [
        "data_scientist",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance entity resolution",
        "1": "Comprend les problèmes de déduplication et matching",
        "2": "Peut implémenter des solutions de matching basiques",
        "3": "Conçoit des systèmes d'entity resolution à grande échelle",
        "4": "Expert en algorithmes d'entity resolution",
        "5": "Architecte MDM de l'organisation",
        "6": "Expert entity resolution reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le problème de déduplication de données",
          "Je connais les techniques de fuzzy matching",
          "Je sais ce qu'est le record linkage"
        ],
        "2": [
          "J'utilise des bibliothèques de fuzzy matching (fuzzywuzzy, rapidfuzz)",
          "J'implémente des règles de matching simples",
          "Je calcule des scores de similarité entre records",
          "J'ai dédupliqué un dataset de taille moyenne"
        ],
        "3": [
          "Je conçois des systèmes de matching à grande échelle",
          "J'utilise le blocking pour optimiser les performances",
          "J'implémente des modèles ML pour le matching",
          "J'ai géré un projet de déduplication complet"
        ],
        "4": [
          "J'ai conçu l'architecture MDM de l'organisation",
          "Je gère des millions de records à matcher",
          "J'optimise la précision et le recall du matching",
          "Je forme les équipes à l'entity resolution"
        ],
        "5": [
          "Je définis les standards MDM et entity resolution de l'organisation",
          "Je suis la référence interne pour les architectures de déduplication",
          "Je mentore les équipes sur les techniques de matching avancées",
          "J'ai mis en place la stratégie de qualité des données maître"
        ],
        "6": [
          "Je suis speaker à des conférences MDM ou Data Quality",
          "J'ai publié des articles sur l'entity resolution à l'échelle",
          "Je contribue à des projets open-source (dedupe, Zingg)",
          "Je suis reconnu comme expert externe en Master Data Management"
        ]
      },
      "resources": [
        {
          "url": "https://recordlinkage.readthedocs.io/",
          "title": "Python Record Linkage Toolkit",
          "type": "documentation"
        },
        {
          "url": "https://dedupe.io/",
          "title": "Dedupe.io",
          "type": "documentation"
        },
        {
          "url": "https://www.microsoft.com/en-us/research/publication/swoosh-a-generic-approach-to-entity-resolution/",
          "title": "Swoosh Paper (Microsoft)",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-quality-fundamentals/9781098112035/",
          "title": "Data Quality Fundamentals",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez une déduplication simple avec fuzzy matching. Utilisez dedupe.io.",
        "2→3": "Construisez un pipeline de matching à grande échelle. Combinez plusieurs techniques.",
        "3→4": "Concevez un système MDM pour l'organisation. Publiez vos algorithmes."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "git_github",
      "name": "Git & GitHub",
      "description": "Utiliser Git pour le contrôle de version (branches, merge, workflows)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Git",
        "1": "Peut cloner, pull, commit, push - opérations basiques",
        "2": "Travaille avec les branches, gère les merges, comprend les workflows",
        "3": "Résout les conflits complexes, conçoit des stratégies de branching",
        "4": "Expert Git, peut gérer tout scénario",
        "5": "Définit les conventions Git de l'organisation",
        "6": "Contributeur Git, expert reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je fais git clone, pull, commit, push au quotidien",
          "J'écris des messages de commit descriptifs",
          "Je sais voir l'historique avec git log",
          "J'utilise parfois git status pour vérifier mes changements"
        ],
        "2": [
          "Je crée et switch entre branches facilement",
          "Je fais des merge et comprends les conflits simples",
          "J'utilise git stash quand j'ai besoin de changer de contexte",
          "Je crée des Pull Requests et fais des code reviews",
          "Je comprends la différence entre merge et rebase"
        ],
        "3": [
          "Je résous des conflits de merge complexes",
          "J'utilise rebase -i pour nettoyer l'historique",
          "Je sais utiliser cherry-pick et bisect",
          "J'ai défini une stratégie de branching (GitFlow, trunk-based)",
          "Je forme les collègues sur Git"
        ],
        "4": [
          "Je peux récupérer d'erreurs Git complexes (reflog, reset)",
          "Je définis les conventions Git de l'équipe",
          "Je fais des revues de PR avec feedback constructif",
          "Je maîtrise les hooks et automatisations Git"
        ],
        "5": [
          "Je définis les conventions et workflows Git pour l'organisation",
          "Je suis la référence interne pour les problèmes Git complexes",
          "Je mentore les équipes sur les stratégies de branching",
          "J'ai mis en place les standards de code review"
        ],
        "6": [
          "Je suis speaker à des conférences Git ou DevOps",
          "Je contribue au projet Git ou outils associés",
          "J'ai publié des articles sur les workflows Git avancés",
          "Je suis reconnu comme expert externe en gestion de version"
        ]
      },
      "resources": [
        {
          "url": "https://learngitbranching.js.org/",
          "title": "Learn Git Branching (Interactive)",
          "type": "tutorial"
        },
        {
          "url": "https://www.atlassian.com/git/tutorials",
          "title": "Atlassian Git Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://ohshitgit.com/",
          "title": "Oh Shit, Git!?",
          "type": "tutorial"
        },
        {
          "url": "https://git-scm.com/book/en/v2",
          "title": "Pro Git Book",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez le branching et le merging. Utilisez Learn Git Branching pour pratiquer.",
        "2→3": "Maîtrisez rebase et cherry-pick. Résolvez des conflits complexes.",
        "3→4": "Définissez une stratégie de branching pour votre équipe. Formez les autres."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "github_actions",
      "name": "GitHub Actions",
      "description": "CI/CD avec GitHub Actions (workflows réutilisables, tests, déploiement)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance GitHub Actions",
        "1": "Comprend les concepts CI/CD, peut lire les workflows",
        "2": "Peut écrire des workflows basiques pour testing et déploiement",
        "3": "Conçoit des pipelines CI/CD complexes, fonctionnalités avancées",
        "4": "Expert en architecture GitHub Actions",
        "5": "Architecte CI/CD de l'organisation",
        "6": "Contributeur Actions community, expert DevOps reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts de CI/CD",
          "Je sais lire un fichier workflow.yml",
          "Je peux voir les logs d'un workflow"
        ],
        "2": [
          "J'écris des workflows pour lancer les tests",
          "J'utilise les actions du marketplace",
          "Je configure les triggers (push, PR, schedule)",
          "Je gère les secrets dans les workflows"
        ],
        "3": [
          "Je crée des workflows réutilisables",
          "J'utilise les matrix builds",
          "Je configure les environments et approvals",
          "J'optimise les temps de build avec le cache"
        ],
        "4": [
          "J'ai conçu l'architecture CI/CD de l'organisation",
          "Je crée des actions custom",
          "Je définis les standards de déploiement",
          "Je forme les équipes au CI/CD"
        ],
        "5": [
          "Je définis les standards CI/CD pour l'ensemble de l'organisation",
          "Je suis la référence interne pour les pipelines complexes",
          "Je mentore les équipes sur les stratégies de déploiement",
          "J'ai mis en place la plateforme CI/CD de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences DevOps ou CI/CD",
          "Je contribue au marketplace GitHub Actions",
          "J'ai publié des articles sur les pipelines CI/CD avancés",
          "Je suis reconnu comme expert externe en automatisation"
        ]
      },
      "resources": [
        {
          "url": "https://docs.github.com/en/actions",
          "title": "GitHub Actions Documentation",
          "type": "documentation"
        },
        {
          "url": "https://github.com/features/actions",
          "title": "GitHub Actions Features",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/watch?v=R8_veQiYBjI",
          "title": "GitHub Actions Tutorial",
          "type": "video"
        },
        {
          "url": "https://github.com/actions/starter-workflows",
          "title": "Starter Workflows",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un workflow de test simple. Utilisez les actions du marketplace.",
        "2→3": "Implémentez des workflows réutilisables. Utilisez les secrets et environments.",
        "3→4": "Optimisez les temps de build. Créez des actions custom."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "terraform",
      "name": "Terraform",
      "description": "Infrastructure as Code avec Terraform (GCP resources, modules, state)",
      "core_roles": [
        "data_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Terraform",
        "1": "Comprend les concepts IaC, peut lire les fichiers Terraform",
        "2": "Peut écrire des configurations Terraform basiques",
        "3": "Conçoit des architectures Terraform modulaires, gère le state",
        "4": "Expert en Terraform et patterns IaC",
        "5": "Architecte IaC, certifié Terraform Associate",
        "6": "Contributeur Terraform providers, expert HashiCorp reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts d'Infrastructure as Code",
          "Je sais lire un fichier .tf",
          "Je connais terraform plan et apply"
        ],
        "2": [
          "J'écris des configurations Terraform basiques",
          "Je crée des ressources GCP (buckets, datasets)",
          "Je comprends le state et son importance",
          "J'utilise les variables et outputs"
        ],
        "3": [
          "Je développe des modules réutilisables",
          "Je configure le state remote (GCS)",
          "J'utilise les workspaces pour les environments",
          "J'intègre Terraform dans le CI/CD"
        ],
        "4": [
          "J'ai conçu l'architecture IaC de l'organisation",
          "J'ai une certification Terraform",
          "Je forme les équipes à Terraform",
          "Je définis les standards et bonnes pratiques"
        ],
        "5": [
          "Je définis les standards IaC pour l'ensemble de l'organisation",
          "Je suis la référence interne pour les architectures Terraform",
          "Je mentore les équipes sur les patterns de modules avancés",
          "J'ai mis en place la plateforme IaC de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences HashiConf ou IaC",
          "Je contribue aux providers Terraform",
          "J'ai publié des articles sur l'Infrastructure as Code",
          "Je suis reconnu comme expert externe certifié HashiCorp"
        ]
      },
      "resources": [
        {
          "url": "https://developer.hashicorp.com/terraform/tutorials",
          "title": "HashiCorp Terraform Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://www.terraform.io/docs",
          "title": "Terraform Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.hashicorp.com/certification/terraform-associate",
          "title": "Terraform Associate Certification",
          "type": "course"
        },
        {
          "url": "https://spacelift.io/blog/terraform-best-practices",
          "title": "Terraform Best Practices",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez vos premières ressources GCP avec Terraform. Comprenez le state.",
        "2→3": "Développez des modules réutilisables. Implémentez la gestion du state remote.",
        "3→4": "Passez la certification Terraform Associate. Contribuez à un provider."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "docker",
      "name": "Docker & Conteneurisation",
      "description": "Conteneuriser les applications (Dockerfile, compose, multi-stage builds)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Docker",
        "1": "Comprend les concepts de conteneurs, peut exécuter des images",
        "2": "Peut écrire des Dockerfiles basiques, utiliser docker-compose",
        "3": "Conçoit des images optimisées, multi-stage builds",
        "4": "Expert en patterns de conteneurisation",
        "5": "Architecte conteneurisation de l'organisation",
        "6": "Expert Docker reconnu, contributeur community"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais lancer un conteneur avec docker run",
          "Je comprends la différence entre image et conteneur",
          "J'utilise docker ps et docker logs",
          "Je peux pull des images depuis Docker Hub"
        ],
        "2": [
          "J'écris des Dockerfiles fonctionnels",
          "J'utilise docker-compose pour plusieurs services",
          "Je sais construire et tag mes images",
          "Je gère les volumes pour la persistance",
          "J'expose et mappe les ports correctement"
        ],
        "3": [
          "J'utilise les multi-stage builds pour réduire la taille",
          "J'optimise le layer caching dans mes Dockerfiles",
          "Je configure les health checks",
          "Je gère les secrets et variables d'environnement",
          "J'utilise des images de base minimales (alpine, distroless)"
        ],
        "4": [
          "Je définis les standards Docker de l'équipe",
          "J'optimise les temps de build et la taille des images",
          "Je maîtrise les réseaux Docker et la sécurité",
          "Je forme les équipes aux bonnes pratiques"
        ],
        "5": [
          "Je définis les standards de conteneurisation pour l'organisation",
          "Je suis la référence interne pour les architectures Docker",
          "Je mentore les équipes sur les patterns de conteneurisation avancés",
          "J'ai mis en place le registry et les pipelines de build"
        ],
        "6": [
          "Je suis speaker à des conférences DockerCon ou Cloud Native",
          "Je contribue à Docker ou projets CNCF",
          "J'ai publié des articles sur la conteneurisation",
          "Je suis reconnu comme expert externe en containers"
        ]
      },
      "resources": [
        {
          "url": "https://docs.docker.com/get-started/",
          "title": "Docker Get Started",
          "type": "tutorial"
        },
        {
          "url": "https://www.docker.com/101-tutorial/",
          "title": "Docker 101 Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://docs.docker.com/develop/develop-images/dockerfile_best-practices/",
          "title": "Dockerfile Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/watch?v=fqMOX6JJhGo",
          "title": "Docker Tutorial for Beginners",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Conteneurisez une application Python. Utilisez docker-compose pour plusieurs services.",
        "2→3": "Optimisez la taille des images avec multi-stage builds. Utilisez les layer caching.",
        "3→4": "Définissez les standards de conteneurisation. Formez les équipes."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "monitoring",
      "name": "Monitoring & Alerting",
      "description": "Surveiller les systèmes et configurer des alertes (Grafana, logs, métriques)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance monitoring",
        "1": "Peut utiliser les dashboards existants, comprend les métriques",
        "2": "Peut créer des dashboards, alertes et queries basiques",
        "3": "Conçoit des stratégies de monitoring, dashboards complexes",
        "4": "Expert en observabilité et monitoring",
        "5": "Architecte observabilité de l'organisation",
        "6": "Expert monitoring reconnu, speaker ObservabilityCon"
      },
      "behavioral_indicators": {
        "1": [
          "Je consulte les dashboards existants",
          "Je comprends les métriques de base (latence, erreurs)",
          "Je sais lire les logs dans Cloud Logging"
        ],
        "2": [
          "Je crée des dashboards Grafana simples",
          "Je configure des alertes basiques",
          "J'écris des queries pour explorer les métriques",
          "Je sais déboguer avec les logs"
        ],
        "3": [
          "Je conçois une stratégie de monitoring complète",
          "Je définis les SLIs et SLOs",
          "Je crée des dashboards pour les pipelines data",
          "J'implémente l'alerting sur les anomalies"
        ],
        "4": [
          "J'ai conçu l'architecture d'observabilité",
          "Je définis les standards de monitoring",
          "Je forme les équipes au monitoring",
          "Je mesure et améliore la fiabilité"
        ],
        "5": [
          "Je définis les standards d'observabilité pour l'organisation",
          "Je suis la référence interne pour les architectures de monitoring",
          "Je mentore les équipes sur les SLIs/SLOs et error budgets",
          "J'ai mis en place la plateforme d'observabilité"
        ],
        "6": [
          "Je suis speaker à des conférences ObservabilityCon ou SREcon",
          "Je contribue à Prometheus, Grafana ou outils similaires",
          "J'ai publié des articles sur l'observabilité",
          "Je suis reconnu comme expert externe en monitoring"
        ]
      },
      "resources": [
        {
          "url": "https://grafana.com/tutorials/",
          "title": "Grafana Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://prometheus.io/docs/introduction/overview/",
          "title": "Prometheus Documentation",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/monitoring/docs",
          "title": "Google Cloud Monitoring",
          "type": "documentation"
        },
        {
          "url": "https://www.datadoghq.com/blog/monitoring-101-collecting-data/",
          "title": "Monitoring 101",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un dashboard Grafana pour vos pipelines. Configurez des alertes basiques.",
        "2→3": "Implémentez une stratégie de monitoring complète. Utilisez les SLIs/SLOs.",
        "3→4": "Concevez l'architecture d'observabilité de l'organisation. Partagez vos pratiques."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "precommit_quality",
      "name": "Pre-commit & Qualité Code",
      "description": "Utiliser les outils de qualité de code (ruff, sqlfluff, pre-commit hooks)",
      "core_roles": [
        "data_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des outils de qualité",
        "1": "Comprend l'importance de la qualité de code",
        "2": "Utilise les hooks pre-commit, fixe les erreurs de linting",
        "3": "Configure les outils de qualité pour le projet",
        "4": "Expert en configuration et optimisation des outils",
        "5": "Définit les standards de qualité de l'organisation",
        "6": "Contributeur ruff/sqlfluff, expert code quality reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends l'importance du linting",
          "Je sais ce qu'est un hook pre-commit",
          "Je connais les outils de base (ruff, black)"
        ],
        "2": [
          "J'utilise pre-commit au quotidien",
          "Je fixe les erreurs de linting signalées",
          "Je comprends les règles de formatage",
          "J'utilise sqlfluff pour le SQL"
        ],
        "3": [
          "Je configure pre-commit pour le projet",
          "Je personnalise les règles ruff/sqlfluff",
          "J'intègre les checks dans le CI",
          "Je définis les standards pour l'équipe"
        ],
        "4": [
          "J'ai défini les standards de qualité de l'organisation",
          "J'optimise les performances des checks",
          "Je forme les équipes aux outils de qualité",
          "Je contribue aux outils open-source"
        ],
        "5": [
          "Je définis les standards de qualité code pour l'organisation",
          "Je suis la référence interne pour les outils de linting",
          "Je mentore les équipes sur les bonnes pratiques de code",
          "J'ai mis en place le programme de qualité code"
        ],
        "6": [
          "Je suis speaker à des conférences Python ou Code Quality",
          "Je contribue à ruff, sqlfluff ou outils similaires",
          "J'ai publié des articles sur la qualité de code",
          "Je suis reconnu comme expert externe en linting et formatage"
        ]
      },
      "resources": [
        {
          "url": "https://pre-commit.com/",
          "title": "Pre-commit Documentation",
          "type": "documentation"
        },
        {
          "url": "https://docs.astral.sh/ruff/",
          "title": "Ruff Documentation",
          "type": "documentation"
        },
        {
          "url": "https://docs.sqlfluff.com/",
          "title": "SQLFluff Documentation",
          "type": "documentation"
        },
        {
          "url": "https://realpython.com/python-code-quality/",
          "title": "Python Code Quality",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Installez pre-commit sur votre projet. Configurez ruff pour le linting Python.",
        "2→3": "Personnalisez les règles pour votre équipe. Ajoutez sqlfluff pour SQL.",
        "3→4": "Définissez les standards de l'organisation. Automatisez dans le CI."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "data_quality_management",
      "name": "Data Quality Management",
      "description": "Validation de données, détection d'anomalies, great expectations, dbt tests, alerting qualité",
      "core_roles": [
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la qualité des données",
        "1": "Comprend l'importance de la qualité des données, identifie les problèmes basiques",
        "2": "Implémente des tests dbt, configure des validations de données",
        "3": "Conçoit des frameworks de qualité, détection d'anomalies automatisée",
        "4": "Expert en data quality, définit les SLAs et stratégie de monitoring",
        "5": "Architecte data quality de l'organisation",
        "6": "Expert data quality reconnu, speaker Data Quality Summit"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends l'importance de la qualité des données",
          "Je sais identifier les doublons et valeurs nulles",
          "Je détecte les problèmes de qualité manuellement"
        ],
        "2": [
          "J'implémente des tests dbt (unique, not_null, accepted_values)",
          "Je configure des validations avec Great Expectations",
          "Je mets en place des alertes simples sur la qualité",
          "Je documente les règles de qualité"
        ],
        "3": [
          "Je conçois un framework de qualité pour l'équipe",
          "J'implémente la détection d'anomalies automatisée",
          "Je définis les SLAs de qualité par table",
          "J'ai réduit significativement les incidents de qualité"
        ],
        "4": [
          "Je définis la stratégie de data quality",
          "Je mets en place le monitoring continu",
          "Je forme les équipes aux bonnes pratiques",
          "Je produis des rapports de qualité pour l'organisation"
        ],
        "5": [
          "Je définis les standards de data quality pour l'ensemble de l'organisation",
          "Je suis la référence interne pour les frameworks de qualité de données",
          "Je mentore les équipes sur les stratégies de monitoring avancées",
          "J'ai mis en place le programme de gouvernance data quality"
        ],
        "6": [
          "Je suis speaker à des conférences Data Quality Summit ou similaires",
          "J'ai publié des articles sur la data quality à l'échelle",
          "Je contribue à des projets open-source (Great Expectations, Soda)",
          "Je suis reconnu comme expert externe en data quality"
        ]
      },
      "resources": [
        {
          "url": "https://greatexpectations.io/expectations/",
          "title": "Great Expectations Documentation",
          "type": "documentation"
        },
        {
          "url": "https://docs.getdbt.com/docs/build/tests",
          "title": "dbt Tests",
          "type": "documentation"
        },
        {
          "url": "https://www.montecarlodata.com/blog-data-observability-guide/",
          "title": "Data Observability Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-quality-fundamentals/9781098112035/",
          "title": "Data Quality Fundamentals (O'Reilly)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez des tests dbt sur vos modèles critiques. Utilisez Great Expectations.",
        "2→3": "Construisez un framework de qualité avec alerting automatique. Définissez les SLAs.",
        "3→4": "Concevez la stratégie data quality de l'organisation. Partagez en conférence."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "data_contracts",
      "name": "Data Contracts",
      "description": "Définition et enforcement de contrats de données entre producteurs et consommateurs",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des data contracts",
        "1": "Comprend le concept de contrat de données et son utilité",
        "2": "Peut documenter et valider les contrats de données existants",
        "3": "Conçoit et implémente des data contracts avec validation automatique",
        "4": "Expert en gouvernance des données, définit les standards organisationnels",
        "5": "Architecte data governance de l'organisation",
        "6": "Expert data contracts reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un contrat de données",
          "Je connais les concepts de producteur et consommateur",
          "Je sais pourquoi les contracts sont importants"
        ],
        "2": [
          "Je documente les schémas et contraintes des tables",
          "J'identifie les producteurs et consommateurs",
          "Je valide manuellement les contrats existants",
          "Je détecte les breaking changes"
        ],
        "3": [
          "J'implémente des data contracts avec dbt",
          "J'automatise la validation dans le CI/CD",
          "Je gère les versions et évolutions des contrats",
          "J'ai réduit les incidents de breaking changes"
        ],
        "4": [
          "J'ai défini le framework de data contracts",
          "Je forme les équipes à la gouvernance",
          "J'évangélise l'approche contract-first",
          "Je mesure l'adoption des contracts"
        ],
        "5": [
          "Je définis les standards de data contracts pour l'organisation",
          "Je suis la référence interne pour la gouvernance des données",
          "Je mentore les équipes sur l'approche contract-first",
          "J'ai mis en place le programme de data governance"
        ],
        "6": [
          "Je suis speaker à des conférences Data Governance ou Data Mesh",
          "J'ai publié des articles sur les data contracts",
          "Je contribue à la spécification Data Contract ou outils associés",
          "Je suis reconnu comme expert externe en data governance"
        ]
      },
      "resources": [
        {
          "url": "https://datacontract.com/",
          "title": "Data Contract Specification",
          "type": "documentation"
        },
        {
          "url": "https://www.getdbt.com/blog/data-contracts/",
          "title": "dbt Data Contracts",
          "type": "documentation"
        },
        {
          "url": "https://www.thoughtworks.com/en-gb/insights/articles/data-contracts",
          "title": "Data Contracts (ThoughtWorks)",
          "type": "documentation"
        },
        {
          "url": "https://atlan.com/data-contracts/",
          "title": "Data Contracts Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Documentez les schemas de vos tables critiques. Identifiez les producteurs et consommateurs.",
        "2→3": "Implémentez des data contracts avec dbt. Automatisez la validation dans le CI.",
        "3→4": "Définissez le framework de data contracts de l'organisation. Évangélisez l'approche."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "data_catalog_lineage",
      "name": "Data Catalog & Lineage",
      "description": "Documentation metadata, traçabilité des transformations, outils type DataHub/Amundsen",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du data catalog",
        "1": "Peut utiliser le data catalog pour trouver des données",
        "2": "Documente les datasets et leurs métadonnées, comprend le lineage",
        "3": "Maintient le data catalog, configure le lineage automatique",
        "4": "Expert en gouvernance, conçoit l'architecture du data catalog",
        "5": "Architecte metadata management de l'organisation",
        "6": "Contributeur DataHub/Amundsen, expert reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans le data catalog pour trouver des données",
          "Je comprends ce qu'est le lineage",
          "Je sais où chercher la documentation des tables"
        ],
        "2": [
          "Je documente mes datasets dans le catalog",
          "Je maintiens les descriptions et métadonnées",
          "Je comprends le lineage de mes pipelines",
          "J'utilise les tags et classifications"
        ],
        "3": [
          "Je configure le lineage automatique (OpenLineage)",
          "Je maintiens la qualité des métadonnées",
          "J'intègre le catalog avec les outils de la stack",
          "Je forme les équipes à utiliser le catalog"
        ],
        "4": [
          "J'ai conçu l'architecture du data catalog",
          "Je définis les standards de documentation",
          "Je mesure l'adoption et la qualité du catalog",
          "Je contribue aux outils open-source"
        ],
        "5": [
          "Je définis les standards de metadata management pour l'organisation",
          "Je suis la référence interne pour l'architecture data catalog",
          "Je mentore les équipes sur le lineage et la traçabilité",
          "J'ai mis en place le programme de data discovery"
        ],
        "6": [
          "Je suis speaker à des conférences Data Governance ou Metadata",
          "J'ai publié des articles sur le data catalog à l'échelle",
          "Je contribue à DataHub, Amundsen ou OpenLineage",
          "Je suis reconnu comme expert externe en metadata management"
        ]
      },
      "resources": [
        {
          "url": "https://datahubproject.io/docs/",
          "title": "DataHub Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.amundsen.io/amundsen/",
          "title": "Amundsen Documentation",
          "type": "documentation"
        },
        {
          "url": "https://atlan.com/what-is-data-lineage/",
          "title": "Data Lineage Guide",
          "type": "documentation"
        },
        {
          "url": "https://openlineage.io/",
          "title": "OpenLineage",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Documentez vos datasets dans le data catalog. Comprenez le lineage de vos pipelines.",
        "2→3": "Configurez le lineage automatique avec OpenLineage. Maintenez la qualité des métadonnées.",
        "3→4": "Concevez l'architecture du data catalog. Intégrez avec tous les outils de la stack."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "cost_optimization",
      "name": "Cost Optimization Cloud",
      "description": "Gestion des coûts cloud, slots BigQuery, optimisation stockage, FinOps data",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'optimisation des coûts",
        "1": "Comprend les modèles de facturation cloud basiques",
        "2": "Surveille les coûts, identifie les optimisations simples",
        "3": "Optimise les coûts BigQuery (slots, stockage), met en place le monitoring",
        "4": "Expert FinOps, définit la stratégie d'optimisation des coûts data",
        "5": "Architecte FinOps de l'organisation",
        "6": "Expert FinOps reconnu, certifié FinOps Practitioner"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le modèle de facturation BigQuery (on-demand vs slots)",
          "Je connais les coûts de stockage GCS",
          "Je sais lire une facture cloud basique"
        ],
        "2": [
          "J'analyse les coûts de mes projets GCP",
          "J'identifie les requêtes les plus coûteuses",
          "Je mets en place des alertes de budget",
          "J'ai réduit les coûts d'un projet de 20%+"
        ],
        "3": [
          "Je configure les slot reservations BigQuery",
          "J'optimise les stratégies de stockage (partitioning, lifecycle)",
          "Je mets en place le monitoring des coûts",
          "J'ai défini les budgets par équipe"
        ],
        "4": [
          "J'ai défini la stratégie FinOps de l'organisation",
          "J'ai réduit les coûts de 30%+ à l'échelle",
          "Je forme les équipes à l'optimisation",
          "Je produis des rapports de coûts réguliers"
        ],
        "5": [
          "Je définis les standards FinOps pour l'ensemble de l'organisation",
          "Je suis la référence interne pour l'optimisation des coûts cloud",
          "Je mentore les équipes sur les stratégies de cost management",
          "J'ai mis en place le programme FinOps de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences FinOps ou Cloud Economics",
          "J'ai obtenu la certification FinOps Practitioner",
          "J'ai publié des articles sur l'optimisation des coûts data",
          "Je suis reconnu comme expert externe en FinOps"
        ]
      },
      "resources": [
        {
          "url": "https://www.finops.org/introduction/what-is-finops/",
          "title": "What is FinOps",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/architecture/cost-optimization",
          "title": "GCP Cost Optimization",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-costs",
          "title": "BigQuery Cost Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://www.finops.org/resources/finops-certifications/",
          "title": "FinOps Certification",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les coûts de vos projets GCP. Identifiez les requêtes BigQuery les plus coûteuses.",
        "2→3": "Implémentez le slot reservation pour BigQuery. Mettez en place des alertes de coûts.",
        "3→4": "Définissez la stratégie FinOps de l'organisation. Passez la certification FinOps."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "query_performance",
      "name": "Query Performance",
      "description": "Optimisation des requêtes, partitioning, clustering, materialized views, plans d'exécution",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'optimisation de requêtes",
        "1": "Comprend l'impact des requêtes sur les performances",
        "2": "Optimise les requêtes basiques, utilise EXPLAIN, comprend les index",
        "3": "Conçoit des stratégies de partitioning/clustering, materialized views",
        "4": "Expert en performance, audite et optimise les pipelines critiques",
        "5": "Architecte performance data de l'organisation",
        "6": "Expert query optimization reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends que certaines requêtes sont plus lentes que d'autres",
          "Je sais que le volume de données impacte les performances",
          "Je connais l'existence des plans d'exécution"
        ],
        "2": [
          "J'utilise EXPLAIN pour analyser mes requêtes",
          "J'optimise mes requêtes avec des filtres sur les partitions",
          "Je comprends l'impact du SELECT * vs colonnes spécifiques",
          "J'ai optimisé une requête en réduisant son temps de 50%+"
        ],
        "3": [
          "Je conçois des stratégies de partitioning et clustering",
          "J'utilise les materialized views pour les agrégations fréquentes",
          "J'optimise les jointures et les sous-requêtes",
          "Je monitore les performances des requêtes critiques"
        ],
        "4": [
          "J'audite les performances des pipelines",
          "J'ai défini les standards d'optimisation",
          "Je forme les équipes aux bonnes pratiques",
          "J'ai réduit les temps de build de 50%+ à l'échelle"
        ],
        "5": [
          "Je définis les standards de performance data pour l'organisation",
          "Je suis la référence interne pour l'optimisation des requêtes",
          "Je mentore les équipes sur les stratégies de partitioning avancées",
          "J'ai mis en place le programme d'optimisation des pipelines"
        ],
        "6": [
          "Je suis speaker à des conférences Data Engineering ou Performance",
          "J'ai publié des articles sur l'optimisation de requêtes à l'échelle",
          "Je contribue à des projets open-source liés à la performance",
          "Je suis reconnu comme expert externe en query optimization"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-performance-overview",
          "title": "BigQuery Performance Guide",
          "type": "documentation"
        },
        {
          "url": "https://use-the-index-luke.com/",
          "title": "Use The Index, Luke!",
          "type": "book"
        },
        {
          "url": "https://www.postgresql.org/docs/current/performance-tips.html",
          "title": "PostgreSQL Performance Tips",
          "type": "documentation"
        },
        {
          "url": "https://mode.com/sql-tutorial/sql-performance-tuning/",
          "title": "SQL Performance Tuning",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez à lire les plans d'exécution. Optimisez une requête lente existante.",
        "2→3": "Implémentez le partitioning et clustering sur vos tables critiques. Utilisez les materialized views.",
        "3→4": "Auditez les performances des pipelines de l'organisation. Formez les équipes."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "technical_scoping",
      "name": "Cadrage Technique",
      "description": "Appréhender les enjeux techniques d'un projet, effectuer un découpage fonctionnel et évaluer la faisabilité et la complexité des solutions",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune capacité de cadrage technique",
        "1": "Comprend les enjeux techniques d'un projet simple et peut identifier les grandes étapes",
        "2": "Découpe un projet en tâches fonctionnelles, estime la complexité et identifie les dépendances",
        "3": "Cadre des projets complexes multi-équipes, anticipe les risques techniques et propose des alternatives",
        "4": "Expert en cadrage, arbitre les choix d'architecture et guide la stratégie technique",
        "5": "Définit les méthodologies de cadrage technique de l'organisation",
        "6": "Référent cadrage reconnu en externe, consultant ou formateur"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le besoin fonctionnel derrière une demande technique",
          "Je sais identifier les grandes étapes d'un projet simple",
          "Je pose des questions pour clarifier le périmètre d'un sujet"
        ],
        "2": [
          "Je découpe un projet en tâches avec des livrables clairs",
          "J'estime la complexité relative des tâches (S/M/L)",
          "J'identifie les dépendances techniques entre composants",
          "Je rédige des spécifications fonctionnelles pour mes tâches"
        ],
        "3": [
          "Je cadre des projets impliquant plusieurs équipes",
          "J'anticipe les risques techniques et propose des plans de mitigation",
          "Je compare plusieurs approches techniques avec leurs trade-offs",
          "Je produis des documents de cadrage structurés (ADR, RFC)"
        ],
        "4": [
          "J'arbitre les choix d'architecture sur les projets complexes",
          "Je guide la stratégie technique de l'équipe",
          "Je forme les autres au cadrage et à l'estimation",
          "Je suis sollicité pour les cadrages stratégiques de l'organisation"
        ],
        "5": [
          "Je définis les méthodologies de cadrage technique de l'organisation",
          "Je forme les tech leads au cadrage de projets complexes",
          "Je suis référent pour les décisions d'architecture structurantes",
          "J'ai mis en place des processus de cadrage reproductibles"
        ],
        "6": [
          "Je suis consultant externe en cadrage et architecture technique",
          "Je donne des conférences sur le cadrage et la planification technique",
          "J'ai publié des articles sur les méthodologies de cadrage",
          "Je suis reconnu comme expert en cadrage technique dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.atlassian.com/agile/project-management/estimation",
          "title": "Atlassian - Estimation Agile",
          "type": "documentation"
        },
        {
          "url": "https://adr.github.io/",
          "title": "Architecture Decision Records",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/software-architecture",
          "title": "Software Architecture (Coursera)",
          "type": "course"
        },
        {
          "url": "https://martinfowler.com/articles/writingPatterns.html",
          "title": "Martin Fowler - Writing Patterns",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Découpez un projet en tâches avec des estimations. Rédigez vos premières spécifications fonctionnelles.",
        "2→3": "Cadrez un projet multi-équipes. Rédigez un ADR ou RFC pour documenter vos choix techniques.",
        "3→4": "Arbitrez les choix d'architecture sur un projet stratégique. Formez les juniors au cadrage."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "problem_solving",
      "name": "Résolution de Problèmes",
      "description": "Approcher les problèmes complexes de manière systématique",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Ne peut pas structurer les problèmes",
        "1": "Peut décomposer des problèmes simples",
        "2": "Approche les problèmes complexes systématiquement",
        "3": "Résout des problèmes ambigus, crée des frameworks",
        "4": "Expert problem solver, guide les décisions stratégiques",
        "5": "Référent résolution de problèmes de l'organisation",
        "6": "Expert reconnu, consultant externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je décompose un problème en sous-problèmes",
          "Je cherche des solutions similaires avant de réinventer",
          "Je sais poser les bonnes questions pour clarifier un problème"
        ],
        "2": [
          "J'utilise une approche structurée (5 whys, issue trees)",
          "Je documente mes hypothèses et les valide",
          "Je priorise les problèmes par impact et urgence",
          "Je sais quand demander de l'aide vs persévérer seul"
        ],
        "3": [
          "Je crée des frameworks réutilisables pour résoudre des classes de problèmes",
          "Je gère l'ambiguïté et avance malgré l'incertitude",
          "J'ai résolu des problèmes impliquant plusieurs équipes",
          "Je challenge les hypothèses implicites"
        ],
        "4": [
          "Je guide des décisions stratégiques par la résolution de problèmes",
          "Je forme les autres à structurer leurs problèmes",
          "Je suis sollicité pour les problèmes complexes de l'organisation",
          "Je transforme les problèmes en opportunités"
        ],
        "5": [
          "Je définis la méthodologie de résolution de problèmes de l'organisation",
          "Je forme les managers et leads à la résolution de problèmes",
          "Je suis le référent pour les problèmes stratégiques cross-équipes",
          "J'ai institutionnalisé des pratiques de problem solving"
        ],
        "6": [
          "Je suis consultant externe en résolution de problèmes",
          "Je donne des conférences sur les méthodologies de problem solving",
          "J'ai publié des articles ou livres sur la résolution de problèmes",
          "Je suis reconnu comme expert problem solving dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/problem-solving",
          "title": "Problem Solving Skills (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.mindtools.com/pages/main/newMN_TMC.htm",
          "title": "Mind Tools - Problem Solving",
          "type": "documentation"
        },
        {
          "url": "https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-problem-with-problem-solving",
          "title": "McKinsey - Problem Solving",
          "type": "documentation"
        },
        {
          "url": "https://bulletproofproblemsolving.com/",
          "title": "Bulletproof Problem Solving",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Utilisez une approche structurée (5 whys, issue trees). Documentez votre processus.",
        "2→3": "Créez des frameworks réutilisables. Résolvez un problème cross-équipes.",
        "3→4": "Guidez des décisions stratégiques. Formez les autres à la résolution de problèmes."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "stakeholder_management",
      "name": "Gestion des Stakeholders",
      "description": "Travailler efficacement avec les stakeholders (product, business, tech)",
      "core_roles": [
        "data_analyst",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Ne peut pas gérer les stakeholders",
        "1": "Travaille avec les stakeholders directs",
        "2": "Gère plusieurs stakeholders, gère les conflits",
        "3": "Influence les stakeholders seniors, drive l'alignement",
        "4": "Expert en gestion des stakeholders",
        "5": "Référent relations inter-équipes de l'organisation",
        "6": "Expert influence reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je communique régulièrement avec mon PM/manager direct",
          "Je comprends les besoins de mes stakeholders directs",
          "Je livre mes résultats dans les délais attendus"
        ],
        "2": [
          "Je gère plusieurs stakeholders avec des besoins différents",
          "J'ai priorisé des demandes conflictuelles avec succès",
          "Je communique proactivement les blocages et retards",
          "Je sais dire non de manière constructive"
        ],
        "3": [
          "J'influence les décisions au niveau senior",
          "Je suis sollicité pour des sujets stratégiques",
          "J'ai aligné des priorités divergentes entre équipes",
          "Je suis reconnu comme un partenaire de confiance"
        ],
        "4": [
          "Je suis le point de contact data pour plusieurs équipes",
          "Je forme les autres à la gestion des stakeholders",
          "J'ai établi des rituels de communication efficaces",
          "Je gère les escalades de manière constructive"
        ],
        "5": [
          "Je définis les processus de collaboration inter-équipes",
          "Je forme les managers à la gestion des stakeholders",
          "Je suis médiateur pour les conflits inter-équipes",
          "J'ai créé des frameworks de priorisation organisationnels"
        ],
        "6": [
          "Je suis consultant externe en gestion des stakeholders",
          "Je donne des formations externes sur l'influence et la négociation",
          "J'ai publié sur les techniques de stakeholder management",
          "Je suis reconnu comme expert en influence dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.pmi.org/learning/library/stakeholder-management-task-project-success-7736",
          "title": "PMI Stakeholder Management",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/stakeholder-management",
          "title": "Stakeholder Management (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2014/03/manage-your-stakeholders",
          "title": "HBR - Manage Your Stakeholders",
          "type": "documentation"
        },
        {
          "url": "https://www.mindtools.com/pages/article/newPPM_07.htm",
          "title": "Stakeholder Analysis",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Identifiez tous vos stakeholders et leurs attentes. Communiquez régulièrement.",
        "2→3": "Gérez un conflit entre stakeholders. Alignez des priorités divergentes.",
        "3→4": "Influencez les décisions au niveau senior. Devenez un point de contact clé."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "mentoring_leadership",
      "name": "Mentorat & Leadership",
      "description": "Accompagner et faire grandir les membres de l'équipe",
      "core_roles": [],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "data_scientist": [
          "NC",
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Pas de compétence en mentorat",
        "1": "Peut aider ponctuellement un collègue sur un sujet maîtrisé",
        "2": "Mentor régulier, fait des code reviews constructives",
        "3": "Accompagne la montée en compétence de plusieurs personnes",
        "4": "Leader reconnu, développe les talents de l'équipe",
        "5": "Définit le programme de mentorat de l'organisation",
        "6": "Coach/mentor reconnu externement"
      },
      "behavioral_indicators": {
        "1": [
          "J'aide mes collègues quand ils ont des questions",
          "Je partage des ressources utiles avec l'équipe",
          "Je peux expliquer un sujet que je maîtrise"
        ],
        "2": [
          "Je fais des code reviews constructives régulièrement",
          "J'ai mentoré au moins une personne sur un sujet spécifique",
          "Je donne du feedback actionnable et bienveillant",
          "J'organise des sessions de pair programming"
        ],
        "3": [
          "Je suis le mentor officiel d'un ou plusieurs juniors",
          "J'organise des sessions de partage de connaissances",
          "J'ai accompagné quelqu'un dans sa montée en compétence",
          "Je crée de la documentation pour faciliter l'onboarding"
        ],
        "4": [
          "Je développe un programme de mentorat structuré",
          "Je suis reconnu comme un leader technique",
          "J'ai aidé plusieurs personnes à progresser significativement",
          "Je contribue aux décisions de promotion et évaluation"
        ],
        "5": [
          "Je définis le programme de mentorat de l'organisation",
          "Je forme les mentors et managers au coaching",
          "Je mesure l'efficacité du programme de mentorat",
          "J'ai créé des parcours de développement de carrière"
        ],
        "6": [
          "Je suis coach ou mentor externe pour d'autres entreprises",
          "Je donne des conférences sur le leadership et le mentorat",
          "J'ai publié sur les techniques de coaching et développement",
          "Je suis reconnu comme expert en leadership dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/leadership-and-emotional-intelligence",
          "title": "Leadership and Emotional Intelligence",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2015/12/everyone-deserves-a-great-manager",
          "title": "HBR - Great Manager",
          "type": "documentation"
        },
        {
          "url": "https://www.amazon.com/Radical-Candor-Revised-Kick-Ass-Humanity/dp/1250235375",
          "title": "Radical Candor",
          "type": "book"
        },
        {
          "url": "https://www.atlassian.com/team-playbook/plays/retrospective",
          "title": "Atlassian Retrospectives",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Mentorez un junior sur un sujet spécifique. Faites des code reviews constructives.",
        "2→3": "Accompagnez plusieurs personnes dans leur développement. Organisez des sessions de partage.",
        "3→4": "Développez un programme de mentorat. Mesurez la progression de vos mentorés."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "communication",
      "name": "Communication",
      "description": "Communiquer efficacement à l'écrit et à l'oral, vulgariser les concepts techniques, informer proactivement et représenter l'équipe",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Ne communique pas efficacement",
        "1": "Explique son code et son travail à ses collègues proches",
        "2": "Pédagogue, informe proactivement son équipe, fait des démos",
        "3": "Vulgarise des sujets complexes, documente, représente l'équipe en externe",
        "4": "Communique avec toutes les parties prenantes (tech, produit, direction, institutions)",
        "5": "Définit les standards de communication de l'organisation",
        "6": "Speaker reconnu, formateur externe en communication technique"
      },
      "behavioral_indicators": {
        "1": [
          "J'explique mon code de manière claire lors des code reviews",
          "Je documente mes travaux avec des commentaires compréhensibles",
          "Je sais présenter mes résultats en réunion d'équipe"
        ],
        "2": [
          "Je fais des démos régulières de mon travail à l'équipe",
          "J'informe proactivement des avancées, blocages et décisions",
          "J'adapte mon discours à mon audience (tech vs non-tech)",
          "Je rédige des messages clairs et structurés (Slack, email, PR)"
        ],
        "3": [
          "Je vulgarise des concepts techniques complexes avec aisance",
          "Je produis de la documentation claire et à jour",
          "Je représente l'équipe data lors de réunions transverses",
          "J'ai présenté dans un brown bag, meetup interne ou conférence"
        ],
        "4": [
          "Je communique efficacement avec toutes les parties prenantes",
          "Je présente à la direction ou aux partenaires institutionnels",
          "Je crée des supports de communication pour l'équipe (templates, guides)",
          "Je forme les autres à la communication technique"
        ],
        "5": [
          "Je définis les standards de communication de l'organisation",
          "Je coache les speakers et rédacteurs",
          "Je suis référent pour les présentations stratégiques",
          "J'organise des sessions de formation à la communication"
        ],
        "6": [
          "Je suis speaker reconnu dans des conférences externes",
          "Je suis formateur externe en communication technique",
          "J'ai publié des contenus reconnus sur la vulgarisation technique",
          "Je suis sollicité comme expert en communication par d'autres organisations"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://www.ted.com/talks/chris_anderson_ted_s_secret_to_great_public_speaking",
          "title": "TED - Secret to Great Speaking",
          "type": "video"
        },
        {
          "url": "https://www.coursera.org/learn/public-speaking",
          "title": "Public Speaking (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.writethedocs.org/guide/",
          "title": "Write the Docs - Documentation Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Faites des démos régulières de votre travail. Informez proactivement votre équipe des avancées et blocages.",
        "2→3": "Vulgarisez un sujet complexe lors d'un brown bag. Documentez un projet de bout en bout.",
        "3→4": "Présentez aux parties prenantes non-techniques. Formez les autres à la communication."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "project_management",
      "name": "Gestion de Projet Data",
      "description": "Piloter un projet data de bout en bout",
      "core_roles": [
        "data_analyst",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune expérience en gestion de projet",
        "1": "Peut gérer ses propres tâches, respecte les deadlines",
        "2": "Peut piloter un petit projet data avec quelques dépendances",
        "3": "Gère des projets complexes multi-équipes",
        "4": "Expert en gestion de projet, méthodologies adaptées au data",
        "5": "Définit les méthodologies projet de l'organisation",
        "6": "Expert gestion de projet (conférences, formateur)"
      },
      "behavioral_indicators": {
        "1": [
          "Je gère mes tâches dans un outil (Jira, Linear, etc.)",
          "Je respecte les deadlines communiquées",
          "Je sais estimer le temps nécessaire pour mes tâches"
        ],
        "2": [
          "J'ai piloté un projet data de bout en bout",
          "Je découpe un projet en tâches avec des livrables clairs",
          "Je communique l'avancement régulièrement aux stakeholders",
          "Je gère les risques et les blocages proactivement"
        ],
        "3": [
          "Je gère des projets avec des dépendances multi-équipes",
          "J'ai livré des projets impliquant 3+ personnes",
          "Je coordonne les travaux entre équipes",
          "J'ai géré un projet avec des contraintes fortes"
        ],
        "4": [
          "J'ai défini une méthodologie de gestion de projet data",
          "Je forme les autres à la gestion de projet",
          "Je suis sollicité pour les projets complexes",
          "J'ai un track record de projets livrés avec succès"
        ],
        "5": [
          "Je définis les méthodologies projet de l'organisation",
          "Je forme les chefs de projet et tech leads",
          "Je suis référent pour les projets stratégiques",
          "J'ai mis en place des outils et processus projet"
        ],
        "6": [
          "Je suis consultant externe en gestion de projet data",
          "Je donne des conférences sur la gestion de projet",
          "J'ai publié sur les méthodologies de projet data",
          "Je suis certifié et reconnu comme expert (PMP, etc.)"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/project-management-foundations",
          "title": "Project Management Foundations",
          "type": "course"
        },
        {
          "url": "https://www.atlassian.com/agile/project-management",
          "title": "Atlassian Agile Project Management",
          "type": "documentation"
        },
        {
          "url": "https://www.pmi.org/learning/library",
          "title": "PMI Learning Library",
          "type": "documentation"
        },
        {
          "url": "https://asana.com/resources/project-management-basics",
          "title": "Project Management Basics",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Pilotez un petit projet data avec des livrables clairs. Utilisez un outil de suivi.",
        "2→3": "Gérez un projet avec plusieurs dépendances. Communiquez régulièrement sur l'avancement.",
        "3→4": "Définissez une méthodologie de gestion de projet data. Formez les équipes."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "posture",
      "name": "Posture",
      "description": "Curiosité intellectuelle, egoless programming, esprit critique, humilité, pédagogie, facilitation et vision",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Posture professionnelle insuffisante",
        "1": "Curieux, ouvert au feedback, accepte ses erreurs",
        "2": "Esprit critique constructif, humble, pédagogue avec ses pairs",
        "3": "Facilitateur, challenge les idées avec bienveillance, fait progresser les autres",
        "4": "Visionnaire, inspire par l'exemple, crée une culture d'apprentissage",
        "5": "Définit la culture et les valeurs techniques de l'organisation",
        "6": "Reconnu comme modèle de posture professionnelle en externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je suis curieux et je cherche à comprendre avant de critiquer",
          "J'accepte le feedback et je remets en question mes choix",
          "Je reconnais quand je me trompe et j'en tire des leçons"
        ],
        "2": [
          "Je pratique l'egoless programming : mon code n'est pas mon identité",
          "Je fais preuve d'esprit critique constructif en code review",
          "J'explique mes raisonnements avec pédagogie à mes collègues",
          "Je suis humble face à la complexité et je demande de l'aide quand nécessaire"
        ],
        "3": [
          "Je facilite les discussions techniques et aide à converger",
          "Je challenge les idées avec bienveillance, en apportant des alternatives",
          "Je fais progresser les juniors par mon exemple et mon accompagnement",
          "Je suis reconnu pour ma posture constructive dans les débats techniques"
        ],
        "4": [
          "J'inspire une culture d'apprentissage continu dans l'équipe",
          "Je crée un environnement psychologiquement sûr pour l'expérimentation",
          "Je porte une vision technique ambitieuse et la partage avec enthousiasme",
          "Je suis un modèle de posture professionnelle pour l'organisation"
        ],
        "5": [
          "Je définis la culture et les valeurs techniques de l'organisation",
          "Je mets en place des rituels favorisant la bonne posture (retros, blameless post-mortems)",
          "Je forme les managers et leads à la facilitation et au leadership bienveillant",
          "Je suis référent pour résoudre les tensions liées à la posture"
        ],
        "6": [
          "Je suis reconnu en externe pour ma posture et mon leadership technique",
          "Je donne des conférences sur la culture engineering et l'egoless programming",
          "J'ai publié sur les bonnes pratiques de posture en équipe tech",
          "Je suis sollicité comme coach ou mentor par d'autres organisations"
        ]
      },
      "resources": [
        {
          "url": "https://blog.codinghorror.com/the-ten-commandments-of-egoless-programming/",
          "title": "The Ten Commandments of Egoless Programming",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/emotional-intelligence",
          "title": "Emotional Intelligence (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.radicalcandor.com/",
          "title": "Radical Candor",
          "type": "book"
        },
        {
          "url": "https://psychsafety.co.uk/psychological-safety/",
          "title": "Psychological Safety Resources",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Pratiquez l'egoless programming en code review. Demandez du feedback régulièrement et agissez dessus.",
        "2→3": "Facilitez une discussion technique. Mentorez un junior en vous concentrant sur la posture.",
        "3→4": "Instaurez des pratiques de blameless post-mortem. Créez un environnement sûr pour l'expérimentation."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "adaptability",
      "name": "Environnement & Adaptabilité",
      "description": "S'adapter aux changements de roadmap, tenir ses engagements, faire preuve de flexibilité face à l'incertitude et aux contraintes",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Difficulté à s'adapter aux changements",
        "1": "Accepte les changements de priorité, tient ses engagements sur des tâches simples",
        "2": "S'adapte aux changements de roadmap, gère les imprévus, reste fiable sous pression",
        "3": "Anticipe les changements, propose des plans B, accompagne l'équipe dans les transitions",
        "4": "Pilote le changement, transforme les contraintes en opportunités, guide l'organisation",
        "5": "Définit les processus d'adaptation et de résilience de l'organisation",
        "6": "Expert reconnu en conduite du changement, consultant externe"
      },
      "behavioral_indicators": {
        "1": [
          "J'accepte les changements de priorité sans résistance",
          "Je tiens mes engagements et je communique quand je suis en difficulté",
          "Je m'adapte à un nouvel outil ou une nouvelle méthode de travail"
        ],
        "2": [
          "Je gère les changements de roadmap en repriorisant mes tâches",
          "Je reste fiable et productif face aux imprévus",
          "Je fais preuve de flexibilité dans mes choix techniques quand le contexte change",
          "Je communique proactivement les impacts des changements sur mes livrables"
        ],
        "3": [
          "J'anticipe les changements et je prépare des plans de contingence",
          "J'accompagne l'équipe lors des transitions (reorg, changement de stack, pivot)",
          "Je propose des alternatives quand un plan initial devient impossible",
          "Je reste serein et constructif face à l'incertitude"
        ],
        "4": [
          "Je pilote des transformations à l'échelle de l'équipe ou de l'organisation",
          "Je transforme les contraintes en opportunités d'amélioration",
          "Je guide les équipes dans les périodes de changement intense",
          "Je suis reconnu pour ma résilience et ma capacité d'adaptation"
        ],
        "5": [
          "Je définis les processus d'adaptation et de résilience de l'organisation",
          "Je forme les managers à la conduite du changement",
          "Je mets en place des pratiques de rétrospective et d'amélioration continue",
          "Je suis référent pour les transformations organisationnelles"
        ],
        "6": [
          "Je suis consultant externe en conduite du changement",
          "Je donne des conférences sur l'adaptabilité et la résilience en contexte tech",
          "J'ai publié sur les stratégies d'adaptation organisationnelle",
          "Je suis reconnu comme expert en transformation d'organisations tech"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/managing-change",
          "title": "Managing Change (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/topic/change-management",
          "title": "HBR - Change Management",
          "type": "documentation"
        },
        {
          "url": "https://www.atlassian.com/agile/agile-at-scale",
          "title": "Atlassian - Agile at Scale",
          "type": "documentation"
        },
        {
          "url": "https://basecamp.com/shapeup",
          "title": "Shape Up (Basecamp)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Gérez un changement de priorité en repriorisant vos tâches. Communiquez proactivement les impacts.",
        "2→3": "Anticipez un changement et préparez un plan B. Accompagnez un collègue dans une transition.",
        "3→4": "Pilotez une transformation à l'échelle de l'équipe. Transformez une contrainte en opportunité."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "teamwork",
      "name": "Travailler en Équipe",
      "description": "Collaborer efficacement: dire 'je ne sais pas', partager ses idées, faciliter, animer la communauté technique et gérer les conflits",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Travaille de manière isolée",
        "1": "Collabore avec ses collègues proches, ose dire 'je ne sais pas' et partage ses idées",
        "2": "Contribue activement aux rituels d'équipe, facilite les échanges, fait du pair programming",
        "3": "Anime la communauté technique, facilite les décisions collectives, gère les désaccords",
        "4": "Leader collaboratif, crée les conditions du travail d'équipe efficace, résout les conflits",
        "5": "Définit les pratiques collaboratives de l'organisation",
        "6": "Expert reconnu en collaboration et facilitation, formateur externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je dis 'je ne sais pas' quand c'est le cas, sans honte",
          "Je partage mes idées et mes doutes avec l'équipe",
          "Je participe activement aux réunions et aux discussions d'équipe"
        ],
        "2": [
          "Je contribue activement aux code reviews, retros et rituels d'équipe",
          "Je fais du pair programming régulièrement",
          "J'aide mes collègues quand ils sont bloqués, sans attendre qu'on me le demande",
          "Je donne et reçois du feedback de manière constructive"
        ],
        "3": [
          "J'anime des sessions de partage de connaissances (brown bags, tech talks)",
          "Je facilite les décisions collectives lors de débats techniques",
          "Je gère les désaccords avec diplomatie et en cherchant le consensus",
          "Je crée des espaces d'échange (guildes, communautés de pratique)"
        ],
        "4": [
          "Je crée les conditions pour que chacun puisse s'exprimer et contribuer",
          "Je résous les conflits au sein de l'équipe de manière constructive",
          "Je suis reconnu comme un catalyseur de collaboration dans l'organisation",
          "Je forme les autres à la facilitation et au travail collaboratif"
        ],
        "5": [
          "Je définis les pratiques collaboratives de l'organisation",
          "Je forme les managers et leads à la facilitation d'équipe",
          "Je mets en place des rituels de collaboration inter-équipes",
          "Je suis référent pour les situations de conflit complexes"
        ],
        "6": [
          "Je suis consultant externe en collaboration et facilitation d'équipe",
          "Je donne des conférences sur le travail d'équipe en contexte tech",
          "J'ai publié sur les pratiques collaboratives en engineering",
          "Je suis reconnu comme expert en dynamique d'équipe dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.atlassian.com/team-playbook",
          "title": "Atlassian Team Playbook",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/teamwork-skills",
          "title": "Teamwork Skills (Coursera)",
          "type": "course"
        },
        {
          "url": "https://martinfowler.com/articles/on-pair-programming.html",
          "title": "Martin Fowler - On Pair Programming",
          "type": "documentation"
        },
        {
          "url": "https://www.amazon.com/Five-Dysfunctions-Team-Leadership-Fable/dp/0787960756",
          "title": "The Five Dysfunctions of a Team",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Faites du pair programming régulièrement. Participez activement aux code reviews et retros.",
        "2→3": "Animez un brown bag ou un tech talk. Facilitez une décision collective lors d'un débat technique.",
        "3→4": "Créez une communauté de pratique. Résolvez un conflit au sein de l'équipe de manière constructive."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    }
  ],
  "assessment_modes": {
    "quick": {
      "name": "Rapide",
      "description": "15-20 compétences clés, ~10-15 min",
      "icon": "zap",
      "skill_count_target": 15
    },
    "standard": {
      "name": "Standard",
      "description": "Toutes les compétences du rôle, ~25-35 min",
      "icon": "clipboard"
    }
  },
  "core_skills_by_role": {
    "data_analyst": [
      "sql_bigquery",
      "statistical_analysis",
      "insight_generation",
      "python_data",
      "metabase",
      "looker",
      "dashboard_design",
      "data_preparation",
      "git_github",
      "technical_scoping",
      "problem_solving",
      "ab_testing",
      "firebase_analytics",
      "stakeholder_management",
      "project_management"
    ],
    "data_engineer": [
      "sql_bigquery",
      "python_data",
      "dbt",
      "airflow",
      "bigquery_advanced",
      "data_modeling",
      "git_github",
      "docker",
      "gcp_fundamentals",
      "github_actions",
      "data_quality_testing",
      "terraform",
      "monitoring",
      "medallion_architecture",
      "problem_solving"
    ],
    "data_scientist": [
      "sql_bigquery",
      "python_data",
      "statistical_analysis",
      "ml_fundamentals",
      "insight_generation",
      "tensorflow_pytorch",
      "embeddings_llm",
      "mlflow_experiment",
      "feature_engineering",
      "ab_testing",
      "git_github",
      "technical_scoping",
      "problem_solving",
      "data_preparation",
      "dashboard_design"
    ],
    "analytics_eng": [
      "sql_bigquery",
      "dbt",
      "dbt_advanced",
      "data_modeling",
      "bigquery_advanced",
      "python_data",
      "git_github",
      "data_quality_testing",
      "medallion_architecture",
      "airflow",
      "github_actions",
      "technical_scoping",
      "problem_solving",
      "data_contracts"
    ],
    "ml_engineer": [
      "python_data",
      "ml_fundamentals",
      "tensorflow_pytorch",
      "mlflow_experiment",
      "vertex_ai",
      "docker",
      "kubernetes",
      "airflow",
      "git_github",
      "github_actions",
      "feature_engineering",
      "embeddings_llm",
      "monitoring",
      "python_backend",
      "problem_solving"
    ],
    "backend": [
      "python_data",
      "python_backend",
      "rest_api_integration",
      "git_github",
      "docker",
      "kubernetes",
      "gcp_fundamentals",
      "github_actions",
      "terraform",
      "sql_bigquery",
      "monitoring",
      "precommit_quality",
      "data_modeling",
      "problem_solving",
      "technical_scoping"
    ]
  },
  "skill_groups": {
    "sql_query": {
      "name": "Compétences SQL & Requêtes",
      "icon": "database",
      "description": "Interrogation et manipulation de données",
      "skills": [
        "sql_bigquery",
        "bigquery_advanced",
        "query_performance"
      ]
    },
    "python_ecosystem": {
      "name": "Écosystème Python",
      "icon": "code",
      "description": "Programmation Python pour la data",
      "skills": [
        "python_data",
        "python_backend",
        "data_preparation"
      ]
    },
    "transformation": {
      "name": "Transformation de Données",
      "icon": "refresh-cw",
      "description": "Modélisation et transformation",
      "skills": [
        "dbt",
        "dbt_advanced",
        "data_modeling",
        "medallion_architecture"
      ]
    },
    "orchestration": {
      "name": "Orchestration & Pipelines",
      "icon": "git-branch",
      "description": "Automatisation des workflows",
      "skills": [
        "airflow",
        "airflow_custom_operators"
      ]
    },
    "cloud_infra": {
      "name": "Cloud & Infrastructure",
      "icon": "cloud",
      "description": "Services cloud et infrastructure",
      "skills": [
        "gcp_fundamentals",
        "kubernetes",
        "vertex_ai",
        "clickhouse"
      ]
    },
    "devops": {
      "name": "DevOps & Qualité",
      "icon": "settings",
      "description": "CI/CD, conteneurs, qualité",
      "skills": [
        "git_github",
        "github_actions",
        "docker",
        "terraform",
        "precommit_quality",
        "monitoring"
      ]
    },
    "analytics_tools": {
      "name": "Outils Analytics",
      "icon": "bar-chart",
      "description": "Analyse et visualisation",
      "skills": [
        "statistical_analysis",
        "ab_testing",
        "insight_generation"
      ]
    },
    "product_analytics": {
      "name": "Product Analytics",
      "icon": "trending-up",
      "description": "Analytics produit",
      "skills": [
        "firebase_analytics",
        "funnel_analysis",
        "cohort_analysis",
        "user_journey",
        "event_tracking"
      ]
    },
    "bi_visualization": {
      "name": "BI & Visualisation",
      "icon": "pie-chart",
      "description": "Outils BI et dashboards",
      "skills": [
        "metabase",
        "looker",
        "dashboard_design"
      ]
    },
    "ml_core": {
      "name": "Machine Learning",
      "icon": "cpu",
      "description": "ML et deep learning",
      "skills": [
        "ml_fundamentals",
        "tensorflow_pytorch",
        "feature_engineering"
      ]
    },
    "ml_advanced": {
      "name": "ML Avancé & LLM",
      "icon": "brain",
      "description": "Embeddings, recommandation, MLOps",
      "skills": [
        "embeddings_llm",
        "recommendation_systems",
        "entity_resolution",
        "mlflow_experiment"
      ]
    },
    "data_quality": {
      "name": "Qualité des Données",
      "icon": "shield",
      "description": "Tests, contrats, gouvernance",
      "skills": [
        "data_quality_testing",
        "data_contracts",
        "data_mesh"
      ]
    },
    "soft_skills": {
      "name": "Soft Skills",
      "icon": "users",
      "description": "Communication et leadership",
      "skills": [
        "technical_scoping",
        "communication",
        "problem_solving",
        "stakeholder_management",
        "mentoring_leadership",
        "project_management",
        "posture",
        "adaptability",
        "teamwork"
      ]
    }
  },
  "inference_rules": [
    {
      "source": "sql_bigquery",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "bigquery_advanced",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "query_performance",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "bigquery_advanced",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "bigquery_advanced",
              "suggestion": 0,
              "confidence": 0.9
            },
            {
              "skill": "dbt",
              "suggestion": 0,
              "confidence": 0.8
            },
            {
              "skill": "query_performance",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "python_data",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "python_backend",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 0,
              "confidence": 0.8
            },
            {
              "skill": "python_backend",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "dbt",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "dbt_advanced",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "data_modeling",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "medallion_architecture",
              "suggestion": 2,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "dbt_advanced",
              "suggestion": 1,
              "confidence": 0.7
            },
            {
              "skill": "data_modeling",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "dbt_advanced",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "airflow",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "airflow_custom_operators",
              "suggestion": 2,
              "confidence": 0.8
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "airflow_custom_operators",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "airflow_custom_operators",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "gcp_fundamentals",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "bigquery_advanced",
              "suggestion": 2,
              "confidence": 0.6
            },
            {
              "skill": "vertex_ai",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "vertex_ai",
              "suggestion": 0,
              "confidence": 0.8
            },
            {
              "skill": "kubernetes",
              "suggestion": 0,
              "confidence": 0.7
            }
          ]
        }
      ]
    },
    {
      "source": "git_github",
      "rules": [
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "github_actions",
              "suggestion": 1,
              "confidence": 0.7
            },
            {
              "skill": "precommit_quality",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "github_actions",
              "suggestion": 0,
              "confidence": 0.8
            }
          ]
        }
      ]
    },
    {
      "source": "docker",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "kubernetes",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "kubernetes",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "ml_fundamentals",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "tensorflow_pytorch",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "feature_engineering",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "mlflow_experiment",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "feature_engineering",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "tensorflow_pytorch",
              "suggestion": 0,
              "confidence": 0.9
            },
            {
              "skill": "embeddings_llm",
              "suggestion": 0,
              "confidence": 0.9
            },
            {
              "skill": "recommendation_systems",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "tensorflow_pytorch",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "embeddings_llm",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "vertex_ai",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "embeddings_llm",
              "suggestion": 0,
              "confidence": 0.8
            }
          ]
        }
      ]
    },
    {
      "source": "statistical_analysis",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "ab_testing",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "ml_fundamentals",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "ab_testing",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "ab_testing",
              "suggestion": 0,
              "confidence": 0.8
            }
          ]
        }
      ]
    },
    {
      "source": "dashboard_design",
      "rules": [
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "metabase",
              "suggestion": 1,
              "confidence": 0.5
            },
            {
              "skill": "looker",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        }
      ]
    },
    {
      "source": "firebase_analytics",
      "rules": [
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "event_tracking",
              "suggestion": 1,
              "confidence": 0.7
            },
            {
              "skill": "funnel_analysis",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "funnel_analysis",
              "suggestion": 0,
              "confidence": 0.7
            },
            {
              "skill": "cohort_analysis",
              "suggestion": 0,
              "confidence": 0.7
            }
          ]
        }
      ]
    },
    {
      "source": "communication",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "technical_scoping",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "stakeholder_management",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        }
      ]
    }
  ]
}
