{
  "_source_hash": "2c6a04705570762f",
  "roles": [
    {
      "id": "data_analyst",
      "name": "Data Analyst",
      "abbreviation": "DA"
    },
    {
      "id": "data_engineer",
      "name": "Data Engineer",
      "abbreviation": "DE"
    },
    {
      "id": "data_scientist",
      "name": "Data Scientist",
      "abbreviation": "DS"
    },
    {
      "id": "analytics_eng",
      "name": "Analytics Eng",
      "abbreviation": "AE"
    },
    {
      "id": "ml_engineer",
      "name": "ML Engineer",
      "abbreviation": "MLE"
    },
    {
      "id": "backend",
      "name": "Backend",
      "abbreviation": "BE"
    }
  ],
  "levels": [
    {
      "id": "junior",
      "name": "Junior",
      "abbreviation": "Jr",
      "experience": "0-3 ans",
      "description": "Apprentissage, besoin d'accompagnement",
      "core_expected": [
        1,
        2
      ],
      "secondary_expected": [
        0,
        1
      ]
    },
    {
      "id": "confirmed",
      "name": "Confirmé",
      "abbreviation": "Cf",
      "experience": "3-5 ans",
      "description": "Autonome sur les tâches standards",
      "core_expected": [
        2,
        3
      ],
      "secondary_expected": [
        1,
        2
      ]
    },
    {
      "id": "senior",
      "name": "Senior",
      "abbreviation": "Sr",
      "experience": "5-10 ans",
      "description": "Expert technique, mentor",
      "core_expected": [
        3,
        4
      ],
      "secondary_expected": [
        2,
        3
      ]
    },
    {
      "id": "expert",
      "name": "Expert",
      "abbreviation": "Ex",
      "experience": "10+ ans",
      "description": "Vision stratégique, leadership technique",
      "core_expected": [
        4,
        5
      ],
      "secondary_expected": [
        3,
        4
      ]
    }
  ],
  "skill_levels": {
    "standard": [
      {
        "level": 0,
        "name": "Aucune connaissance",
        "description": "N'a jamais utilisé l'outil/technique"
      },
      {
        "level": 1,
        "name": "Débutant",
        "description": "Peut exécuter des tâches basiques avec assistance"
      },
      {
        "level": 2,
        "name": "Intermédiaire",
        "description": "Travaille de manière autonome sur des tâches standards"
      },
      {
        "level": 3,
        "name": "Avancé",
        "description": "Gère des scénarios complexes, peut guider les autres"
      },
      {
        "level": 4,
        "name": "Expert",
        "description": "Maîtrise complète, conçoit des solutions à grande échelle"
      }
    ],
    "bonus": [
      {
        "level": 5,
        "name": "Mentor/Évangéliste",
        "description": "Forme les équipes, établit les bonnes pratiques, champion interne"
      },
      {
        "level": 6,
        "name": "Expert Externe",
        "description": "Contributions open-source, conférences, reconnu comme expert"
      }
    ]
  },
  "categories": [
    {
      "id": "analytics",
      "name": "Analytics",
      "skill_count": 8
    },
    {
      "id": "business",
      "name": "Business",
      "skill_count": 5
    },
    {
      "id": "compliance",
      "name": "Compliance",
      "skill_count": 1
    },
    {
      "id": "engineering",
      "name": "Engineering",
      "skill_count": 10
    },
    {
      "id": "ml",
      "name": "Machine Learning",
      "skill_count": 6
    },
    {
      "id": "ops",
      "name": "Data Ops",
      "skill_count": 8
    },
    {
      "id": "soft_skills",
      "name": "Soft Skills",
      "skill_count": 9
    }
  ],
  "skills": [
    {
      "id": "sql_bigquery",
      "name": "SQL & BigQuery",
      "description": "Écrire des requêtes SQL optimisées sur BigQuery, maîtriser le partitionnement, clustering, vues matérialisées, slot reservations et gestion des coûts",
      "core_roles": [
        "data_analyst",
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          2,
          3,
          4,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance SQL",
        "1": "Je suis capable d'écrire des SELECT simples avec JOINs et WHERE basiques",
        "2": "Je suis capable d'écrire des CTEs, window functions et je crée des tables avec partitionnement et clustering",
        "3": "Je conçois l'architecture data warehouse d'un domaine, j'optimise les coûts et je configure les slot reservations",
        "4": "Je maîtrise BigQuery ML, le streaming, les vues matérialisées et je définis les standards pour l'organisation",
        "5": "Je conduis les revues d'architecture données et les audits de coûts BigQuery à l'échelle de l'entreprise",
        "6": "Contributeur BigQuery reconnu, speaker, expert externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux écrire SELECT, WHERE, GROUP BY sans aide",
          "Je sais faire un JOIN entre 2 tables",
          "Je navigue dans les datasets et l'interface BigQuery Console"
        ],
        "2": [
          "J'écris des CTEs (WITH) et window functions (ROW_NUMBER, LEAD, LAG) couramment",
          "Je crée des tables avec partitionnement et clustering",
          "J'analyse les coûts de mes requêtes et j'optimise pour les réduire",
          "J'utilise les vues matérialisées pour les agrégations fréquentes"
        ],
        "3": [
          "J'ai conçu l'architecture data warehouse d'un domaine",
          "Je configure les slot reservations et BI Engine",
          "Je lis et analyse les plans d'exécution pour optimiser les requêtes",
          "Je gère des requêtes sur des tables de plusieurs TB et j'ai réduit les coûts de 50%+"
        ],
        "4": [
          "J'utilise BigQuery ML et le streaming insert",
          "Je conçois des schémas de données optimisés et je maîtrise QUALIFY, PIVOT",
          "Je crée la documentation et les guidelines d'optimisation BigQuery pour l'équipe",
          "J'ai défini les conventions SQL et les standards de coûts du projet"
        ],
        "5": [
          "Je forme et mentore les équipes sur les requêtes SQL/BigQuery optimisées",
          "Je conduis les audits de performance et de coûts BigQuery à l'échelle de l'organisation",
          "Je définis les standards et bonnes pratiques SQL pour l'entreprise",
          "J'ai créé des standards SQL et des patterns d'architecture BigQuery adoptés par plusieurs équipes"
        ],
        "6": [
          "Je contribue à des projets open-source liés à BigQuery ou SQL",
          "J'ai présenté sur SQL/BigQuery à des conférences externes",
          "Je suis reconnu comme expert SQL/BigQuery en dehors de l'entreprise",
          "J'ai publié des articles ou tutoriels sur l'optimisation SQL"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-performance-overview",
          "title": "BigQuery Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://mode.com/sql-tutorial/",
          "title": "Mode SQL Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://www.cloudskillsboost.google/course_templates/53",
          "title": "BigQuery Fundamentals (Qwiklabs)",
          "type": "course"
        },
        {
          "url": "https://learnsql.com/blog/sql-window-functions-cheat-sheet/",
          "title": "Window Functions Cheat Sheet",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Pratiquez les CTEs et window functions. Appliquez le partitionnement et clustering sur vos tables les plus utilisées.",
        "2→3": "Concevez un data warehouse avec des couches distinctes. Implémentez les slot reservations et analysez les plans d'exécution.",
        "3→4": "Explorez BigQuery ML et le streaming. Menez un projet de refonte de modèle de données avec standards de coûts."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "statistical_analysis",
      "name": "Analyse Statistique & Expérimentation",
      "description": "Appliquer des méthodes statistiques, concevoir et analyser des tests A/B (puissance, significativité, interprétation)",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          2,
          3,
          4,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          1
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en statistiques",
        "1": "Je suis capable de calculer et interpréter les statistiques descriptives et je comprends le concept d'A/B test",
        "2": "Je réalise des tests d'hypothèses, j'analyse les résultats d'A/B tests et je calcule la significativité",
        "3": "Je conçois des expériences A/B complexes (multi-variés, calcul de puissance) et je maîtrise les méthodes statistiques avancées",
        "4": "Je définis la stratégie d'expérimentation, je maîtrise les approches bayésiennes et je guide les analyses complexes",
        "5": "Je valide les analyses complexes, je définis les méthodologies standard et je forme les équipes",
        "6": "Publication de recherche, contribution à la communauté statistique"
      },
      "behavioral_indicators": {
        "1": [
          "Je calcule et interprète moyenne, médiane, écart-type",
          "Je comprends la différence entre corrélation et causalité",
          "Je comprends pourquoi on fait des tests A/B et je sais lire les résultats"
        ],
        "2": [
          "J'ai réalisé un test t ou chi-carré sur des données réelles",
          "Je calcule la significativité statistique d'un A/B test et j'interprète les intervalles de confiance",
          "Je peux calculer et interpréter une régression linéaire",
          "Je sais détecter un test arrêté trop tôt et j'ai analysé au moins 5 A/B tests"
        ],
        "3": [
          "J'ai conçu et analysé un A/B test multi-varié de bout en bout",
          "Je calcule la puissance statistique et taille d'échantillon nécessaire",
          "J'utilise des méthodes comme ANOVA ou régression multiple",
          "Je segmente les résultats pour trouver des effets hétérogènes"
        ],
        "4": [
          "J'ai défini le framework d'expérimentation et les guidelines pour les PMs",
          "J'ai créé des guides et templates d'analyse statistique pour l'équipe",
          "Je gère les cas complexes (effet de nouveauté, contamination, biais)",
          "Je maîtrise les approches bayésiennes et je valide les analyses des autres"
        ],
        "5": [
          "Je forme et mentore les équipes sur l'analyse statistique et l'expérimentation",
          "Je définis les méthodologies statistiques et d'A/B testing standard de l'entreprise",
          "Je valide les analyses complexes et j'arbitre les choix méthodologiques",
          "J'ai créé des outils et calculateurs de tests réutilisables adoptés par plusieurs équipes"
        ],
        "6": [
          "Je contribue à des packages statistiques ou d'expérimentation open-source",
          "J'ai présenté sur les statistiques ou l'A/B testing à des conférences externes",
          "Je suis reconnu comme expert statistique en dehors de l'entreprise",
          "J'ai des publications ou articles sur les méthodes statistiques"
        ]
      },
      "resources": [
        {
          "url": "https://www.khanacademy.org/math/statistics-probability",
          "title": "Khan Academy Statistics",
          "type": "course"
        },
        {
          "url": "https://www.udacity.com/course/ab-testing--ud257",
          "title": "A/B Testing by Google (Udacity)",
          "type": "course"
        },
        {
          "url": "https://seeing-theory.brown.edu/",
          "title": "Seeing Theory - Visual Statistics",
          "type": "tutorial"
        },
        {
          "url": "https://www.evanmiller.org/ab-testing/",
          "title": "Evan Miller's A/B Testing Tools",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez les tests d'hypothèses (t-test, chi-carré). Analysez les résultats d'A/B tests passés de l'entreprise.",
        "2→3": "Maîtrisez le calcul de puissance et de taille d'échantillon. Concevez un test multi-varié de bout en bout.",
        "3→4": "Explorez les méthodes bayésiennes. Définissez le framework d'expérimentation de votre équipe."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "insight_generation",
      "name": "Génération d'Insights",
      "description": "Transformer les données en recommandations business actionnables",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Ne peut pas générer d'insights",
        "1": "Je suis capable de décrire ce que montrent les données et de faire des observations basiques",
        "2": "Je suis capable d'identifier les patterns, tendances et anomalies en les reliant au contexte métier",
        "3": "Je suis capable de générer des insights stratégiques et je comprends la théorie du data storytelling pour produire des recommandations actionnables",
        "4": "Je suis capable de piloter la prise de décision data-driven au niveau organisationnel et je comprends les enjeux stratégiques pour influencer les décisions",
        "5": "Je pilote la stratégie de communication data de l'entreprise, je définis les standards d'insights et je forme les équipes au data storytelling",
        "6": "Reconnu comme expert en data storytelling"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux décrire les chiffres clés d'un dashboard",
          "Je réponds aux questions 'combien' et 'quand'",
          "Je présente les données sans interprétation approfondie"
        ],
        "2": [
          "J'identifie les tendances et anomalies dans les données",
          "Je pose la question 'pourquoi' après chaque observation",
          "Je relie les données au contexte métier",
          "Je peux expliquer l'impact potentiel d'un changement observé"
        ],
        "3": [
          "Je produis des analyses qui mènent à des décisions concrètes",
          "Je propose des recommandations actionnables avec les données",
          "J'anticipe les questions des stakeholders",
          "J'ai influencé au moins une décision stratégique avec mes analyses"
        ],
        "4": [
          "Je pilote des initiatives data-driven à l'échelle de l'organisation",
          "Les dirigeants me consultent pour des décisions importantes",
          "J'ai mis en place un framework de data storytelling pour l'organisation",
          "J'ai un track record d'impacts mesurables"
        ],
        "5": [
          "Je forme et mentore les équipes sur la génération d'insights et le data storytelling",
          "Je définis les standards de communication des insights pour l'entreprise",
          "Je pilote les décisions stratégiques nécessitant une analyse de données",
          "J'ai mis en place des frameworks d'insights adoptés par plusieurs équipes"
        ],
        "6": [
          "Je contribue à la communauté data storytelling (blogs, open-source)",
          "J'ai présenté sur la génération d'insights à des conférences externes",
          "Je suis reconnu comme expert data storytelling en dehors de l'entreprise",
          "J'ai des publications ou articles sur l'analyse de données business"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://www.coursera.org/learn/analytics-business",
          "title": "Business Analytics (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2013/03/know-the-difference-between-your-data-and-your-metrics",
          "title": "HBR - Data vs Metrics",
          "type": "documentation"
        },
        {
          "url": "https://amplitude.com/blog/data-storytelling",
          "title": "Data Storytelling Guide",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Pour vos 5 prochaines analyses, ajoutez systématiquement un paragraphe contexte métier et une section implications. Posez la question 'So what?' après chaque observation.",
        "2→3": "Avant chaque présentation, listez 10 questions que les stakeholders pourraient poser. Terminez chaque analyse par 3 recommandations concrètes avec impact estimé.",
        "3→4": "Menez des projets d'impact stratégique. Présentez régulièrement au COMEX ou équivalent."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "ml_fundamentals",
      "name": "Fondamentaux ML",
      "description": "Comprendre et appliquer les concepts de Machine Learning",
      "core_roles": [
        "data_scientist",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance ML",
        "1": "Je suis capable de comprendre les concepts de base (supervisé vs non-supervisé, classification vs régression)",
        "2": "Je suis capable d'implémenter des modèles ML basiques avec scikit-learn et je comprends le compromis biais-variance",
        "3": "Je suis capable de sélectionner les algorithmes appropriés et je comprends la théorie de l'optimisation des hyperparamètres",
        "4": "Je suis capable de concevoir des solutions ML de bout en bout et je comprends la théorie pour optimiser les performances en profondeur",
        "5": "Je conçois les architectures ML de référence, je définis les standards ML pour l'entreprise et je forme les équipes sur le Machine Learning",
        "6": "Contributeur open-source ML, publications, conférences"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends la différence entre supervisé et non-supervisé",
          "Je sais expliquer ce qu'est l'overfitting",
          "Je connais les algorithmes classiques (régression, arbre de décision)",
          "J'ai suivi un cours d'introduction au ML"
        ],
        "2": [
          "J'ai entraîné un modèle scikit-learn sur des données réelles",
          "Je sais faire un train/test split correctement",
          "Je comprends les métriques de base (accuracy, precision, recall)",
          "J'ai participé à un projet ML même en support"
        ],
        "3": [
          "Je choisis l'algorithme adapté selon le problème",
          "Je fais de l'optimisation d'hyperparamètres (GridSearch, RandomSearch)",
          "J'utilise la validation croisée systématiquement",
          "J'ai déployé au moins un modèle en production"
        ],
        "4": [
          "Je conçois l'architecture ML complète d'un projet",
          "Je maîtrise les techniques avancées (ensemble, boosting)",
          "Je gère le monitoring et retraining des modèles",
          "J'ai documenté les bonnes pratiques ML et créé des templates de projets ML"
        ],
        "5": [
          "Je forme et mentore les équipes sur le Machine Learning",
          "Je définis les standards et bonnes pratiques ML pour l'entreprise",
          "J'arbitre les choix d'architecture et d'algorithmes ML pour les projets critiques",
          "J'ai mis en place des pipelines et outils ML adoptés par plusieurs équipes"
        ],
        "6": [
          "Je contribue à des projets open-source ML (scikit-learn, TensorFlow, etc.)",
          "J'ai présenté sur le ML à des conférences externes",
          "Je suis reconnu comme expert ML en dehors de l'entreprise",
          "J'ai des publications ou articles de recherche sur le ML"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/machine-learning",
          "title": "Machine Learning by Andrew Ng",
          "type": "course"
        },
        {
          "url": "https://scikit-learn.org/stable/tutorial/index.html",
          "title": "Scikit-learn Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://www.statlearning.com/",
          "title": "Introduction to Statistical Learning",
          "type": "book"
        },
        {
          "url": "https://madewithml.com/",
          "title": "Made with ML",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez les algorithmes classiques (régression, arbres de décision, clustering) sur des datasets publics.",
        "2→3": "Apprenez la validation croisée et l'optimisation d'hyperparamètres. Participez à une compétition Kaggle.",
        "3→4": "Développez un projet ML complet en production. Maîtrisez le monitoring et le retraining des modèles."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "product_metrics",
      "name": "Product & Behavioral Analytics",
      "description": "Définition et suivi des métriques produit (DAU/MAU, rétention, churn, LTV), analyse de cohortes, funnel analysis, parcours utilisateur et segmentation comportementale",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des métriques produit et de l'analyse comportementale",
        "1": "Je comprends les métriques basiques (DAU, MAU, conversion) et les concepts de funnel et de cohorte",
        "2": "Je calcule les métriques de rétention par cohorte, j'analyse les funnels et je construis des dashboards de suivi",
        "3": "Je définis les KPIs stratégiques, je conçois des segmentations comportementales avancées et je maîtrise les fondements théoriques",
        "4": "Je guide la stratégie produit basée sur les données, je prédis les comportements et je conçois des frameworks de métriques",
        "5": "Je pilote les décisions stratégiques basées sur les données et je forme les équipes sur le product analytics",
        "6": "Expert product analytics reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais ce que signifient DAU, MAU, et taux de conversion",
          "Je comprends ce qu'est un funnel de conversion et une analyse de cohorte",
          "Je peux lire un dashboard de métriques produit et identifier les étapes clés d'un parcours"
        ],
        "2": [
          "Je calcule les cohortes de rétention (D1, D7, D30)",
          "J'analyse les taux de conversion par étape du funnel et j'identifie les points de friction",
          "Je segmente les métriques par source d'acquisition",
          "J'ai construit un dashboard de KPIs produit"
        ],
        "3": [
          "J'ai défini la North Star Metric de mon équipe",
          "Je crée des segments comportementaux (power users, at-risk, dormants)",
          "J'analyse les parcours utilisateur complets et j'identifie les comportements prédictifs de la rétention",
          "Je propose des objectifs quantifiés basés sur les données"
        ],
        "4": [
          "J'ai défini le framework de métriques de l'organisation",
          "Je construis des modèles prédictifs de churn et j'automatise les alertes",
          "Je présente les KPIs au COMEX régulièrement",
          "J'ai créé un guide et des templates pour aider les PMs à définir leurs métriques de succès"
        ],
        "5": [
          "Je forme et mentore les équipes sur les métriques produit et l'analyse comportementale",
          "Je définis les standards et frameworks de métriques pour l'entreprise",
          "Je pilote les décisions stratégiques impliquant les KPIs produit",
          "J'ai créé des frameworks de segmentation et de suivi de KPIs réutilisables"
        ],
        "6": [
          "Je contribue à la communauté product analytics (blogs, outils open-source)",
          "J'ai présenté sur le product analytics à des conférences externes",
          "Je suis reconnu comme expert product analytics en dehors de l'entreprise",
          "J'ai des publications ou articles sur les métriques et l'analyse comportementale"
        ]
      },
      "resources": [
        {
          "url": "https://amplitude.com/blog/product-metrics",
          "title": "Guide to Product Metrics",
          "type": "documentation"
        },
        {
          "url": "https://amplitude.com/blog/cohort-analysis",
          "title": "Cohort Analysis Guide",
          "type": "tutorial"
        },
        {
          "url": "https://mixpanel.com/blog/product-analytics-guide/",
          "title": "Product Analytics Guide (Mixpanel)",
          "type": "tutorial"
        },
        {
          "url": "https://www.lennysnewsletter.com/p/what-is-good-retention-issue-29",
          "title": "What is Good Retention (Lenny's Newsletter)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Calculez les métriques de rétention de votre produit par cohorte. Analysez un funnel de conversion et identifiez les points de friction.",
        "2→3": "Définissez la North Star Metric de votre équipe. Créez des segments comportementaux (power users, at-risk).",
        "3→4": "Créez un framework de métriques pour toute l'organisation. Développez des modèles prédictifs de churn."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "attribution_marketing",
      "name": "Attribution & Marketing Analytics",
      "description": "Modèles d'attribution, analyse des canaux d'acquisition, ROI campagnes, UTM tracking",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'attribution marketing",
        "1": "Je comprends les UTM et le tracking des sources d'acquisition",
        "2": "J'analyse les performances par canal et je calcule le ROI des campagnes marketing",
        "3": "J'implémente des modèles d'attribution multi-touch, j'optimise les budgets et je maîtrise les fondements théoriques des différents modèles d'attribution",
        "4": "Je conçois la stratégie de mesure marketing complète, je gère les contraintes de privacy et je comprends les limites théoriques de chaque approche d'attribution",
        "5": "Je pilote les décisions d'allocation budgétaire basées sur les données, je définis les standards d'attribution pour l'entreprise et je forme les équipes sur le marketing analytics",
        "6": "Expert marketing analytics reconnu, conférences"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce que sont les paramètres UTM",
          "Je sais ce qu'est l'attribution last-click",
          "Je peux identifier la source d'acquisition d'un utilisateur"
        ],
        "2": [
          "Je calcule le CAC (coût d'acquisition) par canal",
          "J'analyse le ROI des campagnes marketing",
          "Je compare les performances des différents canaux",
          "J'ai configuré le tracking UTM pour des campagnes"
        ],
        "3": [
          "J'implémente des modèles d'attribution multi-touch",
          "Je compare les résultats first-click vs last-click vs linear",
          "Je propose des réallocations de budget basées sur les données",
          "Je gère les problèmes de tracking cross-device"
        ],
        "4": [
          "J'ai défini la stratégie de mesure marketing complète",
          "Je challenge les attributions des agences media",
          "J'ai créé les dashboards et rapports d'attribution de référence pour le marketing",
          "Je gère les problèmes de privacy (iOS 14.5, GDPR)"
        ],
        "5": [
          "Je forme et mentore les équipes sur le marketing analytics et l'attribution",
          "Je définis les standards et modèles d'attribution pour l'entreprise",
          "Je pilote les décisions d'allocation budgétaire et de stratégie d'attribution",
          "J'ai créé des frameworks d'attribution réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source de marketing analytics",
          "J'ai présenté sur l'attribution à des conférences marketing externes",
          "Je suis reconnu comme expert marketing analytics en dehors de l'entreprise",
          "J'ai des publications ou articles sur l'attribution et le marketing analytics"
        ]
      },
      "resources": [
        {
          "url": "https://support.google.com/analytics/answer/10596866",
          "title": "Google Analytics Attribution",
          "type": "documentation"
        },
        {
          "url": "https://www.thinkwithgoogle.com/intl/en-gb/marketing-strategies/data-and-measurement/marketing-attribution-models/",
          "title": "Attribution Models (Think with Google)",
          "type": "documentation"
        },
        {
          "url": "https://segment.com/academy/collecting-data/naming-conventions-for-clean-data/",
          "title": "UTM Best Practices",
          "type": "tutorial"
        },
        {
          "url": "https://www.coursera.org/learn/marketing-analytics",
          "title": "Marketing Analytics (Coursera)",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les performances de vos canaux d'acquisition. Calculez le CAC par canal.",
        "2→3": "Implémentez un modèle d'attribution multi-touch. Comparez les résultats avec le last-click.",
        "3→4": "Définissez la stratégie de mesure marketing complète. Optimisez l'allocation budgétaire data-driven."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "tracking_design",
      "name": "Design de Tracking",
      "description": "Conception de taxonomies d'events, data contracts, plan de taggage, documentation",
      "core_roles": [
        "analytics_eng",
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du design de tracking",
        "1": "Je comprends l'importance d'un plan de taggage structuré et je sais lire la documentation existante",
        "2": "Je documente les events existants et je propose des améliorations au tracking",
        "3": "Je conçois des taxonomies d'events cohérentes, je définis les data contracts et je maîtrise les principes théoriques de gouvernance des données événementielles",
        "4": "J'établis les standards de tracking pour l'organisation, j'automatise la validation et je comprends les architectures de collecte de données dans leur ensemble",
        "5": "Je conçois l'architecture de tracking de référence, je définis les standards de gouvernance des données pour l'entreprise et je forme les équipes sur le design de tracking",
        "6": "Expert data governance reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends pourquoi un plan de taggage est important",
          "Je sais ce qu'est un event et ses propriétés",
          "Je peux lire la documentation de tracking existante"
        ],
        "2": [
          "J'ai documenté les events d'une feature",
          "J'identifie les incohérences dans le nommage des events",
          "Je propose des améliorations au tracking existant",
          "Je valide que le tracking est bien implémenté"
        ],
        "3": [
          "J'ai conçu une taxonomie d'events pour un domaine",
          "Je définis des data contracts avec les équipes produit",
          "J'utilise un outil de gestion de tracking (Avo, Amplitude)",
          "Je mets en place un processus de validation du tracking"
        ],
        "4": [
          "J'ai défini les standards de tracking de l'organisation",
          "J'audite la qualité du tracking des différentes équipes",
          "J'ai créé la documentation et les guidelines de tracking pour les développeurs",
          "J'automatise la validation et les alertes de qualité"
        ],
        "5": [
          "Je forme et mentore les équipes sur le design de tracking et la gouvernance des données",
          "Je définis les standards et taxonomies de tracking pour l'entreprise",
          "Je conçois les architectures de tracking et j'arbitre les choix de data governance",
          "J'ai créé des outils et templates de plan de taggage réutilisables"
        ],
        "6": [
          "Je contribue à des outils open-source de data governance",
          "J'ai présenté sur le design de tracking à des conférences externes",
          "Je suis reconnu comme expert data governance en dehors de l'entreprise",
          "J'ai des publications ou articles sur le tracking et data contracts"
        ]
      },
      "resources": [
        {
          "url": "https://segment.com/academy/collecting-data/how-to-create-a-tracking-plan/",
          "title": "How to Create a Tracking Plan",
          "type": "tutorial"
        },
        {
          "url": "https://www.avo.app/blog/tracking-plan-best-practices",
          "title": "Tracking Plan Best Practices (Avo)",
          "type": "documentation"
        },
        {
          "url": "https://snowplow.io/blog/event-data-structure",
          "title": "Event Data Structure (Snowplow)",
          "type": "documentation"
        },
        {
          "url": "https://datacontract.com/",
          "title": "Data Contract Specification",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Documentez les events existants dans votre produit. Identifiez les incohérences de nommage.",
        "2→3": "Créez une taxonomie d'events standardisée. Mettez en place un processus de validation.",
        "3→4": "Implémentez des data contracts avec les équipes produit. Automatisez la validation du tracking."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "dashboard_design",
      "name": "Design de Dashboards & Outils BI",
      "description": "Concevoir des visualisations de données efficaces, maîtriser les outils BI (Metabase, Looker, Tableau) et pratiquer le storytelling data",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en visualisation et outils BI",
        "1": "Je navigue dans les dashboards existants et je crée des graphiques simples et lisibles",
        "2": "Je conçois des dashboards clairs dans un outil BI (Metabase, Looker) en suivant les bonnes pratiques",
        "3": "Je crée des data stories convaincantes, des dashboards interactifs complexes et je maîtrise les fonctionnalités avancées des outils BI",
        "4": "Je définis les standards de dataviz et les bonnes pratiques BI pour l'organisation, je forme les équipes",
        "5": "Je conçois un design system dataviz réutilisable et je pilote la stratégie de visualisation à l'échelle de l'organisation",
        "6": "Expert dataviz reconnu, publications, formations externes"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais quand utiliser un bar chart vs line chart",
          "Je comprends l'importance des titres et labels",
          "Je navigue dans les dashboards Metabase/Looker existants et j'applique des filtres",
          "Je peux exporter des données depuis un outil BI"
        ],
        "2": [
          "Je crée des dashboards dans Metabase/Looker avec des filtres interactifs",
          "Je respecte les bonnes pratiques (pas de 3D, couleurs cohérentes, hiérarchie visuelle)",
          "Je place les KPIs importants en haut du dashboard",
          "Je choisis les échelles appropriées (pas d'axes tronqués trompeurs)"
        ],
        "3": [
          "Je crée des data stories avec un fil conducteur",
          "J'utilise les fonctionnalités avancées des outils BI (SQL natif, variables, drill-down, derived tables)",
          "Mes dashboards guident l'utilisateur vers les insights",
          "Je configure les alertes et subscriptions dans les outils BI"
        ],
        "4": [
          "J'ai défini un style guide dataviz pour l'équipe",
          "J'ai créé des templates de dashboards et une documentation des bonnes pratiques BI",
          "Mes dashboards sont cités en exemple dans l'organisation",
          "Je maîtrise les techniques avancées (small multiples, annotations)"
        ],
        "5": [
          "Je conçois et maintiens un design system dataviz réutilisable",
          "Je définis les standards de visualisation et les bonnes pratiques BI pour l'entreprise",
          "Je forme et mentor les équipes sur le design de dashboards",
          "J'administre les outils BI et définis les conventions de gouvernance du contenu"
        ],
        "6": [
          "Je contribue à des projets open-source de visualisation (D3.js, etc.)",
          "J'ai présenté sur la dataviz à des conférences externes",
          "Je suis reconnu comme expert dataviz en dehors de l'entreprise",
          "J'ai des publications ou articles sur la visualisation de données"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://www.data-to-viz.com/",
          "title": "From Data to Viz - Chart Selection",
          "type": "tutorial"
        },
        {
          "url": "https://www.metabase.com/learn/",
          "title": "Metabase Learn",
          "type": "tutorial"
        },
        {
          "url": "https://nightingaledvs.com/",
          "title": "Nightingale - Data Visualization Society",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez votre premier dashboard dans Metabase ou Looker avec des filtres interactifs. Apprenez quand utiliser chaque type de graphique.",
        "2→3": "Créez une data story complète avec un fil conducteur. Maîtrisez les fonctionnalités avancées de votre outil BI (SQL natif, drill-down).",
        "3→4": "Développez un style guide de dataviz pour votre organisation. Formez les équipes aux bonnes pratiques BI."
      },
      "category": "analytics",
      "category_name": "Analytics"
    },
    {
      "id": "cultural_recommendation",
      "name": "Recommandation Culturelle",
      "description": "Comprendre les enjeux de la recommandation d'offres culturelles: diversification, découverte, sérendipité, équilibre popularité/niche",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la recommandation culturelle",
        "1": "Je comprends les enjeux de diversité et découverte culturelle propres au Pass Culture",
        "2": "Je maîtrise les métriques spécifiques (diversité, sérendipité, taux de découverte) et l'équilibre explore/exploit",
        "3": "Je conçois des stratégies de recommandation adaptées aux objectifs de politique publique",
        "4": "J'équilibre popularité et découverte de niches et je définis la stratégie de recommandation",
        "5": "Je définis la roadmap stratégique de recommandation et je mesure l'impact des algorithmes sur les pratiques culturelles",
        "6": "Expert reco culturelle reconnu, publications académiques sur la diversification"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les objectifs de diversification culturelle",
          "Je connais les risques des bulles de filtre",
          "Je sais ce qu'est la sérendipité dans un contexte culturel"
        ],
        "2": [
          "Je calcule les métriques de diversité (coverage, novelty)",
          "Je mesure le taux de découverte de nouveaux domaines",
          "J'analyse l'impact des recommandations sur la diversification",
          "Je comprends l'équilibre explore/exploit"
        ],
        "3": [
          "Je conçois des stratégies de recommandation pour la diversification",
          "J'intègre les objectifs de politique publique dans les algorithmes",
          "Je mesure l'impact à long terme sur les pratiques culturelles",
          "J'ai contribué à améliorer les recommandations du Pass Culture"
        ],
        "4": [
          "Je définis la stratégie de recommandation de l'organisation",
          "J'équilibre popularité et découverte de niches",
          "Je publie sur la recommandation culturelle",
          "Je forme les équipes aux enjeux spécifiques"
        ],
        "5": [
          "Je définis la roadmap stratégique de recommandation",
          "Je mesure l'impact des algorithmes sur les pratiques culturelles",
          "Je contribue aux décisions éthiques de recommandation",
          "Je forme les équipes produit et direction aux enjeux de la reco"
        ],
        "6": [
          "Je publie des articles académiques sur la recommandation culturelle",
          "Je suis speaker dans des conférences RecSys ou similaires",
          "Je suis consulté par d'autres organisations sur leurs stratégies",
          "Je suis reconnu comme expert de la recommandation culturelle"
        ]
      },
      "resources": [
        {
          "url": "https://research.netflix.com/publications",
          "title": "Netflix Research - Recommendations",
          "type": "documentation"
        },
        {
          "url": "https://recsys.acm.org/",
          "title": "ACM RecSys Conference",
          "type": "documentation"
        },
        {
          "url": "https://arxiv.org/list/cs.IR/recent",
          "title": "arXiv - Information Retrieval",
          "type": "documentation"
        },
        {
          "url": "https://eugeneyan.com/writing/system-design-for-discovery/",
          "title": "System Design for Discovery",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Comprenez les métriques de diversité (coverage, novelty, serendipity). Analysez l'impact des recos actuelles.",
        "2→3": "Concevez des expériences pour mesurer la diversification. Équilibrez explore/exploit.",
        "3→4": "Publiez vos recherches. Contribuez aux discussions académiques sur la recommandation culturelle."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "cultural_ecosystem",
      "name": "Écosystème Culturel Français",
      "description": "Connaître les acteurs culturels (librairies, cinémas, salles de spectacle, musées, festivals), leurs enjeux économiques et territoriaux, ainsi que le fonctionnement du secteur public culturel (Ministère de la Culture, tutelle, établissements publics)",
      "core_roles": [
        "data_analyst"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'écosystème culturel",
        "1": "Je connais les grandes catégories d'acteurs culturels partenaires",
        "2": "Je maîtrise les spécificités par secteur (librairies indépendantes, cinémas art et essai, scènes nationales...)",
        "3": "Je comprends en profondeur les enjeux économiques et territoriaux de chaque secteur culturel",
        "4": "Je contextualise les analyses selon les dynamiques sectorielles et je conseille les équipes sur l'écosystème",
        "5": "Je définis les orientations stratégiques liées à l'écosystème culturel et je forme la direction",
        "6": "Influence les politiques culturelles, expert auprès du ministère de la Culture"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les types d'acteurs culturels partenaires",
          "Je comprends le rôle des librairies, cinémas, musées",
          "Je sais ce qu'est un acteur culturel vs un offreur"
        ],
        "2": [
          "Je connais les spécificités des librairies indépendantes",
          "Je comprends les enjeux des cinémas art et essai",
          "Je sais ce qu'est une scène nationale ou conventionnée",
          "Je comprends le rôle du Ministère de la Culture et la relation de tutelle avec le pass Culture"
        ],
        "3": [
          "Je comprends les enjeux économiques par secteur",
          "J'analyse les dynamiques territoriales (zones rurales, QPV)",
          "Je connais les fédérations et syndicats professionnels",
          "Je contextualise mes analyses selon les réalités sectorielles"
        ],
        "4": [
          "Je contextualise les analyses data selon les dynamiques de chaque secteur culturel",
          "Je participe aux échanges avec les partenaires institutionnels",
          "Je contribue aux rapports sur l'écosystème",
          "Je forme les équipes aux spécificités des acteurs culturels"
        ],
        "5": [
          "Je définis les orientations stratégiques sur l'écosystème",
          "Je suis l'interlocuteur privilégié des fédérations professionnelles",
          "Je contribue aux réflexions de politique publique sur les secteurs",
          "Je forme la direction aux enjeux de l'écosystème"
        ],
        "6": [
          "J'interviens auprès du ministère en tant qu'expert de l'écosystème culturel",
          "Je publie des études sur l'écosystème culturel français",
          "Je donne des conférences sur les enjeux des acteurs culturels",
          "Je suis reconnu comme expert de référence de l'écosystème"
        ]
      },
      "resources": [
        {
          "url": "https://www.culture.gouv.fr/Thematiques/Industries-culturelles",
          "title": "Industries culturelles",
          "type": "documentation"
        },
        {
          "url": "https://www.syndicat-librairie.fr/",
          "title": "Syndicat de la librairie française",
          "type": "documentation"
        },
        {
          "url": "https://www.fncf.org/",
          "title": "FNCF - Cinémas",
          "type": "documentation"
        },
        {
          "url": "https://sdicine.fr/",
          "title": "SDI - Syndicat des Distributeurs Indépendants",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Étudiez les différents types d'acteurs culturels. Comprenez leurs enjeux économiques.",
        "2→3": "Analysez les dynamiques territoriales. Identifiez les zones en tension.",
        "3→4": "Contribuez aux discussions avec les partenaires institutionnels. Publiez des analyses sectorielles."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "cultural_impact_measurement",
      "name": "Mesure d'Impact Culturel",
      "description": "Évaluer l'impact du Pass Culture: études cohortes, diversification des pratiques, découverte culturelle, réitération post-crédit",
      "core_roles": [
        "data_analyst",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "backend": [
          "NC",
          "NC",
          "NC",
          1
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la mesure d'impact",
        "1": "Je comprends les indicateurs clés d'impact (taux d'utilisation, diversification, découverte)",
        "2": "J'analyse les cohortes sortantes et je mesure l'évolution des pratiques culturelles",
        "3": "Je conçois des méthodologies d'évaluation d'impact (enquêtes, analyse comportementale)",
        "4": "Je produis les rapports pour les instances institutionnelles et je définis la stratégie d'évaluation",
        "5": "Je définis la stratégie globale d'évaluation d'impact et je coordonne les études avec les partenaires externes",
        "6": "Expert reconnu en évaluation d'impact, publications académiques"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les indicateurs d'impact du Pass Culture",
          "Je connais le taux d'utilisation et de diversification",
          "Je sais ce qu'est une étude de cohorte"
        ],
        "2": [
          "J'analyse les cohortes sortantes (18-19 ans)",
          "Je mesure l'évolution des pratiques culturelles",
          "Je calcule les indicateurs de découverte et réitération",
          "Je contribue aux tableaux de bord d'impact"
        ],
        "3": [
          "Je conçois des méthodologies d'évaluation d'impact",
          "Je croise les données comportementales et déclaratives",
          "J'analyse la réitération post-crédit",
          "Je produis des études d'impact structurées"
        ],
        "4": [
          "Je suis expert en évaluation de politiques publiques",
          "Je produis les rapports pour les instances institutionnelles",
          "Je définis la stratégie d'évaluation",
          "Je forme les équipes à la mesure d'impact"
        ],
        "5": [
          "Je définis la stratégie globale d'évaluation d'impact pour l'entreprise",
          "Je coordonne les études d'impact avec des partenaires externes et les instances de tutelle",
          "Je forme la direction et les équipes à l'évaluation d'impact",
          "Mon travail sur l'évaluation d'impact influence les décisions stratégiques de l'organisation"
        ],
        "6": [
          "Je publie des articles académiques sur l'évaluation d'impact culturel",
          "J'ai conseillé d'autres institutions publiques sur l'évaluation d'impact",
          "Je donne des conférences sur l'évaluation des politiques culturelles",
          "Je suis reconnu comme expert de référence en évaluation d'impact"
        ]
      },
      "resources": [
        {
          "url": "https://www.sciencespo.fr/liepp/fr/content/evaluation-des-politiques-publiques",
          "title": "Sciences Po - Évaluation politiques publiques",
          "type": "documentation"
        },
        {
          "url": "https://www.strategie.gouv.fr/themes/evaluation",
          "title": "France Stratégie - Évaluation",
          "type": "documentation"
        },
        {
          "url": "https://www.jpal.org/research",
          "title": "J-PAL - Impact Evaluation",
          "type": "documentation"
        },
        {
          "url": "https://www.povertyactionlab.org/sites/default/files/research-resources/practical-guide-evaluating-impact.pdf",
          "title": "Guide pratique évaluation d'impact",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les indicateurs d'impact existants. Comprenez la méthodologie des études cohortes.",
        "2→3": "Contribuez à une étude d'impact. Concevez des indicateurs complémentaires.",
        "3→4": "Menez une étude d'impact de bout en bout. Présentez aux instances institutionnelles."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "organisation_pass",
      "name": "Connaissance de l'Organisation du Pass",
      "description": "Comprendre la structure organisationnelle du pass Culture, ses processus internes, les parties prenantes clés, les interactions entre équipes (produit, tech, data, opérations, partenariats) et savoir naviguer efficacement dans l'organisation",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'organisation du pass Culture",
        "1": "Je connais les équipes principales et l'organigramme général du pass Culture",
        "2": "Je comprends les processus internes, les interactions entre équipes et les circuits de décision",
        "3": "Je navigue efficacement dans l'organisation, j'influence les décisions transverses et je facilite la collaboration inter-équipes",
        "4": "J'ai une compréhension stratégique de l'organisation, j'anticipe les évolutions structurelles et je contribue à l'amélioration des processus",
        "5": "J'optimise les processus transverses et je conseille la direction sur l'organisation",
        "6": "Expert en organisation d'établissements publics numériques, contribue aux réflexions sectorielles"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les équipes du pass Culture et leurs missions principales",
          "Je sais identifier le bon interlocuteur pour une question donnée",
          "Je comprends l'organigramme et les rattachements hiérarchiques"
        ],
        "2": [
          "Je comprends les processus de décision et les circuits de validation",
          "Je connais les rituels d'équipe et les instances de gouvernance",
          "Je sais comment les équipes produit, tech et data interagissent au quotidien",
          "Je comprends le rôle des parties prenantes externes (tutelle, partenaires)"
        ],
        "3": [
          "Je facilite la collaboration entre équipes sur des sujets transverses",
          "J'influence les décisions en m'appuyant sur ma connaissance de l'organisation",
          "Je sais anticiper les impacts organisationnels d'un projet data",
          "Je contribue à l'amélioration des processus inter-équipes"
        ],
        "4": [
          "J'ai une vision stratégique de l'organisation et de ses évolutions",
          "Je conseille les nouveaux arrivants sur le fonctionnement de l'organisation",
          "Je contribue aux réflexions sur l'évolution de la structure organisationnelle",
          "Je suis un relais efficace entre la direction et les équipes opérationnelles"
        ],
        "5": [
          "Je définis et optimise les processus transverses de l'organisation",
          "Je suis consulté par la direction sur les sujets organisationnels",
          "Je facilite les transformations organisationnelles majeures",
          "Je forme les managers aux bonnes pratiques de collaboration"
        ],
        "6": [
          "Je suis reconnu comme expert en organisation d'établissements publics numériques",
          "Je contribue aux réflexions sectorielles sur l'organisation des structures culturelles",
          "Je publie sur les modèles organisationnels innovants dans le secteur public",
          "J'ai conseillé d'autres organisations publiques sur leur fonctionnement"
        ]
      },
      "resources": [
        {
          "url": "https://pass.culture.fr/nous-rejoindre/",
          "title": "Pass Culture - Nous rejoindre (présentation de l'organisation)",
          "type": "documentation"
        },
        {
          "url": "https://www.welcometothejungle.com/fr/companies/pass-culture",
          "title": "Pass Culture sur Welcome to the Jungle",
          "type": "documentation"
        },
        {
          "url": "https://teamtopologies.com/key-concepts",
          "title": "Team Topologies - Concepts clés d'organisation",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Participez aux rituels inter-équipes. Comprenez les circuits de décision et les rôles de chaque partie prenante.",
        "2→3": "Prenez en charge des sujets transverses impliquant plusieurs équipes. Développez votre réseau interne et votre capacité d'influence.",
        "3→4": "Contribuez aux réflexions stratégiques sur l'organisation. Mentorez les nouveaux arrivants sur le fonctionnement interne."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "ecosysteme_technique",
      "name": "Connaissance de l'Écosystème Technique",
      "description": "Connaître le socle technique du pass Culture (stack applicative, infrastructure, flux de données, outils internes), comprendre l'architecture globale et les interconnexions entre systèmes pour contextualiser les choix techniques et contribuer aux décisions d'architecture",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'écosystème technique",
        "1": "Je connais les composants principaux de la stack technique (applications, bases de données, outils data)",
        "2": "Je comprends l'architecture globale, les flux de données et les interactions entre systèmes",
        "3": "Je maîtrise les choix techniques, les compromis d'architecture et je sais proposer des évolutions argumentées",
        "4": "J'ai une vision stratégique de l'écosystème technique et je contribue aux décisions d'architecture structurantes",
        "5": "Je définis la stratégie technique et l'évolution de l'écosystème à moyen/long terme",
        "6": "Expert reconnu en architecture de plateformes culturelles numériques, influence le secteur"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les principaux composants de la stack (API, base de données, data warehouse, outils BI)",
          "Je sais quels outils sont utilisés pour l'ingestion, le stockage et la restitution des données",
          "Je comprends le rôle de chaque brique technique dans l'écosystème global"
        ],
        "2": [
          "Je comprends l'architecture globale et les flux de données entre systèmes",
          "Je sais comment les données transitent de la production au data warehouse",
          "Je connais les APIs internes et externes utilisées par le pass Culture",
          "Je comprends les choix d'infrastructure (cloud, orchestration, monitoring)"
        ],
        "3": [
          "Je maîtrise les compromis techniques derrière les choix d'architecture actuels",
          "Je propose des évolutions techniques argumentées et adaptées au contexte",
          "Je suis capable d'évaluer l'impact technique d'un nouveau besoin métier",
          "Je contribue aux revues d'architecture et aux ADR (Architecture Decision Records)"
        ],
        "4": [
          "J'ai une vision stratégique de l'évolution de l'écosystème technique",
          "Je contribue aux décisions d'architecture structurantes pour l'organisation",
          "J'oriente les choix de stack et d'infrastructure en fonction de la stratégie technique",
          "Je forme les équipes aux principes d'architecture et aux bonnes pratiques"
        ],
        "5": [
          "Je définis la roadmap technique et l'évolution de la plateforme",
          "Je suis consulté par la direction sur les investissements techniques",
          "Je coordonne les chantiers d'architecture transverses",
          "Je forme les tech leads aux enjeux stratégiques de l'écosystème"
        ],
        "6": [
          "Je suis reconnu comme expert en architecture de plateformes numériques culturelles",
          "Je publie sur les architectures data et les choix techniques innovants",
          "Je suis speaker dans des conférences techniques (Devoxx, DataEngConf, etc.)",
          "J'ai conseillé d'autres organisations publiques sur leurs choix d'architecture technique"
        ]
      },
      "resources": [
        {
          "url": "https://github.com/pass-culture",
          "title": "Pass Culture - Dépôts GitHub publics",
          "type": "documentation"
        },
        {
          "url": "https://www.thoughtworks.com/radar",
          "title": "ThoughtWorks Technology Radar",
          "type": "documentation"
        },
        {
          "url": "https://adr.github.io/",
          "title": "Architecture Decision Records (ADR)",
          "type": "documentation"
        },
        {
          "url": "https://martinfowler.com/architecture/",
          "title": "Martin Fowler - Architecture",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Explorez l'architecture technique en lisant la documentation interne et les schémas d'architecture. Comprenez les flux de données de bout en bout.",
        "2→3": "Participez aux revues d'architecture. Comprenez les compromis derrière les choix techniques actuels et proposez des améliorations.",
        "3→4": "Contribuez aux décisions d'architecture structurantes. Formez-vous aux patterns d'architecture distribuée et aux enjeux de scalabilité."
      },
      "category": "business",
      "category_name": "Business"
    },
    {
      "id": "data_security",
      "name": "Sécurité & Conformité des Données",
      "description": "RGPD, protection des données personnelles, IAM, encryption, secrets management et audit de conformité",
      "core_roles": [
        "data_engineer",
        "analytics_eng",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en sécurité et conformité des données",
        "1": "Je connais les principes du RGPD, le principe du moindre privilège et les bases de IAM",
        "2": "J'identifie les données personnelles, j'applique anonymisation/pseudonymisation et je configure les permissions IAM",
        "3": "Je conçois des systèmes avec Privacy by Design, j'implémente le droit à l'oubli et l'audit des accès",
        "4": "Je forme les équipes, je valide la conformité des nouveaux traitements et je réalise des audits de sécurité",
        "5": "Je définis la politique de sécurité et conformité des données pour l'entreprise",
        "6": "Expert sécurité et conformité reconnu, certifications CISSP/CISM"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les 6 principes du RGPD et ce qu'est une donnée personnelle",
          "Je comprends le principe du moindre privilège",
          "Je ne stocke jamais de secrets dans le code"
        ],
        "2": [
          "J'identifie les données personnelles dans mes pipelines et j'applique l'anonymisation",
          "Je configure les permissions IAM correctement et j'utilise Secret Manager",
          "Je chiffre les données sensibles",
          "Je documente les traitements de données"
        ],
        "3": [
          "Je conçois des systèmes avec Privacy by Design",
          "J'implémente le droit à l'oubli et la gestion des durées de rétention",
          "J'implémente l'audit des accès et le column-level security",
          "J'ai réalisé une analyse d'impact (AIPD)"
        ],
        "4": [
          "Je valide la conformité RGPD des nouveaux projets data",
          "Je forme les équipes aux exigences RGPD et bonnes pratiques de sécurité",
          "Je réalise des audits de sécurité et conformité",
          "Je définis les standards de sécurité data de l'équipe"
        ],
        "5": [
          "Je définis la politique de sécurité et de protection des données pour l'entreprise",
          "Je coordonne les audits de conformité internes et externes",
          "Je forme les managers et équipes à la conformité et sécurité",
          "J'arbitre les décisions de sécurité et conformité data pour l'organisation"
        ],
        "6": [
          "Je suis certifié CISSP, CISM ou formateur externe RGPD",
          "J'ai accompagné d'autres organisations sur leur mise en conformité",
          "Je donne des conférences sur la sécurité et conformité des données",
          "Je suis reconnu comme expert en sécurité et conformité dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on",
          "title": "CNIL - RGPD Guide",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/security/best-practices",
          "title": "GCP Security Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://owasp.org/www-project-data-security-top-10/",
          "title": "OWASP Data Security Top 10",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/professional-certificates/google-cybersecurity",
          "title": "Google Cybersecurity Certificate",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Identifiez les données personnelles dans vos pipelines. Configurez les permissions IAM et utilisez Secret Manager.",
        "2→3": "Concevez des systèmes avec Privacy by Design. Implémentez l'audit des accès et le droit à l'oubli.",
        "3→4": "Menez un audit RGPD et sécurité complet. Formez les équipes aux bonnes pratiques."
      },
      "category": "compliance",
      "category_name": "Compliance"
    },
    {
      "id": "data_preparation",
      "name": "Préparation de Données",
      "description": "Nettoyer, transformer et préparer les données (pandas, numpy, pyarrow)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune capacité de préparation de données",
        "1": "Je sais nettoyer une table basique (nulls, doublons, filtres)",
        "2": "Je gère les transformations complexes (jointures, conversions de types, agrégations)",
        "3": "Je conçois des pipelines de préparation reproductibles et je gère les gros volumes",
        "4": "Je définis les standards de préparation de données et j'automatise la validation qualité",
        "5": "Je forme les équipes aux techniques avancées et j'établis les conventions de préparation à l'échelle de l'organisation",
        "6": "Contributeur open-source data processing"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais identifier et supprimer les doublons",
          "Je gère les valeurs nulles (suppression ou imputation simple)",
          "Je peux filtrer et trier un dataset"
        ],
        "2": [
          "Je fais des jointures entre plusieurs tables",
          "Je convertis les types de données correctement (dates, numériques)",
          "J'utilise les opérations groupby et agrégations",
          "Je détecte les outliers et valeurs aberrantes"
        ],
        "3": [
          "Je conçois des pipelines de transformation reproductibles",
          "Je gère les gros volumes avec pyarrow ou polars",
          "J'automatise les contrôles de qualité des données",
          "Je documente les transformations appliquées"
        ],
        "4": [
          "J'ai défini les standards de préparation de données",
          "Je crée des outils de validation réutilisables",
          "Je produis un guide de bonnes pratiques de préparation de données pour l'équipe",
          "J'optimise les performances des pipelines de préparation"
        ],
        "5": [
          "Je définis la stratégie de préparation de données de l'organisation",
          "J'arbitre les choix techniques sur les problématiques complexes de qualité des données",
          "Je forme et mentore les équipes sur les techniques avancées de data preparation",
          "J'établis les conventions et patterns réutilisables à l'échelle de l'entreprise"
        ],
        "6": [
          "Je contribue activement à des projets open-source (pandas, polars, pyarrow)",
          "Je suis reconnu dans la communauté data pour mon expertise en préparation de données",
          "Je publie des articles ou donne des conférences sur le sujet",
          "Je participe à la définition des standards et best practices de l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://pandas.pydata.org/docs/user_guide/index.html",
          "title": "Pandas User Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.kaggle.com/learn/data-cleaning",
          "title": "Data Cleaning Course (Kaggle)",
          "type": "course"
        },
        {
          "url": "https://arrow.apache.org/docs/python/",
          "title": "PyArrow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://realpython.com/python-data-cleaning-numpy-pandas/",
          "title": "Data Cleaning with Pandas",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Maîtrisez les opérations pandas avancées (apply, transform, merge). Gérez les types de données correctement.",
        "2→3": "Construisez des pipelines de préparation reproductibles. Utilisez pyarrow pour les gros volumes.",
        "3→4": "Automatisez la validation de la qualité des données. Définissez les standards de l'équipe."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "data_modeling",
      "name": "Modélisation & Architecture de Données",
      "description": "Concevoir des modèles logiques et physiques (star/snowflake schemas), implémenter l'architecture Medallion (Bronze/Silver/Gold), documenter les modèles et alimenter le data catalog",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance en modélisation et architecture de données",
        "1": "Je comprends les concepts de base (tables, relations, clés) et le rôle des couches Bronze/Silver/Gold",
        "2": "Je conçois des modèles dimensionnels basiques, je structure les données dans les bonnes couches et je documente mes modèles",
        "3": "Je conçois des modèles complexes avec pipelines Bronze-to-Gold, SLAs de qualité par couche et documentation dans le data catalog",
        "4": "Je définis l'architecture data warehouse et les standards Medallion de l'organisation",
        "5": "Je définis la stratégie de modélisation, d'architecture de données et de documentation à l'échelle de l'organisation",
        "6": "Expert data modeling et architecture reconnu, publications, contributions aux méthodologies"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les clés primaires et étrangères",
          "Je sais ce qu'est une relation 1-N et N-N",
          "Je comprends le rôle de chaque couche (Bronze/Silver/Gold) et le flux de données entre elles"
        ],
        "2": [
          "J'ai conçu un star schema avec facts et dimensions",
          "Je comprends comment gérer l'historique des données (écraser vs conserver les anciennes valeurs)",
          "Je structure les données dans les bonnes couches et j'applique les transformations appropriées",
          "Je documente mes modèles avec des diagrammes et des descriptions dans le catalog"
        ],
        "3": [
          "Je maîtrise les stratégies SCD Type 1 et Type 2 pour gérer l'historique des dimensions",
          "J'ai conçu un pipeline complet Bronze to Gold avec SLAs de qualité par couche",
          "Je choisis entre star et snowflake schema selon le cas",
          "Je maintiens la documentation de mes modèles dans le data catalog (descriptions, owners, SLAs)"
        ],
        "4": [
          "J'ai défini l'architecture data warehouse et les standards Medallion de l'équipe",
          "Je produis les guidelines de modélisation et de documentation pour l'équipe",
          "Je fais des revues de modèles pour les autres équipes",
          "J'optimise les coûts de stockage et performances par couche"
        ],
        "5": [
          "Je définis la stratégie de modélisation, d'architecture lakehouse et de data catalog de l'organisation",
          "J'arbitre les décisions d'architecture data warehouse à l'échelle de l'organisation",
          "Je forme et mentore les équipes sur les patterns de modélisation et Medallion avancés",
          "J'établis et fais évoluer les standards de modélisation et documentation"
        ],
        "6": [
          "Je suis reconnu comme expert en modélisation et architecture de données dans l'industrie",
          "Je publie des articles ou livres sur le data modeling et l'architecture lakehouse",
          "Je donne des conférences sur les architectures de données",
          "Je contribue aux évolutions des méthodologies (Kimball, Data Vault, Medallion)"
        ]
      },
      "resources": [
        {
          "url": "https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/",
          "title": "Kimball Dimensional Modeling",
          "type": "documentation"
        },
        {
          "url": "https://www.databricks.com/glossary/medallion-architecture",
          "title": "Medallion Architecture (Databricks)",
          "type": "documentation"
        },
        {
          "url": "https://www.getdbt.com/blog/modular-data-modeling-techniques",
          "title": "dbt Modular Data Modeling",
          "type": "tutorial"
        },
        {
          "url": "https://www.amazon.com/Data-Warehouse-Toolkit-Definitive-Dimensional/dp/1118530802",
          "title": "The Data Warehouse Toolkit (Kimball)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Étudiez les modèles dimensionnels (star schema) et l'architecture Medallion. Concevez votre premier data mart et documentez-le.",
        "2→3": "Appliquez les techniques Kimball et Medallion à un projet complet. Définissez les SLAs de qualité par couche.",
        "3→4": "Concevez l'architecture data warehouse et Medallion de l'organisation. Définissez les conventions de documentation."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "dbt",
      "name": "dbt (Data Build Tool)",
      "description": "Utiliser dbt pour la transformation: modèles, tests, documentation, macros Jinja, packages, modèles incrémentaux, matérialisations custom",
      "core_roles": [
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          2,
          3,
          4,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance dbt",
        "1": "Je sais exécuter des modèles existants, utiliser les tests built-in et les packages comme dbt-utils",
        "2": "J'écris des modèles avec tests, documentation, macros Jinja et modèles incrémentaux",
        "3": "Je conçois la structure du projet, j'implémente les data contracts, les packages internes et j'optimise les builds",
        "4": "Je mets en place le CI/CD dbt, les matérialisations custom, les snapshots et je définis les conventions de l'équipe",
        "5": "Je forme les équipes aux patterns dbt avancés et j'établis la stratégie qualité données de l'organisation",
        "6": "dbt Champion, speaker Coalesce, contributeur packages open-source ou dbt-core"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais exécuter dbt run et dbt test",
          "Je comprends la structure d'un projet dbt (models, tests, seeds)",
          "J'utilise les tests unique et not_null sur mes modèles",
          "J'utilise dbt-utils et je comprends les modèles incrémentaux basiques"
        ],
        "2": [
          "J'écris des modèles dbt avec ref() et source()",
          "J'écris des macros Jinja réutilisables et des tests singular",
          "Je configure la freshness des sources et les merge strategies pour incremental",
          "Je documente mes modèles dans les fichiers .yml"
        ],
        "3": [
          "Je structure le projet en staging/intermediate/mart avec data contracts",
          "J'ai créé un package interne avec des macros réutilisables",
          "J'optimise les temps de build avec defer et state",
          "J'ai mis en place une stratégie de test complète avec exposures"
        ],
        "4": [
          "J'ai mis en place le CI/CD dbt avec tests automatisés et alertes",
          "J'ai créé des matérialisations custom et je maîtrise les snapshots",
          "Je définis les conventions dbt et la documentation de référence pour l'équipe",
          "Je contribue à des packages dbt open-source"
        ],
        "5": [
          "Je définis la stratégie dbt et qualité des données de l'organisation",
          "Je conduis les audits de performance et d'architecture dbt à l'échelle de l'organisation",
          "Je forme et mentore les équipes sur les patterns dbt avancés",
          "J'établis les standards de performance et de réutilisabilité à l'échelle de l'entreprise"
        ],
        "6": [
          "Je contribue activement aux packages dbt open-source ou à dbt-core",
          "Je suis speaker à Coalesce ou autres conférences dbt",
          "Je suis reconnu dans la communauté dbt pour mon expertise",
          "Je publie des articles ou donne des talks sur les patterns dbt avancés"
        ]
      },
      "resources": [
        {
          "url": "https://docs.getdbt.com/",
          "title": "dbt Documentation",
          "type": "documentation"
        },
        {
          "url": "https://courses.getdbt.com/",
          "title": "dbt Learn",
          "type": "course"
        },
        {
          "url": "https://www.getdbt.com/blog/how-we-structure-our-dbt-projects",
          "title": "How to Structure dbt Projects",
          "type": "tutorial"
        },
        {
          "url": "https://docs.getdbt.com/docs/build/jinja-macros",
          "title": "dbt Jinja and Macros",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Écrivez vos premiers modèles dbt avec macros et tests. Implémentez un modèle incrémental.",
        "2→3": "Structurez votre projet en staging/intermediate/mart. Créez un package interne avec des macros réutilisables.",
        "3→4": "Mettez en place le CI/CD dbt. Créez une matérialisation custom. Contribuez à un package open-source."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "data_mesh",
      "name": "Data Mesh",
      "description": "Comprendre et implémenter les principes du Data Mesh (domain ownership, data as product, self-serve platform, federated governance)",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du Data Mesh",
        "1": "Je connais les 4 principes fondamentaux du Data Mesh et je comprends la différence avec une architecture centralisée",
        "2": "J'identifie les domaines de données et je conçois des data products avec leurs interfaces",
        "3": "J'implémente une architecture Data Mesh et je définis les contrats de données inter-domaines",
        "4": "Je guide la transformation Data Mesh de l'organisation et je conçois la plateforme self-serve",
        "5": "Je définis la vision Data Mesh de l'organisation et je forme les domain owners à leurs responsabilités",
        "6": "Expert reconnu, speaker/auteur sur le Data Mesh"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les 4 principes du Data Mesh",
          "Je comprends la différence avec une architecture centralisée",
          "Je sais ce qu'est un data product"
        ],
        "2": [
          "J'ai identifié les domaines de données de l'organisation",
          "J'ai conçu un data product avec ses interfaces",
          "Je comprends les responsabilités d'un domain owner",
          "Je sais définir les SLAs d'un data product"
        ],
        "3": [
          "J'ai mis en place des data contracts entre domaines",
          "Je configure une plateforme self-serve pour les domaines",
          "Je définis la gouvernance fédérée",
          "J'ai accompagné un domaine dans sa transformation"
        ],
        "4": [
          "Je guide la transformation Data Mesh du projet",
          "J'ai conçu la plateforme self-serve complète",
          "Je produis le framework d'onboarding des domain owners",
          "Je mesure la maturité Data Mesh des domaines"
        ],
        "5": [
          "Je définis la vision et la roadmap Data Mesh de l'organisation",
          "J'arbitre les décisions d'architecture Data Mesh à l'échelle de l'organisation",
          "Je forme et mentore les équipes et domain owners sur les principes Data Mesh",
          "J'établis les standards de gouvernance fédérée à l'échelle de l'entreprise"
        ],
        "6": [
          "Je suis reconnu comme expert Data Mesh dans l'industrie",
          "Je donne des conférences sur le Data Mesh (QCon, Data Council)",
          "Je publie des articles ou livres sur le sujet",
          "Je conseille d'autres organisations sur leur transformation Data Mesh"
        ]
      },
      "resources": [
        {
          "url": "https://www.datamesh-architecture.com/",
          "title": "Data Mesh Architecture",
          "type": "documentation"
        },
        {
          "url": "https://martinfowler.com/articles/data-mesh-principles.html",
          "title": "Data Mesh Principles (Martin Fowler)",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-mesh/9781492092384/",
          "title": "Data Mesh Book (O'Reilly)",
          "type": "book"
        },
        {
          "url": "https://www.thoughtworks.com/what-we-do/data-and-ai/data-mesh",
          "title": "ThoughtWorks Data Mesh",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Identifiez les domaines de données de votre organisation. Concevez votre premier data product.",
        "2→3": "Implémentez les data contracts entre domaines. Mettez en place la gouvernance fédérée.",
        "3→4": "Guidez la transformation Data Mesh de l'organisation. Créez un framework d'onboarding pour les domain owners et mesurez la maturité Data Mesh des domaines."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "gcp_fundamentals",
      "name": "Cloud Fondamentaux",
      "description": "Comprendre les fondamentaux du cloud (compute, storage, networking, IAM) — notre stack principale est GCP",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance cloud",
        "1": "Je navigue dans la console cloud et je comprends les services de base (stockage, compute, bases de données)",
        "2": "J'utilise les services de stockage objet, compute et IAM de manière autonome (ex : GCS, GCE sur GCP)",
        "3": "Je conçois des architectures multi-services, je comprends le networking et la sécurité cloud",
        "4": "Je conçois des architectures haute disponibilité, j'optimise les coûts et performances à l'échelle de l'organisation",
        "5": "Je définis la stratégie cloud et les standards de gouvernance pour l'ensemble de l'organisation",
        "6": "Speaker à des conférences cloud (Google Next, AWS re:Invent, KubeCon), expert reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans la console cloud (GCP Console, AWS Console)",
          "Je comprends les services fondamentaux : stockage objet, compute, bases de données managées",
          "Je sais ce qu'est un projet/compte cloud et un environnement"
        ],
        "2": [
          "J'uploade et télécharge des fichiers dans un stockage objet (ex : GCS)",
          "Je configure les permissions IAM basiques (rôles, service accounts)",
          "J'utilise un terminal cloud (ex : Cloud Shell) pour des opérations simples",
          "Je comprends le modèle de facturation cloud"
        ],
        "3": [
          "Je conçois des architectures utilisant plusieurs services cloud",
          "Je configure les réseaux virtuels et règles firewall (ex : VPC sur GCP)",
          "Je mets en place les service accounts et rôles selon le principe du moindre privilège",
          "J'utilise l'Infrastructure as Code (Terraform) pour provisionner les ressources"
        ],
        "4": [
          "J'optimise les coûts cloud du projet",
          "Je conçois des architectures haute disponibilité et disaster recovery",
          "J'ai une certification cloud professionnelle (GCP, AWS, Azure)",
          "Je produis les guidelines d'architecture cloud pour l'équipe"
        ],
        "5": [
          "Je définis la stratégie cloud de l'organisation et les standards de gouvernance",
          "Je conduis les revues d'architecture cloud structurantes de l'organisation",
          "Je forme et mentore les équipes sur les patterns cloud avancés",
          "J'établis les standards de sécurité, coûts et performance cloud"
        ],
        "6": [
          "Je suis speaker à des conférences cloud (Google Next, KubeCon, etc.)",
          "Je suis reconnu comme expert cloud dans l'industrie",
          "Je contribue aux discussions communautaires et publications cloud",
          "Je publie des articles ou études de cas sur les architectures cloud"
        ]
      },
      "resources": [
        {
          "url": "https://cloud.google.com/docs",
          "title": "Google Cloud Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.cloudskillsboost.google/",
          "title": "Google Cloud Skills Boost",
          "type": "course"
        },
        {
          "url": "https://cloud.google.com/certification",
          "title": "Google Cloud Certifications",
          "type": "course"
        },
        {
          "url": "https://www.youtube.com/googlecloudtech",
          "title": "Google Cloud Tech YouTube",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un projet cloud et utilisez le stockage objet pour stocker des données. Configurez les permissions IAM basiques.",
        "2→3": "Concevez une architecture multi-services. Apprenez le networking cloud (VPC) et la sécurité.",
        "3→4": "Passez une certification cloud professionnelle. Optimisez les coûts d'un projet existant."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "kubernetes",
      "name": "Kubernetes (K8s)",
      "description": "Orchestration de conteneurs pour déployer les applications",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance K8s",
        "1": "Je comprends les conteneurs Docker et les concepts K8s de base (Pod, Service, Deployment)",
        "2": "J'écris des manifests YAML et je déploie des applications sur un cluster K8s",
        "3": "Je configure le scaling automatique, je debug les problèmes de pods et je gère le stockage persistant",
        "4": "Je conçois des architectures K8s production-ready, j'optimise les ressources et je forme les équipes au déploiement",
        "5": "Je définis la stratégie Kubernetes de l'organisation, je forme les équipes aux patterns avancés et j'établis les standards de sécurité",
        "6": "Contributeur Kubernetes, speaker KubeCon"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un conteneur Docker",
          "Je connais les concepts Pod, Service, Deployment",
          "Je peux utiliser kubectl pour des opérations basiques"
        ],
        "2": [
          "J'écris des manifests YAML pour déployer des apps",
          "Je configure les ConfigMaps et Secrets",
          "Je comprends les services et l'exposition des apps",
          "J'ai déployé une application sur un cluster"
        ],
        "3": [
          "Je configure le scaling automatique (HPA)",
          "Je debug les problèmes de pods et deployments",
          "J'utilise les PersistentVolumes pour le stockage",
          "Je configure les health checks et readiness probes"
        ],
        "4": [
          "Je conçois des architectures K8s production-ready",
          "J'ai une certification CKA ou CKAD",
          "J'optimise les ressources et les coûts",
          "Je produis les templates et guidelines de déploiement K8s pour l'équipe"
        ],
        "5": [
          "Je définis la stratégie Kubernetes de l'organisation",
          "Je conçois les architectures K8s de référence pour les cas d'usage complexes",
          "Je forme les équipes aux patterns K8s avancés",
          "J'établis les standards de sécurité et de déploiement"
        ],
        "6": [
          "Je contribue au projet Kubernetes ou aux projets CNCF",
          "Je suis speaker à KubeCon ou autres conférences cloud-native",
          "Je suis reconnu comme expert Kubernetes dans la communauté",
          "Je publie des articles ou maintiens des projets K8s open-source"
        ]
      },
      "resources": [
        {
          "url": "https://kubernetes.io/docs/tutorials/",
          "title": "Kubernetes Official Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://killercoda.com/playgrounds/scenario/kubernetes",
          "title": "Killercoda - Kubernetes Playground",
          "type": "tutorial"
        },
        {
          "url": "https://training.linuxfoundation.org/certification/certified-kubernetes-administrator-cka/",
          "title": "CKA Certification",
          "type": "course"
        },
        {
          "url": "https://learnk8s.io/",
          "title": "Learn Kubernetes",
          "type": "course"
        }
      ],
      "improvement_tips": {
        "1→2": "Déployez une application simple sur un cluster K8s. Écrivez vos premiers manifests YAML.",
        "2→3": "Gérez les ConfigMaps, Secrets et les services. Implémentez le scaling automatique.",
        "3→4": "Passez la certification CKA ou CKAD. Concevez une architecture K8s production-ready."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "airflow",
      "name": "Apache Airflow",
      "description": "Orchestration de workflows avec Airflow: DAGs, operators standards et custom, hooks, sensors, plugins, performances",
      "core_roles": [
        "data_engineer",
        "analytics_eng",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Airflow",
        "1": "Je navigue dans l'UI Airflow, je lis les DAGs existants et je comprends les operators standards",
        "2": "J'écris des DAGs avec dépendances, scheduling et hooks pour les connexions externes",
        "3": "Je conçois des workflows complexes, je développe des operators custom documentés et testés, et je crée des plugins",
        "4": "J'optimise les performances d'Airflow à l'échelle, je configure les executors et je contribue à des providers",
        "5": "Je définis la stratégie Airflow de l'organisation, je forme les équipes aux patterns avancés et j'établis les standards de qualité des DAGs",
        "6": "Contributeur Apache Airflow, speaker Airflow Summit"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans l'UI Airflow et comprends les états des tasks",
          "Je sais lire un DAG existant et comprendre ses dépendances",
          "Je peux relancer manuellement un DAG ou une task",
          "Je connais les operators standards (PythonOperator, BashOperator)"
        ],
        "2": [
          "J'écris des DAGs avec plusieurs tasks et dépendances",
          "Je configure le scheduling avec des cron expressions et les templates Jinja",
          "J'utilise les hooks pour les connexions externes et les sensors",
          "Je comprends l'héritage de BaseOperator et je modifie des operators existants"
        ],
        "3": [
          "Je crée des DAGs dynamiques avec des factories",
          "J'ai développé des operators custom documentés et testés",
          "Je crée des plugins Airflow réutilisables et les publie dans un registry interne",
          "J'implémente les patterns de retry et alerting"
        ],
        "4": [
          "J'optimise les performances d'Airflow à l'échelle",
          "Je configure les executors (Celery, Kubernetes) et je définis les conventions de l'équipe",
          "Je produis les templates de DAGs et la documentation de référence pour l'équipe",
          "J'ai contribué à un provider Airflow et conçu l'architecture des plugins"
        ],
        "5": [
          "Je définis la stratégie Airflow de l'organisation",
          "Je conçois les architectures de workflows de référence pour les cas complexes",
          "Je forme les équipes aux patterns Airflow avancés et au développement d'operators",
          "J'établis les standards de qualité, de monitoring et de réutilisabilité des DAGs et plugins"
        ],
        "6": [
          "Je contribue au code source d'Apache Airflow ou aux providers officiels",
          "Je suis speaker à Airflow Summit ou conférences data engineering",
          "Je suis reconnu comme expert Airflow dans la communauté",
          "Je publie des articles ou maintiens des providers Airflow open-source"
        ]
      },
      "resources": [
        {
          "url": "https://airflow.apache.org/docs/",
          "title": "Apache Airflow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.astronomer.io/docs/learn",
          "title": "Astronomer Learn",
          "type": "tutorial"
        },
        {
          "url": "https://academy.astronomer.io/",
          "title": "Astronomer Academy",
          "type": "course"
        },
        {
          "url": "https://airflow.apache.org/docs/apache-airflow/stable/howto/custom-operator.html",
          "title": "Custom Operators Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Écrivez votre premier DAG avec plusieurs tasks et dépendances. Utilisez les hooks pour une connexion externe.",
        "2→3": "Créez un operator custom documenté et testé. Développez un plugin réutilisable pour votre équipe.",
        "3→4": "Optimisez les performances d'Airflow à l'échelle. Contribuez à un provider Apache Airflow."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "python_data",
      "name": "Python (Data)",
      "description": "Programmation Python pour le data (pandas, numpy, pyarrow, uv)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          2,
          3,
          4,
          4
        ],
        "data_scientist": [
          2,
          3,
          4,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Python",
        "1": "J'écris des scripts basiques et j'utilise pandas simplement",
        "2": "J'écris du code propre et j'utilise pandas/numpy efficacement",
        "3": "Je construis des pipelines de données et je comprends les patterns de transformation complexes",
        "4": "Je maîtrise Python en profondeur, j'écris du code maintenable et scalable et je comprends les mécanismes internes",
        "5": "Je forme l'organisation aux bonnes pratiques Python et je définis les standards de code",
        "6": "Contributeur open-source Python data ecosystem"
      },
      "behavioral_indicators": {
        "1": [
          "Je peux lire un CSV avec pandas et faire des filtres basiques",
          "J'utilise des boucles for et des conditions if/else",
          "Je sais créer des fonctions simples",
          "Je cherche souvent la syntaxe sur Stack Overflow"
        ],
        "2": [
          "J'utilise groupby, merge, pivot_table couramment",
          "Je structure mon code en fonctions réutilisables",
          "Je gère les types de données (datetime, categorical, etc.)",
          "J'écris des list/dict comprehensions",
          "Je sais utiliser numpy pour les opérations vectorisées"
        ],
        "3": [
          "Je construis des pipelines de transformation modulaires",
          "J'utilise pyarrow/polars pour les gros volumes",
          "Je crée des packages Python avec pyproject.toml et uv",
          "J'écris des tests unitaires pour mon code",
          "J'utilise les type hints et la validation Pydantic"
        ],
        "4": [
          "Je fais des code reviews Python pour l'équipe",
          "J'ai défini les standards Python du projet",
          "Je maîtrise les patterns avancés (decorators, context managers)",
          "J'optimise les performances (profiling, memory)"
        ],
        "5": [
          "Je définis les standards Python de l'organisation",
          "J'arbitre les décisions d'architecture Python pour l'organisation",
          "Je forme les équipes sur les patterns Python avancés",
          "J'établis les conventions de code et les bonnes pratiques"
        ],
        "6": [
          "Je contribue activement à des projets open-source (pandas, numpy, polars)",
          "Je suis speaker à PyCon ou autres conférences Python",
          "Je suis reconnu dans la communauté Python data",
          "Je publie des articles ou packages Python populaires"
        ]
      },
      "resources": [
        {
          "url": "https://docs.python.org/3/tutorial/",
          "title": "Python Official Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://pandas.pydata.org/docs/getting_started/intro_tutorials/",
          "title": "Pandas Getting Started",
          "type": "tutorial"
        },
        {
          "url": "https://www.coursera.org/specializations/python",
          "title": "Python for Everybody (Coursera)",
          "type": "course"
        },
        {
          "url": "https://realpython.com/",
          "title": "Real Python Tutorials",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez les opérations pandas avancées (groupby, merge, pivot). Écrivez du code avec des fonctions réutilisables.",
        "2→3": "Maîtrisez les patterns de data pipelines. Apprenez pyarrow pour les gros volumes.",
        "3→4": "Contribuez aux standards de code de l'équipe. Écrivez des packages Python internes documentés."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "python_backend",
      "name": "Python Backend & APIs",
      "description": "Consommer et construire des APIs REST avec Python (FastAPI, Flask): pagination, auth, intégration, patterns de résilience, architecture backend",
      "core_roles": [
        "backend",
        "ml_engineer",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance API/backend Python",
        "1": "Je fais des appels API basiques (requests, curl), je comprends REST et le format JSON",
        "2": "Je construis des APIs simples avec FastAPI et je gère l'authentification, la pagination et les erreurs",
        "3": "Je conçois des APIs scalables avec auth, caching et retry, et je crée des clients API robustes avec patterns de résilience",
        "4": "Je maîtrise l'architecture backend et API en profondeur, je gère les scénarios complexes (webhooks, streaming)",
        "5": "Je définis la stratégie API et backend de l'organisation et je forme les équipes aux bonnes pratiques",
        "6": "Contributeur FastAPI/frameworks, expert API design reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je fais des appels GET/POST avec requests ou curl",
          "Je comprends les codes HTTP et le format JSON",
          "Je peux lire la documentation d'une API et l'utiliser"
        ],
        "2": [
          "J'ai créé une API CRUD avec FastAPI et Pydantic",
          "Je gère l'authentification (API keys, tokens, JWT)",
          "J'implémente la pagination et la gestion des erreurs HTTP",
          "Je documente mes APIs avec OpenAPI/Swagger"
        ],
        "3": [
          "J'implémente l'authentification OAuth et le caching (Redis)",
          "Je crée des clients API robustes avec retry et rate limiting",
          "Je structure mes projets avec une architecture clean",
          "J'ai intégré plusieurs APIs externes avec patterns de résilience"
        ],
        "4": [
          "Je conçois l'architecture API et backend de l'équipe",
          "J'implémente le monitoring des APIs et les métriques de performance",
          "Je gère les scénarios complexes (webhooks, streaming, concurrence)",
          "Je produis les standards d'intégration et les patterns réutilisables pour l'équipe"
        ],
        "5": [
          "Je définis la stratégie API et backend de l'organisation",
          "J'arbitre les décisions d'architecture backend et d'intégration",
          "Je forme les équipes sur les patterns API avancés et la résilience",
          "J'établis les standards de sécurité, performance et robustesse"
        ],
        "6": [
          "Je contribue activement à FastAPI ou autres frameworks Python",
          "Je suis speaker à PyCon ou conférences API",
          "Je contribue aux standards et spécifications API (OpenAPI, AsyncAPI)",
          "Je publie des articles ou maintiens des projets open-source backend"
        ]
      },
      "resources": [
        {
          "url": "https://fastapi.tiangolo.com/tutorial/",
          "title": "FastAPI Tutorial",
          "type": "tutorial"
        },
        {
          "url": "https://testdriven.io/courses/tdd-fastapi/",
          "title": "Test-Driven Development with FastAPI",
          "type": "course"
        },
        {
          "url": "https://12factor.net/",
          "title": "The Twelve-Factor App",
          "type": "documentation"
        },
        {
          "url": "https://swagger.io/specification/",
          "title": "OpenAPI Specification",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez une API CRUD avec FastAPI. Intégrez une API externe avec authentification et pagination.",
        "2→3": "Implémentez l'authentification OAuth et le caching. Créez un client API robuste avec retry et rate limiting.",
        "3→4": "Concevez une architecture API complète avec monitoring. Définissez les standards d'intégration de votre équipe."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "etl_connectors",
      "name": "Connecteurs ETL",
      "description": "Développer des connecteurs vers des sources externes (APIs SaaS, fichiers)",
      "core_roles": [
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance ETL",
        "1": "Je comprends les patterns d'extraction de données",
        "2": "Je développe des connecteurs basiques vers des APIs",
        "3": "Je conçois des connecteurs robustes avec retry et error handling et je comprends les patterns de résilience",
        "4": "Je maîtrise les patterns de connecteurs et la gestion des états en profondeur",
        "5": "Je définis la stratégie d'intégration de données et je forme les équipes au développement de connecteurs",
        "6": "Contributeur Singer/Airbyte, expert ETL reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le pattern Extract-Transform-Load",
          "Je sais ce qu'est un connecteur de données",
          "Je peux extraire des données d'un fichier CSV/JSON"
        ],
        "2": [
          "J'ai développé un connecteur vers une API SaaS",
          "Je gère la pagination et les erreurs",
          "Je configure Airbyte ou Fivetran pour une source",
          "J'extrais des données incrémentales"
        ],
        "3": [
          "Je crée des connecteurs avec retry et backoff",
          "Je gère l'état pour les extractions incrémentales",
          "J'ai développé des connecteurs custom robustes",
          "Je documente et teste mes connecteurs"
        ],
        "4": [
          "J'ai créé un framework de connecteurs réutilisable",
          "Je contribue à Airbyte ou Singer",
          "Je définis les patterns de connecteurs de l'organisation",
          "Je forme les équipes au développement de connecteurs"
        ],
        "5": [
          "Je définis la stratégie d'intégration de données de l'organisation",
          "J'arbitre les décisions d'architecture de connecteurs pour l'organisation",
          "Je forme les équipes sur les patterns ETL avancés",
          "J'établis les standards de qualité et de robustesse des connecteurs"
        ],
        "6": [
          "Je contribue activement à Airbyte, Singer ou Fivetran",
          "Je suis reconnu comme expert ETL dans la communauté",
          "Je publie des connecteurs open-source populaires",
          "Je donne des conférences sur l'intégration de données"
        ]
      },
      "resources": [
        {
          "url": "https://airbyte.com/data-engineering-resources/data-extraction",
          "title": "Data Extraction Guide (Airbyte)",
          "type": "tutorial"
        },
        {
          "url": "https://hub.meltano.com/",
          "title": "Meltano Hub - Singer Taps & Targets",
          "type": "documentation"
        },
        {
          "url": "https://docs.airbyte.com/connector-development/",
          "title": "Airbyte Connector Development",
          "type": "documentation"
        },
        {
          "url": "https://airbyte.com/tutorials",
          "title": "Airbyte Tutorials",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Développez un connecteur simple vers une API SaaS. Gérez la pagination et les erreurs.",
        "2→3": "Ajoutez la gestion d'état et les reprises après échec. Implémentez l'extraction incrémentale.",
        "3→4": "Contribuez à Airbyte ou Singer. Créez un framework de connecteurs réutilisable."
      },
      "category": "engineering",
      "category_name": "Engineering"
    },
    {
      "id": "recommendation_systems",
      "name": "Systèmes de Recommandation",
      "description": "Concevoir et implémenter des systèmes de recommandation",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          2,
          3
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des systèmes de recommandation",
        "1": "Je connais les types de systèmes de recommandation (collaborative, content-based) et leurs cas d'usage",
        "2": "J'entraîne et déploie un modèle de recommandation en production et je réalise des AB tests",
        "3": "Je développe des systèmes de recommandation avancés (two-tower, hybrides) et j'optimise le ranking et la diversité",
        "4": "Je conçois l'architecture de recommandation de l'organisation et je mesure l'impact business",
        "5": "Je définis les standards RecSys pour l'entreprise et je forme les équipes aux architectures de recommandation avancées",
        "6": "Expert RecSys reconnu, publications, speaker RecSys"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais la différence entre collaborative et content-based filtering",
          "Je comprends le problème du cold start",
          "Je sais ce qu'est une matrice user-item"
        ],
        "2": [
          "J'ai implémenté un collaborative filtering basique",
          "Je calcule les métriques de recommandation (precision, recall, MRR)",
          "Je comprends les factorisations matricielles",
          "J'ai déployé un modèle de recommandation simple en production"
        ],
        "3": [
          "J'ai conçu un système two-tower avec embeddings",
          "Je combine plusieurs signaux (collaborative + content)",
          "Je gère le ranking et la diversité des recommandations",
          "J'ai déployé un système de recommandation multi-stage (retrieval + ranking) en production"
        ],
        "4": [
          "J'ai conçu l'architecture de recommandation de l'équipe",
          "Je gère le serving temps réel des recommandations",
          "Je mesure l'impact business des recommandations",
          "Je produis la documentation technique et les patterns de recommandation pour l'équipe"
        ],
        "5": [
          "Je définis les standards et patterns de recommandation pour l'entreprise",
          "Je forme et mentore les équipes sur les systèmes de recommandation avancés",
          "J'arbitre les choix d'architecture RecSys pour l'organisation",
          "J'ai mis en place des patterns de recommandation adoptés par plusieurs équipes"
        ],
        "6": [
          "Je suis speaker à des conférences RecSys ou similaires",
          "J'ai publié des articles ou papers sur les systèmes de recommandation",
          "Je contribue à des projets open-source dans le domaine RecSys",
          "Je suis reconnu comme expert externe et sollicité par d'autres entreprises"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/specializations/recommender-systems",
          "title": "Recommender Systems Specialization (Coursera)",
          "type": "course"
        },
        {
          "url": "https://developers.google.com/machine-learning/recommendation",
          "title": "Google ML Recommendations",
          "type": "tutorial"
        },
        {
          "url": "https://arxiv.org/abs/1905.01395",
          "title": "Two-Tower Models Paper",
          "type": "documentation"
        },
        {
          "url": "https://eugeneyan.com/writing/system-design-for-discovery/",
          "title": "System Design for Discovery",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez un système de collaborative filtering simple. Comprenez les métriques (MRR, NDCG).",
        "2→3": "Construisez un système two-tower avec des embeddings. Combinez plusieurs signaux.",
        "3→4": "Concevez un système de recommandation à l'échelle. Publiez vos learnings."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "embeddings",
      "name": "Embeddings & Base de données Vectorielles",
      "description": "Générer des embeddings et implémenter des bases de données vectorielles",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance des embeddings",
        "1": "Je comprends les concepts de vecteurs, similarité cosine et les cas d'usage des embeddings",
        "2": "Je génère des embeddings avec des modèles pré-entraînés et j'implémente une recherche par similarité",
        "3": "Je conçois des pipelines d'embeddings à l'échelle et j'optimise le retrieval vectoriel",
        "4": "Je conçois l'architecture de recherche vectorielle et je gère des milliards d'embeddings en production",
        "5": "Je définis la stratégie embeddings et vector search pour l'entreprise et je forme les équipes au retrieval avancé",
        "6": "Expert vector search reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends ce qu'est un vecteur et la similarité cosine",
          "Je sais ce qu'est un embedding et son utilité",
          "Je connais des applications (recherche sémantique, recommandation)"
        ],
        "2": [
          "J'utilise des modèles pré-entraînés (Sentence-BERT, OpenAI)",
          "J'ai implémenté une recherche par similarité",
          "Je comprends les métriques de distance",
          "J'utilise une base vectorielle (Pinecone, Qdrant)"
        ],
        "3": [
          "Je conçois des pipelines d'embeddings à l'échelle",
          "Je fine-tune des modèles d'embeddings",
          "J'optimise les performances de retrieval",
          "J'ai déployé une recherche sémantique en production"
        ],
        "4": [
          "J'ai conçu l'architecture de recherche vectorielle",
          "Je gère des milliards d'embeddings",
          "J'optimise les coûts et latences",
          "Je produis les pipelines de référence et la documentation d'indexation vectorielle pour l'équipe"
        ],
        "5": [
          "Je définis la stratégie embeddings et vector search pour l'entreprise",
          "Je forme et mentore les équipes sur les systèmes de recherche sémantique",
          "J'arbitre les choix d'architecture de retrieval vectoriel pour l'organisation",
          "J'ai établi les bonnes pratiques d'indexation vectorielle à l'échelle"
        ],
        "6": [
          "Je suis speaker à des conférences sur le vector search ou les embeddings",
          "J'ai publié des articles ou papers sur le retrieval vectoriel",
          "Je contribue à des projets open-source (Qdrant, Milvus, FAISS)",
          "Je suis reconnu comme expert externe en recherche sémantique"
        ]
      },
      "resources": [
        {
          "url": "https://www.pinecone.io/learn/",
          "title": "Pinecone Learning Center",
          "type": "tutorial"
        },
        {
          "url": "https://huggingface.co/blog/getting-started-with-embeddings",
          "title": "Getting Started with Embeddings (HuggingFace)",
          "type": "tutorial"
        },
        {
          "url": "https://www.sbert.net/",
          "title": "Sentence Transformers",
          "type": "documentation"
        },
        {
          "url": "https://qdrant.tech/articles/",
          "title": "Qdrant Vector Search Articles",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Utilisez des modèles pré-entraînés pour générer des embeddings. Implémentez une recherche par similarité.",
        "2→3": "Construisez un pipeline d'embeddings avec un vector store. Fine-tunez un modèle pour votre domaine.",
        "3→4": "Optimisez les performances à grande échelle. Contribuez à la communauté vector search."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "mlflow",
      "name": "Plateforme MLOps",
      "description": "Tracking des expériences ML, gestion des modèles (MLFlow, Model Registry) et plateforme ML cloud (Vertex AI: training, serving, endpoints)",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance MLOps et plateformes ML",
        "1": "Je navigue dans l'UI MLFlow et Vertex AI, je comprends les concepts d'experiment, run et endpoint",
        "2": "Je logue les paramètres et métriques, j'enregistre des modèles et je déploie sur un endpoint Vertex AI",
        "3": "Je conçois des workflows MLOps intégrés, j'utilise le Model Registry et je configure le monitoring des modèles",
        "4": "Je conçois l'architecture MLOps de l'organisation, j'intègre MLFlow avec le CI/CD et j'optimise les coûts",
        "5": "Je définis les standards MLOps pour l'entreprise et je forme les équipes aux workflows ML en production",
        "6": "Expert MLOps reconnu, contributeur open-source"
      },
      "behavioral_indicators": {
        "1": [
          "Je navigue dans l'UI MLFlow et Vertex AI",
          "Je comprends les concepts d'experiment, run et endpoint",
          "Je comprends la différence entre AutoML et custom training"
        ],
        "2": [
          "Je logue les paramètres, métriques et artefacts dans MLFlow",
          "J'enregistre des modèles dans le Model Registry",
          "J'ai déployé un modèle sur un endpoint Vertex AI",
          "J'utilise Vertex AI Workbench pour le développement"
        ],
        "3": [
          "J'intègre MLFlow dans les pipelines de training",
          "Je crée des pipelines de training custom sur Vertex AI",
          "Je configure le monitoring des modèles en production",
          "J'automatise la promotion des modèles (dev/staging/prod)"
        ],
        "4": [
          "J'ai conçu l'architecture MLOps de l'équipe",
          "J'intègre MLFlow avec le CI/CD et j'optimise les coûts de training/serving",
          "Je produis les templates de pipelines MLOps pour l'équipe",
          "J'ai une certification GCP ML Engineer"
        ],
        "5": [
          "Je définis les standards MLOps et experiment tracking pour l'entreprise",
          "Je forme et mentore les équipes sur les workflows ML en production",
          "J'arbitre les choix d'architecture MLOps pour l'organisation",
          "J'ai mis en place la gouvernance des modèles ML"
        ],
        "6": [
          "Je suis speaker à des conférences MLOps ou ML Platform",
          "Je contribue au projet MLFlow ou outils similaires",
          "J'ai publié des articles sur les bonnes pratiques MLOps",
          "Je suis reconnu comme expert externe en ML lifecycle management"
        ]
      },
      "resources": [
        {
          "url": "https://mlflow.org/docs/latest/index.html",
          "title": "MLFlow Documentation",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/vertex-ai/docs",
          "title": "Vertex AI Documentation",
          "type": "documentation"
        },
        {
          "url": "https://madewithml.com/courses/mlops/",
          "title": "Made with ML - MLOps",
          "type": "course"
        },
        {
          "url": "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning",
          "title": "MLOps Architecture Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Loggez vos premières expériences avec MLFlow. Déployez un modèle sur un endpoint Vertex AI.",
        "2→3": "Intégrez MLFlow dans vos pipelines de training. Créez un pipeline custom sur Vertex AI.",
        "3→4": "Concevez l'architecture MLOps de l'organisation. Passez la certification ML Engineer."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "ml_deployment",
      "name": "Déploiement & Services ML",
      "description": "Déployer des modèles ML en production (APIs, conteneurs, endpoints) et concevoir des services ML internes avec des patterns backend solides (API design, tests, monitoring)",
      "core_roles": [
        "ml_engineer",
        "data_scientist",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          2,
          3,
          4,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance du déploiement ML et des services ML",
        "1": "Je comprends les défis du déploiement ML (latence, throughput, batch vs temps réel) et les bases du design d'API",
        "2": "Je déploie des modèles via une API FastAPI, je conteneurise avec Docker et j'écris des tests",
        "3": "Je conçois des systèmes ML production avec scaling, monitoring, A/B testing et patterns backend solides (API versioning, error handling)",
        "4": "Je conçois l'architecture de serving et des services ML de l'organisation et j'optimise les performances à grande échelle",
        "5": "Je définis les standards de déploiement ML et d'architecture de services pour l'entreprise et je forme les équipes",
        "6": "Expert ML serving et services reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les défis du déploiement ML (latence, throughput)",
          "Je connais les options de déploiement (batch vs temps réel)",
          "Je connais les principes de base du design d'API REST"
        ],
        "2": [
          "J'ai déployé un modèle via une API FastAPI",
          "Je conteneurise mes modèles avec Docker",
          "J'écris des tests unitaires et d'intégration pour mes services",
          "Je gère les erreurs et la validation des entrées"
        ],
        "3": [
          "Je configure le scaling automatique des endpoints",
          "Je mets en place le monitoring et l'alerting pour mes services",
          "J'implémente le A/B testing de modèles avec API versioning",
          "Je gère le cycle de vie des modèles (versioning, rollback)"
        ],
        "4": [
          "J'ai conçu l'architecture de serving et des services ML de l'équipe",
          "Je définis les patterns de service design (circuit breaker, retry, caching)",
          "J'optimise les latences et throughput à grande échelle",
          "Je produis les templates de déploiement et la documentation d'architecture pour l'équipe"
        ],
        "5": [
          "Je définis les standards de déploiement ML et d'architecture de services pour l'entreprise",
          "Je forme et mentore les équipes sur le ML en production et les patterns backend avancés",
          "J'arbitre les choix d'architecture ML serving pour l'organisation",
          "J'ai mis en place la plateforme ML serving de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences ML Platform ou MLOps",
          "J'ai publié des articles sur le ML serving et les services ML à grande échelle",
          "Je contribue à des projets open-source (KServe, BentoML)",
          "Je suis reconnu comme expert externe en ML production"
        ]
      },
      "resources": [
        {
          "url": "https://www.oreilly.com/library/view/building-machine-learning/9781492045106/",
          "title": "Building ML Powered Applications",
          "type": "book"
        },
        {
          "url": "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning",
          "title": "Google MLOps Guide",
          "type": "documentation"
        },
        {
          "url": "https://microservices.io/patterns/index.html",
          "title": "Microservice Architecture Patterns",
          "type": "documentation"
        },
        {
          "url": "https://fastapi.tiangolo.com/",
          "title": "FastAPI - Documentation officielle",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Déployez un modèle simple via une API FastAPI avec Docker. Ajoutez des tests unitaires et de la validation d'entrées.",
        "2→3": "Implémentez le monitoring, l'alerting et le scaling automatique. Ajoutez le versioning d'API.",
        "3→4": "Concevez l'architecture complète de serving et services ML. Définissez les patterns pour l'équipe."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "feature_engineering",
      "name": "Feature Engineering",
      "description": "Créer des features efficaces pour les modèles ML (transformations, feature stores)",
      "core_roles": [
        "ml_engineer",
        "data_scientist"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          "NC",
          "NC",
          1,
          2
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance feature engineering",
        "1": "Je comprends les types de features (numériques, catégoriques) et les transformations basiques",
        "2": "Je crée des features à partir de données temporelles et j'applique la sélection de features",
        "3": "Je conçois des pipelines de features reproductibles avec un feature store et je gère le feature drift",
        "4": "Je conçois l'architecture du feature store et je gère des milliers de features à l'échelle",
        "5": "Je définis les standards de feature engineering pour l'entreprise et je forme les équipes à la création de features avancées",
        "6": "Expert feature engineering reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends la différence entre features numériques et catégoriques",
          "Je sais ce qu'est la normalisation et le scaling",
          "Je connais les encodages basiques (one-hot, label encoding)"
        ],
        "2": [
          "Je crée des features à partir de données temporelles",
          "Je gère les valeurs manquantes et outliers",
          "J'utilise les transformations (log, polynomial)",
          "J'applique la sélection de features"
        ],
        "3": [
          "Je crée des pipelines de features reproductibles",
          "J'utilise un feature store (Feast, Vertex Feature Store)",
          "Je gère le feature drift en production",
          "J'automatise le feature engineering"
        ],
        "4": [
          "J'ai conçu l'architecture du feature store",
          "Je gère des milliers de features à l'échelle",
          "J'optimise les performances de serving",
          "Je produis le catalogue de features et la documentation du feature store pour l'équipe"
        ],
        "5": [
          "Je définis les standards de feature engineering pour l'entreprise",
          "Je forme et mentore les équipes sur la création de features avancées",
          "J'arbitre les choix d'architecture feature store pour l'organisation",
          "J'ai mis en place la gouvernance des features ML"
        ],
        "6": [
          "Je suis speaker à des conférences ML ou Feature Store Summit",
          "J'ai publié des articles sur le feature engineering à l'échelle",
          "Je contribue à des projets open-source (Feast, Feathr)",
          "Je suis reconnu comme expert externe en feature platforms"
        ]
      },
      "resources": [
        {
          "url": "https://www.featurestore.org/",
          "title": "Feature Store.org",
          "type": "documentation"
        },
        {
          "url": "https://www.kaggle.com/learn/feature-engineering",
          "title": "Feature Engineering (Kaggle)",
          "type": "course"
        },
        {
          "url": "https://feast.dev/",
          "title": "Feast Feature Store",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/",
          "title": "Feature Engineering for ML (O'Reilly)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez des features pour un projet Kaggle. Maîtrisez les encodages catégoriels.",
        "2→3": "Construisez un pipeline de features reproductible. Explorez les feature stores.",
        "3→4": "Implémentez un feature store pour l'organisation. Automatisez la feature discovery."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "entity_resolution",
      "name": "Linkage & Matching",
      "description": "Construire des concepts métier et relier les données (déduplication, matching)",
      "core_roles": [
        "data_scientist",
        "ml_engineer"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          4
        ],
        "analytics_eng": [
          "NC",
          "NC",
          1,
          2
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance",
        "1": "Je comprends les problèmes de déduplication et les techniques de fuzzy matching",
        "2": "J'implémente des solutions de matching basiques avec des bibliothèques spécialisées",
        "3": "Je conçois des systèmes de linkage et matching à grande échelle avec du blocking et des modèles ML",
        "4": "Je conçois l'architecture de matching de l'organisation et j'optimise la précision et le recall à grande échelle",
        "5": "Je définis les standards de matching et déduplication pour l'entreprise et je forme les équipes aux techniques avancées",
        "6": "Expert linkage et matching reconnu, publications"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le problème de déduplication de données",
          "Je connais les techniques de fuzzy matching",
          "Je sais ce qu'est le record linkage"
        ],
        "2": [
          "J'utilise des bibliothèques de fuzzy matching (fuzzywuzzy, rapidfuzz)",
          "J'implémente des règles de matching simples",
          "Je calcule des scores de similarité entre records",
          "J'ai dédupliqué un dataset de taille moyenne"
        ],
        "3": [
          "Je conçois des systèmes de matching à grande échelle",
          "J'utilise le blocking pour optimiser les performances",
          "J'implémente des modèles ML pour le matching",
          "J'ai géré un projet de déduplication complet"
        ],
        "4": [
          "J'ai conçu l'architecture de matching de l'équipe",
          "Je gère des millions de records à matcher",
          "J'optimise la précision et le recall du matching",
          "Je crée la documentation et les guidelines de matching pour l'équipe"
        ],
        "5": [
          "Je définis les standards de matching et déduplication pour l'entreprise",
          "Je forme et mentore les équipes sur les techniques de matching avancées",
          "J'arbitre les choix d'architecture de qualité des données pour l'organisation",
          "J'ai mis en place des standards de matching adoptés par plusieurs équipes"
        ],
        "6": [
          "Je suis speaker à des conférences sur la qualité de données et le record linkage",
          "J'ai publié des articles sur le matching et la déduplication à grande échelle",
          "Je contribue à des projets open-source (dedupe, Zingg)",
          "Je suis reconnu comme expert externe en Master Data Management"
        ]
      },
      "resources": [
        {
          "url": "https://recordlinkage.readthedocs.io/",
          "title": "Python Record Linkage Toolkit",
          "type": "documentation"
        },
        {
          "url": "https://moj-analytical-services.github.io/splink/",
          "title": "Splink - Data Linkage at Scale",
          "type": "documentation"
        },
        {
          "url": "https://www.microsoft.com/en-us/research/publication/swoosh-a-generic-approach-to-entity-resolution/",
          "title": "Swoosh Paper (Microsoft)",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-quality-fundamentals/9781098112035/",
          "title": "Data Quality Fundamentals",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez une déduplication simple avec fuzzy matching. Utilisez la bibliothèque splink ou dedupe sur un dataset réel.",
        "2→3": "Construisez un pipeline de matching à grande échelle. Combinez plusieurs techniques.",
        "3→4": "Concevez un système de qualité de la donnée pour l'organisation. Publiez vos algorithmes."
      },
      "category": "ml",
      "category_name": "Machine Learning"
    },
    {
      "id": "git_github",
      "name": "Git, Qualité Code & CI",
      "description": "Contrôle de version (Git, branches, PR, workflows), qualité de code (ruff, sqlfluff, pre-commit) et stratégies de tests (unitaires, intégration, e2e)",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          2,
          3,
          4,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Git et qualité de code",
        "1": "Je fais clone, pull, commit, push et je comprends l'importance du linting et des tests",
        "2": "Je travaille avec les branches et PRs, j'utilise pre-commit au quotidien et j'écris des tests unitaires",
        "3": "Je résous les conflits complexes, je définis la stratégie de tests et j'intègre les quality gates au CI",
        "4": "Je maîtrise tout scénario Git, je définis les standards de qualité et de tests CI/CD pour l'organisation",
        "5": "Je pilote le programme de qualité code, Git et tests à l'échelle de l'organisation",
        "6": "Contributeur Git/ruff/pytest, expert reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je fais git clone, pull, commit, push au quotidien",
          "J'écris des messages de commit descriptifs",
          "Je comprends l'importance du linting et des tests",
          "Je connais les outils de base (ruff, pytest)"
        ],
        "2": [
          "Je crée des branches et je fais des Pull Requests avec code reviews",
          "J'utilise pre-commit au quotidien et je fixe les erreurs de linting",
          "J'écris des tests unitaires pour mon code",
          "Je comprends la pyramide de tests (unitaires, intégration, e2e)"
        ],
        "3": [
          "Je résous des conflits de merge complexes et j'utilise rebase",
          "Je configure pre-commit et personnalise les règles ruff/sqlfluff",
          "Je définis la stratégie de tests et les quality gates dans le CI/CD",
          "J'ai défini une stratégie de branching (GitFlow, trunk-based)"
        ],
        "4": [
          "Je définis les conventions Git et les standards de qualité de l'équipe",
          "J'optimise les pipelines CI/CD (parallélisation, caching des tests)",
          "Je produis les configurations de référence (ruff, sqlfluff, pytest) et les quality gates",
          "Je mets en place les métriques de qualité (couverture, dette technique)"
        ],
        "5": [
          "Je pilote le programme de qualité code, Git et tests à l'échelle de l'organisation",
          "Je définis les standards de qualité, les quality gates et les métriques",
          "Je forme et mentore les équipes sur les stratégies de tests avancées",
          "Je mesure et améliore la maturité qualité de l'organisation"
        ],
        "6": [
          "Je suis speaker à des conférences Python, DevOps ou Code Quality",
          "Je contribue à ruff, sqlfluff, pytest ou Git",
          "J'ai publié des articles sur la qualité de code et les workflows Git avancés",
          "Je suis reconnu comme expert externe en qualité et versioning"
        ]
      },
      "resources": [
        {
          "url": "https://learngitbranching.js.org/",
          "title": "Learn Git Branching (Interactive)",
          "type": "tutorial"
        },
        {
          "url": "https://pre-commit.com/",
          "title": "Pre-commit Documentation",
          "type": "documentation"
        },
        {
          "url": "https://docs.astral.sh/ruff/",
          "title": "Ruff Documentation",
          "type": "documentation"
        },
        {
          "url": "https://git-scm.com/book/en/v2",
          "title": "Pro Git Book",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Apprenez le branching et les PRs. Installez pre-commit et écrivez vos premiers tests unitaires.",
        "2→3": "Maîtrisez rebase et les conflits. Définissez la stratégie de tests et intégrez les quality gates au CI.",
        "3→4": "Définissez les standards Git et qualité pour l'organisation. Optimisez les pipelines CI/CD."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "github_actions",
      "name": "GitHub Actions",
      "description": "CI/CD avec GitHub Actions (workflows réutilisables, tests, déploiement)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance GitHub Actions",
        "1": "Je lis et comprends les fichiers workflow, je consulte les logs CI/CD",
        "2": "J'écris des workflows basiques pour le testing et le déploiement",
        "3": "Je conçois des pipelines CI/CD complexes avec workflows réutilisables et matrix builds",
        "4": "Je crée des actions custom et je définis les standards de déploiement de l'équipe",
        "5": "Je conçois la plateforme CI/CD de l'organisation et j'arbitre les choix d'architecture de pipelines",
        "6": "Contributeur Actions community, expert DevOps reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts de CI/CD",
          "Je sais lire un fichier workflow.yml",
          "Je peux voir les logs d'un workflow"
        ],
        "2": [
          "J'écris des workflows pour lancer les tests",
          "J'utilise les actions du marketplace",
          "Je configure les triggers (push, PR, schedule)",
          "Je gère les secrets dans les workflows"
        ],
        "3": [
          "Je crée des workflows réutilisables",
          "J'utilise les matrix builds",
          "Je configure les environments et approvals",
          "J'optimise les temps de build avec le cache"
        ],
        "4": [
          "J'ai conçu l'architecture CI/CD de l'équipe",
          "Je crée des actions custom",
          "Je définis les standards de déploiement",
          "Je produis la documentation et les templates CI/CD réutilisables pour l'équipe"
        ],
        "5": [
          "Je définis les standards CI/CD pour l'ensemble de l'organisation",
          "Je diagnostique et résous les problèmes de pipelines complexes à l'échelle de l'organisation",
          "Je mentore les équipes sur les stratégies de déploiement",
          "J'ai mis en place la plateforme CI/CD de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences DevOps ou CI/CD",
          "Je contribue au marketplace GitHub Actions",
          "J'ai publié des articles sur les pipelines CI/CD avancés",
          "Je suis reconnu comme expert externe en automatisation"
        ]
      },
      "resources": [
        {
          "url": "https://docs.github.com/en/actions",
          "title": "GitHub Actions Documentation",
          "type": "documentation"
        },
        {
          "url": "https://github.com/features/actions",
          "title": "GitHub Actions Features",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/watch?v=R8_veQiYBjI",
          "title": "GitHub Actions Tutorial",
          "type": "video"
        },
        {
          "url": "https://github.com/actions/starter-workflows",
          "title": "Starter Workflows",
          "type": "tutorial"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un workflow de test simple. Utilisez les actions du marketplace.",
        "2→3": "Implémentez des workflows réutilisables. Utilisez les secrets et environments.",
        "3→4": "Optimisez les temps de build. Créez des actions custom."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "terraform",
      "name": "Terraform",
      "description": "Infrastructure as Code avec Terraform (GCP resources, modules, state)",
      "core_roles": [
        "data_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          "NC",
          1
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Terraform",
        "1": "Je lis les fichiers .tf et j'exécute terraform plan/apply",
        "2": "J'écris des configurations Terraform basiques pour créer des ressources GCP",
        "3": "Je conçois des architectures modulaires et je gère le state remote",
        "4": "Je maîtrise les patterns IaC avancés et je définis les standards Terraform de l'équipe",
        "5": "Je conçois la plateforme IaC de l'organisation et j'arbitre les choix d'architecture Terraform",
        "6": "Contributeur Terraform providers, expert HashiCorp reconnu"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts d'Infrastructure as Code",
          "Je sais lire un fichier .tf",
          "Je connais terraform plan et apply"
        ],
        "2": [
          "J'écris des configurations Terraform basiques",
          "Je crée des ressources GCP (buckets, datasets)",
          "Je comprends le state et son importance",
          "J'utilise les variables et outputs"
        ],
        "3": [
          "Je développe des modules réutilisables",
          "Je configure le state remote (GCS)",
          "J'utilise les workspaces pour les environments",
          "J'intègre Terraform dans le CI/CD"
        ],
        "4": [
          "J'ai conçu l'architecture IaC de l'équipe",
          "J'ai une certification Terraform",
          "Je produis les modules Terraform réutilisables et la documentation pour l'équipe",
          "Je définis les standards et bonnes pratiques"
        ],
        "5": [
          "Je définis les standards IaC pour l'ensemble de l'organisation",
          "Je conçois les architectures Terraform complexes et multi-environnements pour l'organisation",
          "Je mentore les équipes sur les patterns de modules avancés",
          "J'ai mis en place la plateforme IaC de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences HashiConf ou IaC",
          "Je contribue aux providers Terraform",
          "J'ai publié des articles sur l'Infrastructure as Code",
          "Je suis reconnu comme expert externe certifié HashiCorp"
        ]
      },
      "resources": [
        {
          "url": "https://developer.hashicorp.com/terraform/tutorials",
          "title": "HashiCorp Terraform Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://developer.hashicorp.com/terraform/docs",
          "title": "Terraform Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.hashicorp.com/certification/terraform-associate",
          "title": "Terraform Associate Certification",
          "type": "course"
        },
        {
          "url": "https://spacelift.io/blog/terraform-best-practices",
          "title": "Terraform Best Practices",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez vos premières ressources GCP avec Terraform. Comprenez le state.",
        "2→3": "Développez des modules réutilisables. Implémentez la gestion du state remote.",
        "3→4": "Passez la certification Terraform Associate. Définissez les standards et modules Terraform réutilisables pour votre équipe."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "docker",
      "name": "Docker & Conteneurisation",
      "description": "Conteneuriser les applications (Dockerfile, compose, multi-stage builds)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance Docker",
        "1": "Je lance des conteneurs avec docker run et j'utilise les commandes de base",
        "2": "J'écris des Dockerfiles et j'utilise docker-compose pour plusieurs services",
        "3": "Je conçois des images optimisées avec multi-stage builds et layer caching",
        "4": "Je définis les standards Docker de l'équipe et je maîtrise les réseaux et la sécurité",
        "5": "Je conçois les standards de conteneurisation de l'organisation et j'arbitre les choix d'architecture Docker",
        "6": "Expert Docker reconnu, contributeur community"
      },
      "behavioral_indicators": {
        "1": [
          "Je sais lancer un conteneur avec docker run",
          "Je comprends la différence entre image et conteneur",
          "J'utilise docker ps et docker logs",
          "Je peux pull des images depuis Docker Hub"
        ],
        "2": [
          "J'écris des Dockerfiles fonctionnels",
          "J'utilise docker-compose pour plusieurs services",
          "Je sais construire et tag mes images",
          "Je gère les volumes pour la persistance"
        ],
        "3": [
          "J'utilise les multi-stage builds pour réduire la taille",
          "J'optimise le layer caching dans mes Dockerfiles",
          "Je configure les health checks",
          "Je gère les secrets et variables d'environnement"
        ],
        "4": [
          "Je définis les standards Docker de l'équipe",
          "J'optimise les temps de build et la taille des images",
          "Je maîtrise les réseaux Docker et la sécurité",
          "Je produis les images de base et les Dockerfiles de référence pour l'équipe"
        ],
        "5": [
          "Je définis les standards de conteneurisation pour l'organisation",
          "Je conçois les architectures de conteneurisation complexes pour l'organisation",
          "Je mentore les équipes sur les patterns de conteneurisation avancés",
          "J'ai mis en place le registry et les pipelines de build"
        ],
        "6": [
          "Je suis speaker à des conférences DockerCon ou Cloud Native",
          "Je contribue à Docker ou projets CNCF",
          "J'ai publié des articles sur la conteneurisation",
          "Je suis reconnu comme expert externe en containers"
        ]
      },
      "resources": [
        {
          "url": "https://docs.docker.com/get-started/",
          "title": "Docker Get Started",
          "type": "tutorial"
        },
        {
          "url": "https://docker-curriculum.com/",
          "title": "Docker Curriculum",
          "type": "tutorial"
        },
        {
          "url": "https://docs.docker.com/build/building/best-practices/",
          "title": "Dockerfile Best Practices",
          "type": "documentation"
        },
        {
          "url": "https://www.youtube.com/watch?v=fqMOX6JJhGo",
          "title": "Docker Tutorial for Beginners",
          "type": "video"
        }
      ],
      "improvement_tips": {
        "1→2": "Conteneurisez une application Python. Utilisez docker-compose pour plusieurs services.",
        "2→3": "Optimisez la taille des images avec multi-stage builds. Utilisez les layer caching.",
        "3→4": "Définissez les standards de conteneurisation. Formez les équipes."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "monitoring",
      "name": "Monitoring & Alerting",
      "description": "Surveiller les systèmes et configurer des alertes (Grafana, logs, métriques)",
      "core_roles": [
        "data_engineer",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          "NC",
          1,
          2
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance monitoring",
        "1": "Je consulte les dashboards existants et je comprends les métriques de base",
        "2": "Je crée des dashboards Grafana, je configure des alertes et j'écris des queries",
        "3": "Je conçois une stratégie de monitoring complète avec SLIs/SLOs et alerting sur anomalies",
        "4": "Je définis les standards de monitoring de l'équipe et j'améliore la fiabilité des systèmes",
        "5": "Je conçois la plateforme d'observabilité de l'organisation et j'arbitre les choix d'architecture de monitoring",
        "6": "Expert monitoring reconnu, speaker ObservabilityCon"
      },
      "behavioral_indicators": {
        "1": [
          "Je consulte les dashboards existants",
          "Je comprends les métriques de base (latence, erreurs)",
          "Je sais lire les logs dans Cloud Logging"
        ],
        "2": [
          "Je crée des dashboards Grafana simples",
          "Je configure des alertes basiques",
          "J'écris des queries pour explorer les métriques",
          "Je sais déboguer avec les logs"
        ],
        "3": [
          "Je conçois une stratégie de monitoring complète",
          "Je définis les SLIs et SLOs",
          "Je crée des dashboards pour les pipelines data",
          "J'implémente l'alerting sur les anomalies"
        ],
        "4": [
          "J'ai conçu l'architecture d'observabilité de l'équipe",
          "Je définis les standards de monitoring",
          "Je produis les dashboards de référence et les runbooks pour l'équipe",
          "Je mesure et améliore la fiabilité"
        ],
        "5": [
          "Je définis les standards d'observabilité pour l'organisation",
          "Je conduis les revues d'architecture de monitoring pour l'ensemble de l'organisation",
          "Je mentore les équipes sur les SLIs/SLOs et error budgets",
          "J'ai mis en place la plateforme d'observabilité"
        ],
        "6": [
          "Je suis speaker à des conférences ObservabilityCon ou SREcon",
          "Je contribue à Prometheus, Grafana ou outils similaires",
          "J'ai publié des articles sur l'observabilité",
          "Je suis reconnu comme expert externe en monitoring"
        ]
      },
      "resources": [
        {
          "url": "https://grafana.com/tutorials/",
          "title": "Grafana Tutorials",
          "type": "tutorial"
        },
        {
          "url": "https://prometheus.io/docs/introduction/overview/",
          "title": "Prometheus Documentation",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/monitoring/docs",
          "title": "Google Cloud Monitoring",
          "type": "documentation"
        },
        {
          "url": "https://sre.google/sre-book/monitoring-distributed-systems/",
          "title": "Google SRE Book - Monitoring",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Créez un dashboard Grafana pour vos pipelines. Configurez des alertes basiques.",
        "2→3": "Implémentez une stratégie de monitoring complète. Utilisez les SLIs/SLOs.",
        "3→4": "Concevez l'architecture d'observabilité de l'équipe. Documentez les runbooks d'incident response et formez les équipes."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "data_quality_management",
      "name": "Data Quality Management",
      "description": "Validation de données, détection d'anomalies, Elementary, dbt tests, alerting qualité, gouvernance de la qualité",
      "core_roles": [
        "analytics_eng",
        "data_engineer"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la qualité des données",
        "1": "Je comprends l'importance de la qualité des données et j'identifie les problèmes basiques",
        "2": "J'implémente des tests dbt et des validations, je documente les règles de qualité",
        "3": "Je conçois des frameworks de qualité avec détection d'anomalies automatisée et SLAs",
        "4": "Je définis la stratégie de data quality et la gouvernance de la qualité pour l'organisation",
        "5": "Je pilote le programme de gouvernance data quality à l'échelle de l'organisation",
        "6": "J'ai des résultats mesurables à grande échelle et je contribue à la communauté data quality"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends l'importance de la qualité des données",
          "Je sais identifier les doublons et valeurs nulles",
          "Je détecte les problèmes de qualité manuellement"
        ],
        "2": [
          "J'implémente des tests dbt (unique, not_null, accepted_values)",
          "Je configure des validations avec Elementary ou dbt packages",
          "Je mets en place des alertes simples sur la qualité",
          "Je documente les règles de qualité et les data owners"
        ],
        "3": [
          "Je conçois un framework de qualité pour l'équipe",
          "J'implémente la détection d'anomalies automatisée",
          "Je définis les SLAs de qualité par table et les responsabilités des data owners",
          "J'ai réduit significativement les incidents de qualité"
        ],
        "4": [
          "Je définis la stratégie de data quality et les processus de gouvernance",
          "Je mets en place le monitoring continu et les rapports de qualité",
          "Je produis les rapports de qualité et les guides de bonnes pratiques pour l'équipe",
          "Je mesure et communique les KPIs de qualité des données à la direction"
        ],
        "5": [
          "Je pilote le programme de gouvernance data quality à l'échelle de l'organisation",
          "Je définis les standards de qualité, les rôles (data owners, stewards) et les processus",
          "Je forme et mentore les équipes sur les stratégies de monitoring avancées",
          "Je mesure et communique la maturité data quality de l'organisation"
        ],
        "6": [
          "J'ai réduit le nombre d'incidents data quality de >50% sur 12 mois mesurés",
          "J'ai publié des articles ou retours d'expérience sur la data quality à l'échelle",
          "Je contribue à des projets open-source (Elementary, Soda, dbt packages)",
          "J'ai mis en place un programme data quality adopté par 3+ équipes avec des résultats mesurables"
        ]
      },
      "resources": [
        {
          "url": "https://docs.elementary-data.com/",
          "title": "Elementary Documentation",
          "type": "documentation"
        },
        {
          "url": "https://docs.getdbt.com/docs/build/tests",
          "title": "dbt Tests",
          "type": "documentation"
        },
        {
          "url": "https://www.montecarlodata.com/blog-data-observability-guide/",
          "title": "Data Observability Guide",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-quality-fundamentals/9781098112035/",
          "title": "Data Quality Fundamentals (O'Reilly)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Implémentez des tests dbt sur vos modèles critiques. Documentez les data owners.",
        "2→3": "Construisez un framework de qualité avec alerting automatique. Définissez les SLAs et data owners.",
        "3→4": "Concevez la stratégie data quality et gouvernance de l'organisation."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "data_governance",
      "name": "Data Gouvernance",
      "description": "Gouvernance des données: ownership, policies, compliance, data contracts, data catalog, lineage, metadata management, classification et data discovery self-service",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de la gouvernance des données",
        "1": "Je comprends qui est responsable des données et je sais naviguer dans le data catalog pour trouver ce dont j'ai besoin",
        "2": "Je documente les schémas, classifie les données, maintiens le catalog et je détecte les changements incompatibles (breaking changes)",
        "3": "Je conçois des frameworks de gouvernance, j'implémente les data contracts en CI/CD et je configure le lineage automatique",
        "4": "Je pilote le programme de gouvernance, je conçois l'architecture du data catalog et la stratégie de data discovery",
        "5": "Je conduis la transformation culturelle de la gouvernance des données dans l'organisation",
        "6": "J'ai des résultats mesurables à grande échelle et je contribue à la communauté data governance"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends les concepts de data ownership, classification et contrats de données",
          "Je navigue dans le data catalog pour trouver des données et comprends le lineage",
          "Je sais identifier qui est responsable d'un dataset",
          "Je connais les principes de base de la compliance (RGPD, données sensibles)"
        ],
        "2": [
          "Je documente les schémas, métadonnées et data owners dans le catalog",
          "J'applique les règles de classification des données et je détecte les changements incompatibles (breaking changes)",
          "J'identifie les producteurs et consommateurs de données",
          "Je maintiens à jour le registre des traitements pour mon périmètre"
        ],
        "3": [
          "J'implémente des data contracts avec validation automatique dans le CI/CD",
          "Je configure le lineage automatique et le self-service data",
          "Je définis les rôles et responsabilités (data owners, data stewards)",
          "Je mets en place les processus de compliance et d'audit"
        ],
        "4": [
          "Je pilote le programme de data governance pour mon domaine",
          "J'ai conçu l'architecture du data catalog et la stratégie de data discovery self-service",
          "Je coordonne les data owners et stewards et je mesure l'adoption",
          "Je produis des rapports de conformité et de maturité pour la direction"
        ],
        "5": [
          "Je conduis la transformation culturelle autour de la gouvernance des données",
          "Je définis les standards de gouvernance, contracts et catalogage à l'échelle de l'entreprise",
          "Je mentore les leaders data sur les enjeux de compliance et gouvernance",
          "Je mesure et améliore la maturité data governance de l'organisation"
        ],
        "6": [
          "Je suis speaker à des conférences Data Governance",
          "J'ai publié des articles sur la gouvernance des données à l'échelle",
          "J'ai mis en place un programme de gouvernance avec des métriques d'adoption mesurables (>80% de couverture catalog)",
          "J'ai formalisé et déployé des data contracts adoptés par 3+ équipes productrices"
        ]
      },
      "resources": [
        {
          "url": "https://datacontract.com/",
          "title": "Data Contract Specification",
          "type": "documentation"
        },
        {
          "url": "https://docs.elementary-data.com/",
          "title": "Elementary Documentation",
          "type": "documentation"
        },
        {
          "url": "https://www.oreilly.com/library/view/data-governance-the/9781492063483/",
          "title": "Data Governance: The Definitive Guide (O'Reilly)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Documentez les schémas et data owners de vos tables critiques. Classifiez les données selon leur sensibilité.",
        "2→3": "Implémentez des data contracts avec validation CI/CD. Configurez le lineage automatique et le self-service data.",
        "3→4": "Pilotez le programme de gouvernance à l'échelle. Concevez l'architecture du data catalog et mesurez l'adoption."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "cost_optimization",
      "name": "Cost & Performance Optimization",
      "description": "Gestion des coûts cloud (FinOps), optimisation des requêtes (partitioning, clustering, materialized views, plans d'exécution), monitoring des performances",
      "core_roles": [
        "data_engineer",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          "NC",
          "NC",
          1,
          2
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune connaissance de l'optimisation des coûts et performances",
        "1": "Je comprends les modèles de facturation cloud et l'impact des requêtes sur les performances",
        "2": "J'analyse les coûts de mes projets, j'utilise EXPLAIN et j'optimise mes requêtes avec des filtres sur les partitions",
        "3": "J'optimise les coûts cloud (slots, stockage), je conçois des stratégies de partitioning/clustering et je mets en place le monitoring",
        "4": "Je définis la stratégie FinOps et les standards de performance de l'équipe, j'ai réduit les coûts et temps de traitement significativement",
        "5": "Je conçois le programme FinOps et performance de l'organisation, j'audite les pipelines critiques et je forme les équipes",
        "6": "Expert FinOps et query optimization reconnu, certifié FinOps Practitioner"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le modèle de facturation BigQuery (on-demand vs slots)",
          "Je sais que le volume de données et la structure des requêtes impactent les performances",
          "Je connais l'existence des plans d'exécution"
        ],
        "2": [
          "J'analyse les coûts de mes projets GCP et j'identifie les requêtes les plus coûteuses",
          "J'utilise EXPLAIN pour analyser mes requêtes et je comprends l'impact du SELECT *",
          "Je mets en place des alertes de budget",
          "J'ai optimisé une requête en réduisant son temps de 50%+"
        ],
        "3": [
          "Je configure les slot reservations BigQuery et j'optimise les stratégies de stockage",
          "Je conçois des stratégies de partitioning et clustering",
          "J'utilise les materialized views pour les agrégations fréquentes",
          "Je mets en place le monitoring des coûts et des performances"
        ],
        "4": [
          "J'ai défini la stratégie FinOps et les standards de performance de l'équipe",
          "J'audite les performances des pipelines et j'ai réduit les coûts de 30%+",
          "Je produis les dashboards de coûts et les guides d'optimisation pour l'équipe",
          "Je produis des rapports de coûts et de performance réguliers"
        ],
        "5": [
          "Je définis les standards FinOps et de performance pour l'organisation",
          "J'audite les coûts cloud et les requêtes complexes à l'échelle de l'organisation",
          "Je mentore les équipes sur les stratégies de cost management et d'optimisation",
          "J'ai mis en place le programme FinOps et performance de l'entreprise"
        ],
        "6": [
          "Je suis speaker à des conférences FinOps ou Data Engineering",
          "J'ai obtenu la certification FinOps Practitioner",
          "J'ai publié des articles sur l'optimisation des coûts et performances data",
          "Je suis reconnu comme expert externe en FinOps et query optimization"
        ]
      },
      "resources": [
        {
          "url": "https://www.finops.org/introduction/what-is-finops/",
          "title": "What is FinOps",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/architecture/framework/cost-optimization",
          "title": "GCP Cost Optimization",
          "type": "documentation"
        },
        {
          "url": "https://cloud.google.com/bigquery/docs/best-practices-performance-overview",
          "title": "BigQuery Performance Guide",
          "type": "documentation"
        },
        {
          "url": "https://use-the-index-luke.com/",
          "title": "Use The Index, Luke!",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Analysez les coûts de vos projets GCP. Apprenez à lire les plans d'exécution et optimisez une requête lente.",
        "2→3": "Implémentez le slot reservation et le partitioning/clustering sur vos tables critiques. Mettez en place le monitoring des coûts.",
        "3→4": "Définissez la stratégie FinOps et de performance de l'organisation. Passez la certification FinOps."
      },
      "category": "ops",
      "category_name": "Data Ops"
    },
    {
      "id": "technical_scoping",
      "name": "Cadrage Technique",
      "description": "Appréhender les enjeux techniques d'un projet, effectuer un découpage fonctionnel et évaluer la faisabilité et la complexité des solutions",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Aucune capacité de cadrage technique",
        "1": "Je comprends les enjeux techniques d'un projet simple et j'identifie les grandes étapes",
        "2": "Je découpe un projet en tâches fonctionnelles, j'estime la complexité et j'identifie les dépendances",
        "3": "Je cadre des projets complexes multi-équipes, j'anticipe les risques techniques et je propose des alternatives",
        "4": "J'arbitre les choix d'architecture sur les projets complexes et je guide la stratégie technique",
        "5": "Je définis les méthodologies de cadrage technique pour l'entreprise et je forme les tech leads au cadrage de projets complexes",
        "6": "Expert en cadrage technique reconnu en externe, consultant ou formateur"
      },
      "behavioral_indicators": {
        "1": [
          "Je comprends le besoin fonctionnel derrière une demande technique",
          "Je sais identifier les grandes étapes d'un projet simple",
          "Je pose des questions pour clarifier le périmètre d'un sujet"
        ],
        "2": [
          "Je découpe un projet en tâches avec des livrables clairs",
          "J'estime la complexité relative des tâches (S/M/L)",
          "J'identifie les dépendances techniques entre composants",
          "Je rédige des spécifications fonctionnelles pour mes tâches"
        ],
        "3": [
          "Je cadre des projets impliquant plusieurs équipes",
          "J'anticipe les risques techniques et propose des plans de mitigation",
          "Je compare plusieurs approches techniques avec leurs trade-offs",
          "Je produis des documents de cadrage structurés (ADR, RFC)"
        ],
        "4": [
          "J'arbitre les choix d'architecture sur les projets complexes",
          "Je guide la stratégie technique de l'équipe",
          "Je forme les autres au cadrage et à l'estimation",
          "Je pilote les cadrages stratégiques de l'organisation"
        ],
        "5": [
          "Je définis les méthodologies de cadrage technique pour l'entreprise",
          "Je forme les tech leads au cadrage de projets complexes",
          "J'arbitre les décisions d'architecture structurantes",
          "J'ai mis en place des processus de cadrage reproductibles"
        ],
        "6": [
          "Je suis consultant externe en cadrage et architecture technique",
          "Je donne des conférences sur le cadrage et la planification technique",
          "J'ai publié des articles sur les méthodologies de cadrage",
          "Je suis reconnu comme expert en cadrage technique dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.atlassian.com/agile/project-management/estimation",
          "title": "Atlassian - Estimation Agile",
          "type": "documentation"
        },
        {
          "url": "https://adr.github.io/",
          "title": "Architecture Decision Records",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/software-architecture",
          "title": "Software Architecture (Coursera)",
          "type": "course"
        },
        {
          "url": "https://martinfowler.com/articles/writingPatterns.html",
          "title": "Martin Fowler - Writing Patterns",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Découpez un projet en tâches avec des estimations. Rédigez vos premières spécifications fonctionnelles.",
        "2→3": "Cadrez un projet multi-équipes. Rédigez un ADR ou RFC pour documenter vos choix techniques.",
        "3→4": "Arbitrez les choix d'architecture sur un projet stratégique. Formez les juniors au cadrage."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "problem_solving",
      "name": "Résolution de Problèmes",
      "description": "Approcher les problèmes complexes de manière systématique",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Ne peut pas structurer les problèmes",
        "1": "Je décompose des problèmes simples en sous-problèmes et je cherche des solutions existantes",
        "2": "J'approche les problèmes complexes de manière structurée (5 whys, issue trees) et je priorise par impact",
        "3": "Je résous des problèmes ambigus, je crée des frameworks réutilisables et je gère l'incertitude",
        "4": "Je guide les décisions stratégiques par la résolution de problèmes et je forme les autres",
        "5": "Je définis la méthodologie de résolution de problèmes pour l'entreprise et je forme les managers",
        "6": "Expert reconnu en résolution de problèmes, consultant externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je décompose un problème en sous-problèmes",
          "Je cherche des solutions similaires avant de réinventer",
          "Je sais poser les bonnes questions pour clarifier un problème"
        ],
        "2": [
          "J'utilise une approche structurée (5 whys, issue trees)",
          "Je documente mes hypothèses et les valide",
          "Je priorise les problèmes par impact et urgence",
          "Je sais quand demander de l'aide vs persévérer seul"
        ],
        "3": [
          "Je crée des frameworks réutilisables pour résoudre des classes de problèmes",
          "Je gère l'ambiguïté et avance malgré l'incertitude",
          "J'ai résolu des problèmes impliquant plusieurs équipes",
          "Je challenge les hypothèses implicites"
        ],
        "4": [
          "Je guide des décisions stratégiques par la résolution de problèmes",
          "Je forme les autres à structurer leurs problèmes",
          "J'interviens sur les problèmes complexes de l'organisation",
          "Je transforme les problèmes en opportunités"
        ],
        "5": [
          "Je définis la méthodologie de résolution de problèmes pour l'entreprise",
          "Je forme les managers et leads à la résolution de problèmes",
          "Je conduis la résolution des problèmes stratégiques cross-équipes",
          "J'ai institutionnalisé des pratiques de problem solving"
        ],
        "6": [
          "Je suis consultant externe en résolution de problèmes",
          "Je donne des conférences sur les méthodologies de problem solving",
          "J'ai publié des articles ou livres sur la résolution de problèmes",
          "Je suis reconnu comme expert problem solving dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/problem-solving",
          "title": "Problem Solving Skills (Coursera)",
          "type": "course"
        },
        {
          "url": "https://untools.co/",
          "title": "Untools - Problem Solving Tools",
          "type": "documentation"
        },
        {
          "url": "https://www.mckinsey.com/capabilities/strategy-and-corporate-finance/our-insights/the-problem-with-problem-solving",
          "title": "McKinsey - Problem Solving",
          "type": "documentation"
        },
        {
          "url": "https://bulletproofproblemsolving.com/",
          "title": "Bulletproof Problem Solving",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Utilisez une approche structurée (5 whys, issue trees). Documentez votre processus.",
        "2→3": "Créez des frameworks réutilisables. Résolvez un problème cross-équipes.",
        "3→4": "Guidez des décisions stratégiques. Formez les autres à la résolution de problèmes."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "mentoring_leadership",
      "name": "Mentorat & Leadership",
      "description": "Accompagner et faire grandir les membres de l'équipe",
      "core_roles": [],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "data_scientist": [
          "NC",
          1,
          2,
          3
        ],
        "analytics_eng": [
          "NC",
          1,
          2,
          3
        ],
        "ml_engineer": [
          "NC",
          1,
          2,
          3
        ],
        "backend": [
          "NC",
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Pas de compétence en mentorat",
        "1": "J'aide ponctuellement un collègue sur un sujet que je maîtrise",
        "2": "Je mentor régulièrement, je fais des code reviews constructives et j'organise du pair programming",
        "3": "J'accompagne la montée en compétence de plusieurs personnes et j'organise des sessions de partage",
        "4": "Je développe un programme de mentorat structuré et je contribue aux évaluations",
        "5": "Je définis le programme de mentorat pour l'entreprise et je forme les mentors et managers au coaching",
        "6": "Coach et mentor reconnu en externe, formateur"
      },
      "behavioral_indicators": {
        "1": [
          "J'aide mes collègues quand ils ont des questions",
          "Je partage des ressources utiles avec l'équipe",
          "Je peux expliquer un sujet que je maîtrise"
        ],
        "2": [
          "Je fais des code reviews pédagogiques en expliquant le 'pourquoi' de mes retours",
          "J'ai mentoré au moins une personne sur un sujet spécifique",
          "Je donne du feedback de progression à mes mentorés avec des actions concrètes",
          "J'organise des sessions de pair programming"
        ],
        "3": [
          "Je suis le mentor officiel d'un ou plusieurs juniors",
          "J'organise des sessions de partage de connaissances",
          "J'ai accompagné quelqu'un dans sa montée en compétence",
          "Je crée de la documentation pour faciliter l'onboarding"
        ],
        "4": [
          "Je développe un programme de mentorat structuré",
          "Je suis reconnu comme un leader technique",
          "J'ai aidé plusieurs personnes à progresser significativement",
          "Je contribue aux décisions de promotion et évaluation"
        ],
        "5": [
          "Je définis le programme de mentorat pour l'entreprise",
          "Je forme les mentors et managers au coaching",
          "Je mesure l'efficacité du programme de mentorat",
          "J'ai créé des parcours de développement de carrière"
        ],
        "6": [
          "Je suis coach ou mentor externe pour d'autres entreprises",
          "Je donne des conférences sur le leadership et le mentorat",
          "J'ai publié sur les techniques de coaching et développement",
          "Je suis reconnu comme expert en leadership dans l'industrie"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/leadership-and-emotional-intelligence",
          "title": "Leadership and Emotional Intelligence",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2015/12/everyone-deserves-a-great-manager",
          "title": "HBR - Great Manager",
          "type": "documentation"
        },
        {
          "url": "https://www.amazon.com/Radical-Candor-Revised-Kick-Ass-Humanity/dp/1250235375",
          "title": "Radical Candor",
          "type": "book"
        },
        {
          "url": "https://www.atlassian.com/team-playbook/plays/retrospective",
          "title": "Atlassian Retrospectives",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Mentorez un junior sur un sujet spécifique. Faites des code reviews constructives.",
        "2→3": "Accompagnez plusieurs personnes dans leur développement. Organisez des sessions de partage.",
        "3→4": "Développez un programme de mentorat. Mesurez la progression de vos mentorés."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "communication",
      "name": "Communication & Stakeholders",
      "description": "Communiquer efficacement à l'écrit et à l'oral, vulgariser les concepts techniques, gérer les stakeholders et représenter l'équipe",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Ne communique pas efficacement",
        "1": "J'explique mon travail à mes collègues proches et je travaille avec mes stakeholders directs",
        "2": "Je fais des démos régulières, j'adapte mon discours à mon audience et je gère plusieurs stakeholders",
        "3": "Je vulgarise des sujets complexes, je représente l'équipe et j'influence les décisions au niveau senior",
        "4": "Je communique avec toutes les parties prenantes (tech, produit, direction) et je forme les autres",
        "5": "Je définis les standards de communication et de collaboration pour l'entreprise",
        "6": "Speaker reconnu, formateur externe en communication technique"
      },
      "behavioral_indicators": {
        "1": [
          "J'explique mon code et mes résultats de manière claire",
          "Je communique régulièrement avec mon PM/manager direct",
          "Je comprends les besoins de mes stakeholders directs"
        ],
        "2": [
          "Je fais des démos régulières de mon travail à l'équipe",
          "J'adapte mon discours à mon audience (tech vs non-tech)",
          "Je gère plusieurs stakeholders avec des besoins différents",
          "Je communique proactivement les blocages et retards"
        ],
        "3": [
          "Je vulgarise des concepts techniques complexes avec aisance",
          "Je représente l'équipe data lors de réunions transverses",
          "J'influence les décisions au niveau senior et j'aligne des priorités divergentes",
          "J'ai présenté dans un brown bag, meetup interne ou conférence"
        ],
        "4": [
          "Je communique efficacement avec toutes les parties prenantes (tech, produit, direction)",
          "Je suis le point de contact data pour plusieurs équipes",
          "Je crée des supports de communication pour l'équipe (templates, guides)",
          "Je forme les autres à la communication et à la gestion des stakeholders"
        ],
        "5": [
          "Je définis les standards de communication et de collaboration inter-équipes pour l'entreprise",
          "Je coache les speakers et rédacteurs",
          "J'interviens comme médiateur pour les conflits inter-équipes",
          "J'ai créé des frameworks de priorisation et communication organisationnels"
        ],
        "6": [
          "Je suis speaker reconnu dans des conférences externes",
          "Je suis formateur externe en communication technique",
          "J'ai publié des contenus reconnus sur la communication et l'influence",
          "J'ai conseillé d'autres organisations sur leur communication"
        ]
      },
      "resources": [
        {
          "url": "https://www.storytellingwithdata.com/",
          "title": "Storytelling with Data",
          "type": "book"
        },
        {
          "url": "https://hbr.org/2014/03/manage-your-stakeholders",
          "title": "HBR - Manage Your Stakeholders",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/public-speaking",
          "title": "Public Speaking (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.writethedocs.org/guide/",
          "title": "Write the Docs - Documentation Guide",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Faites des démos régulières. Identifiez tous vos stakeholders et adaptez votre discours à chacun.",
        "2→3": "Vulgarisez un sujet complexe lors d'un brown bag. Gérez un conflit entre stakeholders.",
        "3→4": "Présentez aux parties prenantes non-techniques. Devenez le point de contact data clé."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "project_management",
      "name": "Gestion de Projet Data",
      "description": "Piloter un projet data de bout en bout",
      "core_roles": [
        "data_analyst",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          "NC",
          1,
          2,
          3
        ],
        "data_engineer": [
          1,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          1,
          2,
          3
        ],
        "analytics_eng": [
          1,
          1,
          2,
          3
        ],
        "ml_engineer": [
          1,
          1,
          2,
          3
        ],
        "backend": [
          1,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune expérience en gestion de projet",
        "1": "Je gère mes propres tâches et je respecte les deadlines",
        "2": "Je pilote un petit projet data avec des livrables clairs et quelques dépendances",
        "3": "Je gère des projets complexes multi-équipes avec des contraintes fortes",
        "4": "Je définis des méthodologies de gestion de projet data et je forme les équipes",
        "5": "Je définis les méthodologies projet pour l'entreprise et je forme les chefs de projet et tech leads",
        "6": "Expert gestion de projet (conférences, formateur)"
      },
      "behavioral_indicators": {
        "1": [
          "Je gère mes tâches dans un outil (Jira, Linear, etc.)",
          "Je respecte les deadlines communiquées",
          "Je sais estimer le temps nécessaire pour mes tâches"
        ],
        "2": [
          "J'ai piloté un projet data de bout en bout",
          "Je découpe un projet en tâches avec des livrables clairs",
          "Je communique l'avancement régulièrement aux stakeholders",
          "Je gère les risques et les blocages proactivement"
        ],
        "3": [
          "Je gère des projets avec des dépendances multi-équipes",
          "J'ai livré des projets impliquant 3+ personnes",
          "Je coordonne les travaux entre équipes",
          "J'ai géré un projet avec des contraintes fortes"
        ],
        "4": [
          "J'ai défini une méthodologie de gestion de projet data",
          "Je forme les autres à la gestion de projet",
          "Je pilote les projets complexes",
          "J'ai un track record de projets livrés avec succès"
        ],
        "5": [
          "Je définis les méthodologies projet pour l'entreprise",
          "Je forme les chefs de projet et tech leads",
          "Je pilote les projets stratégiques",
          "J'ai mis en place des outils et processus projet"
        ],
        "6": [
          "Je suis consultant externe en gestion de projet data",
          "Je donne des conférences sur la gestion de projet",
          "J'ai publié sur les méthodologies de projet data",
          "Je suis certifié et reconnu comme expert (PMP, etc.)"
        ]
      },
      "resources": [
        {
          "url": "https://www.coursera.org/learn/project-management-foundations",
          "title": "Project Management Foundations",
          "type": "course"
        },
        {
          "url": "https://www.atlassian.com/agile/project-management",
          "title": "Atlassian Agile Project Management",
          "type": "documentation"
        },
        {
          "url": "https://www.pmi.org/learning/library",
          "title": "PMI Learning Library",
          "type": "documentation"
        },
        {
          "url": "https://asana.com/resources/project-management-basics",
          "title": "Project Management Basics",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Pilotez un petit projet data avec des livrables clairs. Utilisez un outil de suivi.",
        "2→3": "Gérez un projet avec plusieurs dépendances. Communiquez régulièrement sur l'avancement.",
        "3→4": "Définissez une méthodologie de gestion de projet data. Formez les équipes."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "posture",
      "name": "Collaboration & Posture",
      "description": "Collaborer efficacement, esprit critique, humilité, pédagogie, facilitation, animer la communauté technique et gérer les conflits",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Posture professionnelle insuffisante et travail isolé",
        "1": "Je suis curieux, ouvert au feedback, j'ose dire 'je ne sais pas' et je partage mes idées",
        "2": "Je fais preuve d'esprit critique constructif, je fais du pair programming et je contribue aux rituels d'équipe",
        "3": "Je facilite les discussions techniques, j'anime la communauté et je gère les désaccords avec bienveillance",
        "4": "J'inspire une culture d'apprentissage continu, je crée un environnement sûr et je résous les conflits",
        "5": "Je définis la culture et les valeurs techniques pour l'entreprise et je forme les managers",
        "6": "Reconnu comme modèle de collaboration et posture en externe"
      },
      "behavioral_indicators": {
        "1": [
          "Je suis curieux et je cherche à comprendre avant de critiquer",
          "Je dis 'je ne sais pas' quand c'est le cas, sans honte",
          "Je partage mes idées et mes doutes avec l'équipe"
        ],
        "2": [
          "Je pratique l'egoless programming : mon code n'est pas mon identité",
          "Je fais du pair programming régulièrement et je contribue aux code reviews",
          "Je partage mes apprentissages et mes erreurs pour faire progresser le collectif",
          "Je suis humble face à la complexité et je demande de l'aide quand nécessaire"
        ],
        "3": [
          "J'anime des sessions de partage (brown bags, tech talks)",
          "Je facilite les décisions collectives et je gère les désaccords avec diplomatie",
          "Je challenge les idées avec bienveillance, en apportant des alternatives",
          "Je crée des espaces d'échange (guildes, communautés de pratique)"
        ],
        "4": [
          "J'inspire une culture d'apprentissage continu dans l'équipe",
          "Je crée un climat de confiance où l'équipe ose expérimenter et échouer",
          "Je résous les conflits au sein de l'équipe de manière constructive",
          "Je forme les autres à la facilitation et au travail collaboratif"
        ],
        "5": [
          "Je définis la culture et les valeurs techniques pour l'entreprise",
          "Je mets en place des rituels favorisant la bonne posture (retros, blameless post-mortems)",
          "Je forme les managers et leads à la facilitation et au leadership bienveillant",
          "Je mets en place des rituels de collaboration inter-équipes"
        ],
        "6": [
          "Je suis reconnu en externe pour ma posture et mon leadership technique",
          "Je donne des conférences sur la culture engineering et la collaboration",
          "J'ai publié sur les bonnes pratiques de posture en équipe tech",
          "Je suis consultant externe en collaboration et facilitation d'équipe"
        ]
      },
      "resources": [
        {
          "url": "https://blog.codinghorror.com/the-ten-commandments-of-egoless-programming/",
          "title": "The Ten Commandments of Egoless Programming",
          "type": "documentation"
        },
        {
          "url": "https://martinfowler.com/articles/on-pair-programming.html",
          "title": "Martin Fowler - On Pair Programming",
          "type": "documentation"
        },
        {
          "url": "https://www.radicalcandor.com/",
          "title": "Radical Candor",
          "type": "book"
        },
        {
          "url": "https://www.amazon.com/Five-Dysfunctions-Team-Leadership-Fable/dp/0787960756",
          "title": "The Five Dysfunctions of a Team",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Pratiquez l'egoless programming en code review. Faites du pair programming régulièrement.",
        "2→3": "Animez un brown bag ou un tech talk. Facilitez une décision collective lors d'un débat technique.",
        "3→4": "Instaurez des pratiques de blameless post-mortem. Créez un environnement sûr pour l'expérimentation."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "culture_feedback",
      "name": "Culture du Feedback",
      "description": "Donner et recevoir du feedback de manière constructive, instaurer une culture de feedback continu au sein de l'équipe et de l'organisation",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Ne sait pas recevoir ni donner du feedback",
        "1": "Je reçois le feedback avec ouverture et j'en tiens compte",
        "2": "Je donne du feedback constructif à mes pairs et je le sollicite activement",
        "3": "J'instaure une culture du feedback au sein de mon équipe",
        "4": "Je mets en place des processus de feedback à l'échelle de l'organisation",
        "5": "Je transforme la culture de feedback de l'organisation entière",
        "6": "Reconnu en externe comme expert en culture du feedback"
      },
      "behavioral_indicators": {
        "1": [
          "Je reçois le feedback sans me braquer et je remercie la personne",
          "Je prends en compte les retours pour améliorer mon travail",
          "Je demande du feedback à mon manager ou mes collègues proches"
        ],
        "2": [
          "Je donne du feedback constructif à mes collègues en utilisant des faits concrets",
          "Je sollicite régulièrement du feedback auprès de différentes personnes",
          "Je formule mes retours de manière bienveillante et actionnable",
          "Je fais la distinction entre feedback sur le travail et feedback sur la personne"
        ],
        "3": [
          "J'ai instauré des rituels de feedback réguliers dans mon équipe (1:1, retros)",
          "Je forme mes collègues à donner et recevoir du feedback efficacement",
          "Je crée un environnement psychologiquement sûr pour l'échange de feedback",
          "Je donne du feedback ascendant (à mon manager) de manière constructive"
        ],
        "4": [
          "Je mets en place des processus de feedback structurés (360°, peer reviews)",
          "Je mesure l'efficacité des pratiques de feedback dans l'organisation",
          "Je forme les managers à la culture du feedback",
          "Je résous les situations de feedback difficiles (conflits, tensions)"
        ],
        "5": [
          "Je transforme la culture de feedback à l'échelle de toute l'organisation",
          "J'ai mis en place des outils et processus de feedback à grande échelle",
          "Je conduis les situations de feedback sensibles (performance, recadrage)",
          "Je mesure l'impact de la culture feedback sur la performance des équipes"
        ],
        "6": [
          "Je suis consultant ou formateur externe en culture du feedback",
          "Je donne des conférences sur les pratiques de feedback en entreprise",
          "J'ai publié des articles ou ouvrages sur la culture du feedback",
          "Je suis reconnu comme expert en feedback dans l'industrie tech"
        ]
      },
      "resources": [
        {
          "url": "https://www.radicalcandor.com/",
          "title": "Radical Candor - Kim Scott",
          "type": "book"
        },
        {
          "url": "https://www.coursera.org/learn/feedback",
          "title": "Giving Helpful Feedback (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2019/03/the-feedback-fallacy",
          "title": "HBR - The Feedback Fallacy",
          "type": "documentation"
        },
        {
          "url": "https://www.nonviolentcommunication.com/",
          "title": "Communication Non Violente (CNV)",
          "type": "book"
        }
      ],
      "improvement_tips": {
        "1→2": "Donnez du feedback constructif à un collègue en utilisant la méthode SBI (Situation, Comportement, Impact). Sollicitez du feedback après chaque projet.",
        "2→3": "Instaurez un rituel de feedback régulier dans votre équipe. Formez vos collègues aux techniques de feedback constructif.",
        "3→4": "Mettez en place un processus de feedback 360° dans votre organisation. Formez les managers à la culture du feedback."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "proactivity_challenge",
      "name": "Proactivité & Challenge",
      "description": "Partager ses opinions, proposer des améliorations de manière proactive, challenger les décisions et les pratiques avec bienveillance à tous les niveaux",
      "core_roles": [
        "data_analyst",
        "data_engineer",
        "data_scientist",
        "analytics_eng",
        "ml_engineer",
        "backend"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          1,
          2,
          3,
          4
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          4
        ],
        "ml_engineer": [
          1,
          2,
          3,
          4
        ],
        "backend": [
          1,
          2,
          3,
          4
        ]
      },
      "level_descriptions": {
        "0": "Reste passif et n'ose pas partager ses idées",
        "1": "Je partage mon opinion au sein de mon équipe",
        "2": "Je propose des améliorations de manière proactive",
        "3": "Je challenge les décisions et pratiques au-delà de mon équipe",
        "4": "J'influence les décisions au niveau de la direction",
        "5": "J'impulse des changements stratégiques à l'échelle de l'organisation",
        "6": "Reconnu en externe pour sa capacité à challenger et innover"
      },
      "behavioral_indicators": {
        "1": [
          "Je partage mon avis lors des réunions d'équipe, même quand il diffère",
          "Je pose des questions quand quelque chose ne me semble pas clair ou optimal",
          "J'ose proposer des idées nouvelles dans un cadre bienveillant"
        ],
        "2": [
          "Je propose des améliorations concrètes sur les processus ou le code sans qu'on me le demande",
          "Je prends l'initiative de résoudre des problèmes que j'identifie",
          "Je challenge les choix techniques de manière constructive en code review",
          "Je porte des sujets d'amélioration auprès de mon manager"
        ],
        "3": [
          "Je challenge les décisions et pratiques au-delà de mon équipe",
          "Je porte des propositions d'amélioration auprès d'autres équipes",
          "Je sais argumenter et défendre une position avec des données et des faits",
          "Je crée des espaces pour que les autres puissent aussi challenger (retros, RFC)"
        ],
        "4": [
          "J'influence les décisions stratégiques au niveau du comité de direction",
          "Je porte des sujets de transformation auprès du leadership",
          "Je challenge les orientations techniques de l'organisation",
          "Je forme les autres à oser challenger avec bienveillance"
        ],
        "5": [
          "J'impulse des changements stratégiques à l'échelle de toute l'organisation",
          "Je mets en place des processus pour favoriser l'innovation bottom-up (hackathons, RFC)",
          "J'arbitre les décisions stratégiques controversées",
          "Je crée une culture où le challenge constructif est valorisé"
        ],
        "6": [
          "Je suis reconnu en externe pour ma capacité à challenger et innover",
          "Je donne des conférences sur la proactivité et le challenge constructif",
          "J'ai publié sur les pratiques de challenge et d'innovation en entreprise",
          "J'ai conseillé d'autres organisations sur la transformation de leur culture"
        ]
      },
      "resources": [
        {
          "url": "https://www.amazon.com/Think-Again-Power-Knowing-What/dp/1984878107",
          "title": "Think Again - Adam Grant",
          "type": "book"
        },
        {
          "url": "https://www.coursera.org/learn/creative-thinking-innovation",
          "title": "Creative Thinking and Innovation (Coursera)",
          "type": "course"
        },
        {
          "url": "https://hbr.org/2017/01/how-to-speak-up-about-ethical-issues-at-work",
          "title": "HBR - How to Speak Up at Work",
          "type": "documentation"
        },
        {
          "url": "https://oxide.computer/blog/rfd-1-requests-for-discussion",
          "title": "Oxide - Requests for Discussion (RFD)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Proposez une amélioration concrète sur un processus ou un outil de votre équipe. Prenez l'initiative de résoudre un problème identifié.",
        "2→3": "Challengez une décision technique en dehors de votre équipe avec des arguments factuels. Créez une RFC pour proposer un changement transverse.",
        "3→4": "Portez un sujet de transformation auprès de la direction. Formez vos collègues à oser challenger avec bienveillance."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    },
    {
      "id": "strategic_thinking",
      "name": "Pensée Stratégique & Priorisation",
      "description": "Aligner le travail data sur les objectifs business, évaluer l'impact potentiel des analyses et prioriser les sujets à fort levier",
      "core_roles": [
        "data_analyst",
        "data_scientist",
        "analytics_eng"
      ],
      "levels": {
        "data_analyst": [
          1,
          2,
          3,
          4
        ],
        "data_engineer": [
          0,
          1,
          2,
          3
        ],
        "data_scientist": [
          1,
          2,
          3,
          4
        ],
        "analytics_eng": [
          1,
          2,
          3,
          3
        ],
        "ml_engineer": [
          0,
          1,
          2,
          3
        ],
        "backend": [
          0,
          1,
          2,
          3
        ]
      },
      "level_descriptions": {
        "0": "Aucune prise de recul sur l'alignement business du travail",
        "1": "Je comprends les KPIs de mon équipe et je relie mon travail aux objectifs métier",
        "2": "Je priorise mes analyses selon l'impact business attendu et je dimensionne les opportunités",
        "3": "Je construis des roadmaps data alignées sur la stratégie business et je challenge les priorités cross-équipes",
        "4": "Je définis la stratégie data en lien avec la direction et j'arbitre les investissements data à l'échelle de l'organisation",
        "5": "Je définis la vision data stratégique de l'entreprise et j'influence les décisions business à partir des données",
        "6": "Reconnu en externe pour sa vision stratégique data et son impact business"
      },
      "behavioral_indicators": {
        "1": [
          "Je connais les KPIs principaux de mon équipe et leur signification",
          "Je comprends comment mon travail contribue aux objectifs de l'équipe",
          "Je pose des questions sur le 'pourquoi' avant de me lancer dans une analyse"
        ],
        "2": [
          "J'évalue l'impact business potentiel avant de lancer une analyse (opportunity sizing)",
          "Je priorise mes sujets en fonction du levier business, pas seulement de la faisabilité technique",
          "Je sais dire non ou 'pas maintenant' à une demande à faible impact",
          "Je propose des analyses proactives alignées sur les enjeux business du moment"
        ],
        "3": [
          "Je construis des roadmaps data trimestrielles alignées sur les OKR de l'entreprise",
          "Je challenge les priorités des stakeholders avec des arguments data-driven",
          "J'identifie des opportunités business que les données peuvent éclairer avant qu'on me le demande",
          "Je dimensionne les projets data en termes d'impact business (€, users, conversion)"
        ],
        "4": [
          "Je participe aux décisions stratégiques de l'entreprise en apportant la perspective data",
          "J'arbitre les investissements data (infra, outils, équipe) en fonction du ROI",
          "Je définis les KPIs stratégiques avec la direction",
          "Je forme les managers à utiliser les données pour leurs décisions stratégiques"
        ],
        "5": [
          "Je définis la vision data à long terme alignée sur la stratégie d'entreprise",
          "J'éclaire la direction sur les décisions business majeures grâce aux données",
          "Je mets en place une culture data-driven à l'échelle de l'organisation",
          "J'influence la stratégie produit et business grâce aux insights data"
        ],
        "6": [
          "Je suis reconnu en externe pour ma capacité à créer de la valeur business par la data",
          "Je donne des conférences sur la stratégie data et l'alignement business",
          "J'ai publié sur les meilleures pratiques de data strategy",
          "Je conseille d'autres organisations sur leur stratégie data"
        ]
      },
      "resources": [
        {
          "url": "https://www.amazon.com/Lean-Analytics-Better-Startup-Faster/dp/1449335675",
          "title": "Lean Analytics - Alistair Croll & Ben Yoskovitz",
          "type": "book"
        },
        {
          "url": "https://hbr.org/2020/02/use-this-framework-to-predict-the-success-of-your-big-data-project",
          "title": "HBR - Predicting Big Data Project Success",
          "type": "documentation"
        },
        {
          "url": "https://www.coursera.org/learn/analytics-business-metrics",
          "title": "Business Metrics for Data-Driven Companies (Coursera)",
          "type": "course"
        },
        {
          "url": "https://www.reforge.com/blog/scaling-data",
          "title": "Scaling Data Framework (Reforge)",
          "type": "documentation"
        }
      ],
      "improvement_tips": {
        "1→2": "Avant chaque analyse, estimez l'impact business potentiel. Apprenez à prioriser avec un framework (RICE, ICE) et à dire non aux demandes à faible impact.",
        "2→3": "Construisez une roadmap data alignée sur les OKR. Challengez les priorités de vos stakeholders avec des données d'impact.",
        "3→4": "Participez aux discussions stratégiques de la direction. Mesurez le ROI des projets data pour arbitrer les investissements."
      },
      "category": "soft_skills",
      "category_name": "Soft Skills"
    }
  ],
  "assessment_modes": {
    "quick": {
      "name": "Rapide",
      "description": "15-20 compétences clés, ~10-15 min",
      "icon": "zap",
      "skill_count_target": 15
    },
    "standard": {
      "name": "Standard",
      "description": "Toutes les compétences du rôle, ~25-35 min",
      "icon": "clipboard"
    }
  },
  "core_skills_by_role": {
    "data_analyst": [
      "sql_bigquery",
      "statistical_analysis",
      "insight_generation",
      "python_data",
      "dashboard_design",
      "data_preparation",
      "git_github",
      "technical_scoping",
      "problem_solving",
      "communication",
      "project_management"
    ],
    "data_engineer": [
      "sql_bigquery",
      "python_data",
      "dbt",
      "airflow",
      "data_modeling",
      "git_github",
      "docker",
      "gcp_fundamentals",
      "github_actions",
      "data_quality_management",
      "terraform",
      "monitoring",
      "problem_solving"
    ],
    "data_scientist": [
      "sql_bigquery",
      "python_data",
      "statistical_analysis",
      "ml_fundamentals",
      "insight_generation",
      "ml_deployment",
      "embeddings",
      "mlflow",
      "feature_engineering",
      "git_github",
      "technical_scoping",
      "problem_solving",
      "data_preparation",
      "dashboard_design"
    ],
    "analytics_eng": [
      "sql_bigquery",
      "dbt",
      "data_modeling",
      "python_data",
      "git_github",
      "data_quality_management",
      "airflow",
      "github_actions",
      "technical_scoping",
      "problem_solving",
      "data_governance"
    ],
    "ml_engineer": [
      "python_data",
      "ml_fundamentals",
      "ml_deployment",
      "mlflow",
      "docker",
      "kubernetes",
      "airflow",
      "git_github",
      "github_actions",
      "feature_engineering",
      "embeddings",
      "monitoring",
      "python_backend",
      "problem_solving"
    ],
    "backend": [
      "python_data",
      "python_backend",
      "git_github",
      "docker",
      "kubernetes",
      "gcp_fundamentals",
      "github_actions",
      "terraform",
      "sql_bigquery",
      "monitoring",
      "data_modeling",
      "problem_solving",
      "technical_scoping"
    ]
  },
  "skill_groups": {
    "sql_query": {
      "name": "Compétences SQL & Requêtes",
      "icon": "database",
      "description": "Interrogation et manipulation de données",
      "skills": [
        "sql_bigquery"
      ]
    },
    "python_ecosystem": {
      "name": "Écosystème Python",
      "icon": "code",
      "description": "Programmation Python pour la data",
      "skills": [
        "python_data",
        "python_backend",
        "data_preparation"
      ]
    },
    "transformation": {
      "name": "Transformation de Données",
      "icon": "refresh-cw",
      "description": "Modélisation et transformation",
      "skills": [
        "dbt",
        "data_modeling"
      ]
    },
    "orchestration": {
      "name": "Orchestration & Pipelines",
      "icon": "git-branch",
      "description": "Automatisation des workflows",
      "skills": [
        "airflow"
      ]
    },
    "cloud_infra": {
      "name": "Cloud & Infrastructure",
      "icon": "cloud",
      "description": "Services cloud et infrastructure",
      "skills": [
        "gcp_fundamentals",
        "kubernetes"
      ]
    },
    "devops": {
      "name": "DevOps & Qualité",
      "icon": "settings",
      "description": "CI/CD, conteneurs, qualité",
      "skills": [
        "git_github",
        "github_actions",
        "docker",
        "terraform",
        "monitoring"
      ]
    },
    "analytics_tools": {
      "name": "Outils Analytics",
      "icon": "bar-chart",
      "description": "Analyse et visualisation",
      "skills": [
        "statistical_analysis",
        "insight_generation"
      ]
    },
    "product_analytics": {
      "name": "Product Analytics",
      "icon": "trending-up",
      "description": "Analytics produit",
      "skills": [
        "product_metrics",
        "attribution_marketing",
        "tracking_design"
      ]
    },
    "bi_visualization": {
      "name": "BI & Visualisation",
      "icon": "pie-chart",
      "description": "Outils BI et dashboards",
      "skills": [
        "dashboard_design"
      ]
    },
    "ml_core": {
      "name": "Machine Learning",
      "icon": "cpu",
      "description": "ML et deep learning",
      "skills": [
        "ml_fundamentals",
        "ml_deployment",
        "feature_engineering"
      ]
    },
    "ml_advanced": {
      "name": "ML Avancé & LLM",
      "icon": "brain",
      "description": "Embeddings, recommandation, MLOps",
      "skills": [
        "embeddings",
        "recommendation_systems",
        "entity_resolution",
        "mlflow"
      ]
    },
    "data_quality": {
      "name": "Qualité & Gouvernance",
      "icon": "shield",
      "description": "Tests, gouvernance, data mesh",
      "skills": [
        "data_quality_management",
        "data_governance",
        "data_mesh"
      ]
    },
    "optimization": {
      "name": "Optimisation",
      "icon": "zap",
      "description": "Coûts et performances",
      "skills": [
        "cost_optimization"
      ]
    },
    "domain_knowledge": {
      "name": "Connaissances Métier",
      "icon": "book",
      "description": "Domaine, organisation, écosystème",
      "skills": [
        "pass_culture_knowledge",
        "cultural_ecosystem",
        "cultural_recommendation",
        "cultural_impact_measurement",
        "organisation_pass",
        "ecosysteme_technique"
      ]
    },
    "soft_skills": {
      "name": "Soft Skills",
      "icon": "users",
      "description": "Communication et leadership",
      "skills": [
        "technical_scoping",
        "communication",
        "problem_solving",
        "mentoring_leadership",
        "project_management",
        "posture",
        "culture_feedback",
        "proactivity_challenge",
        "strategic_thinking"
      ]
    }
  },
  "inference_rules": [
    {
      "source": "sql_bigquery",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "cost_optimization",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "dbt",
              "suggestion": 0,
              "confidence": 0.8
            },
            {
              "skill": "cost_optimization",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "python_data",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "python_backend",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "data_preparation",
              "suggestion": 0,
              "confidence": 0.8
            },
            {
              "skill": "python_backend",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "dbt",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "data_modeling",
              "suggestion": 2,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "data_modeling",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": []
        }
      ]
    },
    {
      "source": "gcp_fundamentals",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "mlflow",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "kubernetes",
              "suggestion": 0,
              "confidence": 0.7
            }
          ]
        }
      ]
    },
    {
      "source": "git_github",
      "rules": [
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "github_actions",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "github_actions",
              "suggestion": 0,
              "confidence": 0.8
            }
          ]
        }
      ]
    },
    {
      "source": "docker",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "kubernetes",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "kubernetes",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "ml_fundamentals",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "ml_deployment",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "feature_engineering",
              "suggestion": 2,
              "confidence": 0.8
            },
            {
              "skill": "mlflow",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "feature_engineering",
              "suggestion": 1,
              "confidence": 0.7
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "ml_deployment",
              "suggestion": 0,
              "confidence": 0.9
            },
            {
              "skill": "embeddings",
              "suggestion": 0,
              "confidence": 0.9
            },
            {
              "skill": "recommendation_systems",
              "suggestion": 0,
              "confidence": 0.9
            }
          ]
        }
      ]
    },
    {
      "source": "ml_deployment",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "embeddings",
              "suggestion": 2,
              "confidence": 0.7
            },
            {
              "skill": "mlflow",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        },
        {
          "condition": "<= 1",
          "targets": [
            {
              "skill": "embeddings",
              "suggestion": 0,
              "confidence": 0.8
            }
          ]
        }
      ]
    },
    {
      "source": "statistical_analysis",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "ml_fundamentals",
              "suggestion": 1,
              "confidence": 0.5
            }
          ]
        }
      ]
    },
    {
      "source": "tracking_design",
      "rules": [
        {
          "condition": ">= 2",
          "targets": [
            {
              "skill": "product_metrics",
              "suggestion": 1,
              "confidence": 0.6
            }
          ]
        }
      ]
    },
    {
      "source": "communication",
      "rules": [
        {
          "condition": ">= 3",
          "targets": [
            {
              "skill": "technical_scoping",
              "suggestion": 2,
              "confidence": 0.7
            }
          ]
        }
      ]
    }
  ]
}
